{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f8d1244",
   "metadata": {},
   "source": [
    "# KoChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21ce6ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version:1.12.1\n",
      "Cuda version: 11.3\n",
      "transformers version: 4.28.0\n",
      "GPU 사용 가능여부: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "\n",
    "print(\"Torch version:{}\".format(torch.__version__)) # Torch version:1.12.1\n",
    "print(\"Cuda version: {}\".format(torch.version.cuda)) # Cuda version: 11.3\n",
    "print(\"transformers version: {}\".format(transformers.__version__)) # transformers 4.28.0\n",
    "print(\"GPU 사용 가능여부: {}\".format(torch.cuda.is_available()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40df5e1b",
   "metadata": {},
   "source": [
    "## Base model and Dataset for RLHF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56e7855b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import pandas as pd\n",
    "import numpy\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_name = \"skt/kogpt2-base-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd074efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt2': 1024,\n",
       " 'gpt2-medium': 1024,\n",
       " 'gpt2-large': 1024,\n",
       " 'gpt2-xl': 1024,\n",
       " 'distilgpt2': 1024}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델의 토크나이저가 입력받아 처리할 수 있는 최대 토큰 수를 확인\n",
    "tokenizer.max_model_input_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60ba0918",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_txt = \"바람도 없는 공중에 수직의 파문을 내이며 고요히 떨어지는 오동잎은 누구의 발자취 입니까.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7f5db9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer(input_txt).tokens()\n",
    "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5899a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>kogpt-2_tokens</th>\n",
       "      <td>▁바람</td>\n",
       "      <td>도</td>\n",
       "      <td>▁없는</td>\n",
       "      <td>▁공중에</td>\n",
       "      <td>▁수직</td>\n",
       "      <td>의</td>\n",
       "      <td>▁파</td>\n",
       "      <td>문을</td>\n",
       "      <td>▁내</td>\n",
       "      <td>이며</td>\n",
       "      <td>▁고</td>\n",
       "      <td>요</td>\n",
       "      <td>히</td>\n",
       "      <td>▁떨어지는</td>\n",
       "      <td>▁오동</td>\n",
       "      <td>잎은</td>\n",
       "      <td>▁누</td>\n",
       "      <td>구의</td>\n",
       "      <td>▁발자</td>\n",
       "      <td>취</td>\n",
       "      <td>▁입</td>\n",
       "      <td>니까</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Input_IDs</th>\n",
       "      <td>10891</td>\n",
       "      <td>7235</td>\n",
       "      <td>9712</td>\n",
       "      <td>49207</td>\n",
       "      <td>14438</td>\n",
       "      <td>8143</td>\n",
       "      <td>9203</td>\n",
       "      <td>9941</td>\n",
       "      <td>9094</td>\n",
       "      <td>9639</td>\n",
       "      <td>9065</td>\n",
       "      <td>8084</td>\n",
       "      <td>8811</td>\n",
       "      <td>21215</td>\n",
       "      <td>34769</td>\n",
       "      <td>19985</td>\n",
       "      <td>9669</td>\n",
       "      <td>10139</td>\n",
       "      <td>21626</td>\n",
       "      <td>8408</td>\n",
       "      <td>9241</td>\n",
       "      <td>23775</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0     1     2      3      4     5     6     7     8     9   \\\n",
       "kogpt-2_tokens    ▁바람     도   ▁없는   ▁공중에    ▁수직     의    ▁파    문을    ▁내    이며   \n",
       "Input_IDs       10891  7235  9712  49207  14438  8143  9203  9941  9094  9639   \n",
       "\n",
       "                  10    11    12     13     14     15    16     17     18  \\\n",
       "kogpt-2_tokens    ▁고     요     히  ▁떨어지는    ▁오동     잎은    ▁누     구의    ▁발자   \n",
       "Input_IDs       9065  8084  8811  21215  34769  19985  9669  10139  21626   \n",
       "\n",
       "                  19    20     21   22  \n",
       "kogpt-2_tokens     취    ▁입     니까    .  \n",
       "Input_IDs       8408  9241  23775  389  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토크나이징 확인\n",
    "pd.options.display.max_columns = 40\n",
    "pd.options.display.max_rows = 60\n",
    "df = pd.DataFrame([tokens, input_ids[0]], index=[\"kogpt-2_tokens\", \"Input_IDs\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8b6be8",
   "metadata": {},
   "source": [
    "### SFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00013245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prompt': '불고기용 고기 한우에요?',\n",
       "  'completion': \"'저는 인공지능 챗봇이며, 직접적으로 식품에 관한 정보를 가지고 있지 않습니다. 하지만 일반적으로 불고기용 고기는 한우, 쇠고기, 돼지고기 등 다양한 종류의 고기를 사용합니다. 하지만 한우는 대표적인 고급 육류로 알려져 있기 때문에, 한우를 사용하는 경우도 많습니다. 알러지나 개별 건강 상태에 따라 다를 수 있으니 충분한 정보 수집 후에 선택해 주시기 바랍니다.\",\n",
       "  'tokens': 193},\n",
       " {'prompt': '쓰던 앱이 유료로 전환됐어',\n",
       "  'completion': \"'어떤 앱인지 모르기 때문에 정확한 답변을 드리기 어렵습니다. 하지만, 일반적으로 유료 전환된 앱은 기존 무료 앱에서 추가적인 기능이나 서비스를 제공하는 경우가 많습니다. 이 경우, 유료 전환 이전 가격이 매우 저렴하거나 무료인 경우가 많으므로, 앱을 계속 사용하려면 추가적인 비용을 지불해야 할 수 있습니다. 하지만, 유료 전환 이후에는 기존 사용자 또는 새로운 사용자 모두가 추가 기능과 높은 품질의 서비스를 이용할 수 있게 됩니다. 따라서, 앱 개발자는 유료 모델로 전환함으로써 앱의 수익을 증가시키고 더 나은 서비스를 제공할 수 있습니다.\",\n",
       "  'tokens': 288},\n",
       " {'prompt': '여친이랑 다툼',\n",
       "  'completion': \"'저는 인공지능이기 때문에 여친과의 다툼에 대해서는 조언을 드릴 수는 없습니다. 하지만 다투게 되면 상대방의 말을 경청하는 태도와 서로의 감정을 존중하는 것이 중요합니다. 논리적이고 차분한 대화를 통해 문제를 해결해보세요. 그리고 서로를 이해하고 서로의 의견을 수용하는 것이 중요합니다.\",\n",
       "  'tokens': 153}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋 확인\n",
    "import json \n",
    "data_path_1_SFT = '/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_1_SFT.jsonl' \n",
    "with open(data_path_1_SFT, \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "print(len(list_data_dict))\n",
    "list_data_dict[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3d3cec",
   "metadata": {},
   "source": [
    "### RM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec8e67ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prompt': '번디는 자신이 탐정잡지, 범죄소설 그리고 성범죄 관련 실제 범죄 다큐멘터리들을 탐독했다고 누구에게 말했나?',\n",
       "  'completion_0': 'Allow me to answer your question. I know that you are curious about me.',\n",
       "  'completion_1': '번디는 다양한 인터뷰자들과 뉴스홍보 담당자들과의 면담 때 밝혔다.',\n",
       "  'completion_2': '라이언에게 말했다.',\n",
       "  'ranking': [2, 1, 0]},\n",
       " {'prompt': '개포주공아파트는 몇 단지로 이루어져 있나?',\n",
       "  'completion_0': '개포주공아파트는 다섯 단지로 이루어져 있습니다.',\n",
       "  'completion_1': '이날 목송에서 구글상위노',\n",
       "  'completion_2': '개포주공아파트는 총 27개 단지로 이루어져 있습니다.',\n",
       "  'ranking': [2, 0, 1]},\n",
       " {'prompt': '김영삼의 후보 시절 지역표심을 겨냥한 발언을 문제삼은 후보는?',\n",
       "  'completion_0': 'The diameter of the Metallic domain is bigger than the Hyperonic domain.',\n",
       "  'completion_1': '이 질문은 조금 불분명합니다. 김영삼 대통령이 후보 시절에 어떤 발언을 했고, 누가 그 발언을 문제삼았는지에 따라 답이 다를 수 있습니다.\\\\n\\\\n만약 김영삼 대통령이 후보 시절에 지역표심을 겨냥한 발언을 했다는 가정하에, 그 발언을 문제삼은 후보가 누구였는지를 대답하자면, 그 답은 이화선 당시 민주당 대통령 후보가 될 것입니다. 1992년 총선 때, 김영삼 대선후보는 \"집값이 오른 노량진역 부근의 부동산 가격은 세월호 폭침 후 \\\\\\'강남 도시재생\\\\\\' 일환으로 상승했다\"는 발언을 했습니다. 하지만 이화선 후보는 이 발언을 \"전국적으로 경제적 발전이 이루어지지 않은 지방민의 마음을 멀리해지려는 무례한 발언\"이라고 비판하며 문제삼았습니다.\\\\n\\\\n하지만, 이 질문을 답변하는 데 있어서 보다 명확한 정보가 있으면 답변을 보완할 수 있습니다.',\n",
       "  'completion_2': '김영삼의 후보 시절에 지역표심을 겨냥한 발언은 대통령 당선 전까지 대한민국 정부가 추구하고 있는 민주주의 광범위하게 확립과 보수의 사상을 이어가는 데 있어 지역경제 발전과 공공서비스 신속 개선을 위해 합리적인 국가 정책에 따르는 방향성을 제시하고 있습니다.',\n",
       "  'ranking': [1, 2, 0]}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path_2_RM = '/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_2_RM.jsonl'\n",
    "with open(data_path_2_RM, \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "print(len(list_data_dict))\n",
    "list_data_dict[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b1959b",
   "metadata": {},
   "source": [
    "### PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "501d6fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prompt': '번디는 자신이 탐정잡지, 범죄소설 그리고 성범죄 관련 실제 범죄 다큐멘터리들을 탐독했다고 누구에게 말했나?'},\n",
       " {'prompt': '개포주공아파트는 몇 단지로 이루어져 있나?'},\n",
       " {'prompt': '김영삼의 후보 시절 지역표심을 겨냥한 발언을 문제삼은 후보는?'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path_3_PPO = '/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_3_PPO.jsonl'\n",
    "with open(data_path_3_PPO, \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "print(len(list_data_dict))\n",
    "list_data_dict[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456cddd0",
   "metadata": {},
   "source": [
    "## Supervised Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "946507a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim import Adam\n",
    "from datasets import load_dataset\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from copy import deepcopy\n",
    "import copy\n",
    "import logging\n",
    "import json\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "234e65c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2TokenizerFast(name_or_path='skt/kogpt2-base-v2', vocab_size=51200, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '</s>', 'eos_token': '</s>', 'unk_token': '</s>', 'pad_token': '</s>'}, clean_up_tokenization_spaces=True)\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('skt/kogpt2-base-v2')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "    padding_side=\"right\",\n",
    "    model_max_length=512,\n",
    ")\n",
    "\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b624276e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Dict, Sequence\n",
    "\n",
    "class SFT_dataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_path_1_SFT: str, tokenizer: transformers.PreTrainedTokenizer, verbose=False):\n",
    "        super(SFT_dataset, self).__init__()\n",
    "        logging.warning(\"Loading data...\")\n",
    "\n",
    "        pattern_instruction = 'prompt'  # instruction\n",
    "        pattern_output = 'completion'  # response\n",
    "\n",
    "        with open(data_path_1_SFT, \"r\", encoding='utf-8-sig') as json_file:\n",
    "            list_data_dict = json.load(json_file)\n",
    "\n",
    "        PROMPT_DICT = {\n",
    "            \"prompt_input\": (\n",
    "                \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "            )\n",
    "        }\n",
    "\n",
    "        prompt_input = PROMPT_DICT[\"prompt_input\"]\n",
    "\n",
    "        sources = []\n",
    "        for example in list_data_dict:\n",
    "            tmp = prompt_input.format_map(example)\n",
    "            sources.append(tmp)\n",
    "\n",
    "        targets = []\n",
    "        for example in list_data_dict:\n",
    "            targets.append(f\"{example[pattern_output]}{tokenizer.eos_token}\")\n",
    "        examples = [s + t for s, t in zip(sources, targets)]\n",
    "\n",
    "        sources_tokenized = self._tokenize_fn(sources, tokenizer)  # source\n",
    "        examples_tokenized = self._tokenize_fn(examples, tokenizer)  # source + target\n",
    "\n",
    "        input_ids = examples_tokenized[\"input_ids\"]\n",
    "        labels = copy.deepcopy(input_ids)\n",
    "        for label, source_len in zip(labels, sources_tokenized[\"input_ids_lens\"]):\n",
    "            label[:source_len] = -100\n",
    "\n",
    "        data_dict = dict(input_ids=input_ids, labels=labels)\n",
    "\n",
    "        self.input_ids = data_dict[\"input_ids\"]\n",
    "        self.labels = data_dict[\"labels\"]\n",
    "        logging.warning(\"Loading data done!!: %d\"%(len(self.labels)))\n",
    "\n",
    "\n",
    "    def _tokenize_fn(self, strings: Sequence[str], tokenizer: transformers.PreTrainedTokenizer) -> Dict:\n",
    "        tokenized_list = [\n",
    "            tokenizer(\n",
    "                text,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=\"longest\",\n",
    "                max_length=tokenizer.model_max_length,\n",
    "                truncation=True,\n",
    "            )\n",
    "            for text in strings\n",
    "        ]\n",
    "        input_ids = labels = [tokenized.input_ids[0] for tokenized in tokenized_list]\n",
    "        input_ids_lens = labels_lens = [\n",
    "            tokenized.input_ids.ne(tokenizer.pad_token_id).sum().item() for tokenized in tokenized_list\n",
    "        ]\n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            input_ids_lens=input_ids_lens,\n",
    "            labels_lens=labels_lens,\n",
    "        )\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "\n",
    "    def __getitem__(self, i) -> Dict[str, torch.Tensor]:\n",
    "        return dict(input_ids=self.input_ids[i], labels=self.labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af60783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorForSupervisedDataset(object): \n",
    "\n",
    "    tokenizer: transformers.PreTrainedTokenizer\n",
    "\n",
    "    def __call__(self, instances: Sequence[Dict]) -> Dict[str, torch.Tensor]:\n",
    "        input_ids, labels = tuple([instance[key] for instance in instances] for key in (\"input_ids\", \"labels\"))\n",
    "        input_ids = torch.nn.utils.rnn.pad_sequence(\n",
    "            input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id\n",
    "        )\n",
    "        labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value= -100)\n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            attention_mask=input_ids.ne(self.tokenizer.pad_token_id),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e8d1efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Loading data...\n",
      "WARNING:root:Loading data done!!: 12000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input : tensor([  739,   378,   378,   378, 14659, 13394, 37091, 10651,   383, 25841,\n",
      "         8006, 14914,   375,  7673, 20479,  8091, 22311,  9036, 30902, 13675,\n",
      "          375,   378,   378,   378, 41951,   454,  9549, 20549,   383,  8142,\n",
      "         7192, 14914,   382, 37767, 13753,  8263,  7166,   739,  8352,  7659,\n",
      "         9594, 25585, 13600,  8022,  9378, 11532,  9887, 11218,  9111, 16691,\n",
      "        10351, 10561,  9128, 20479,  8091,  9065,  9446,  9036, 28420, 26521,\n",
      "        10163, 26367,  6958,  9030,  9882, 12317, 25882,  9209, 37194, 10351,\n",
      "         9036, 12168, 10529, 15989,  9719, 15434, 10552, 11188, 13362,  9036,\n",
      "        15805, 11300, 11846,  9146, 16691,  9181,  7397, 15806, 13480, 11342,\n",
      "        17596,  9161, 19996,  9025, 25006, 18595,  9966, 12592, 10751, 11814,\n",
      "         8711,  9046, 12450,  9117,  7377, 12521,     1])\n",
      "output: tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,   382, 37767, 13753,  8263,  7166,   739,  8352,  7659,\n",
      "         9594, 25585, 13600,  8022,  9378, 11532,  9887, 11218,  9111, 16691,\n",
      "        10351, 10561,  9128, 20479,  8091,  9065,  9446,  9036, 28420, 26521,\n",
      "        10163, 26367,  6958,  9030,  9882, 12317, 25882,  9209, 37194, 10351,\n",
      "         9036, 12168, 10529, 15989,  9719, 15434, 10552, 11188, 13362,  9036,\n",
      "        15805, 11300, 11846,  9146, 16691,  9181,  7397, 15806, 13480, 11342,\n",
      "        17596,  9161, 19996,  9025, 25006, 18595,  9966, 12592, 10751, 11814,\n",
      "         8711,  9046, 12450,  9117,  7377, 12521,     1])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SFT_dataset(data_path_1_SFT='/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_1_SFT.jsonl', tokenizer=tokenizer)\n",
    "data_collator = DataCollatorForSupervisedDataset(tokenizer=tokenizer)\n",
    "\n",
    "print('input : %s'%train_dataset.input_ids[0])\n",
    "print('output: %s'%train_dataset.labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67aa4f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/aiffel/KoChatGPT/test\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=5,\n",
    "    prediction_loss_only=True,\n",
    "    fp16 = True\n",
    "    )\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7648e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4500' max='4500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4500/4500 16:23, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.007800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.795700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.251900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>2.262400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.827800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.840500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.823100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "model.save_pretrained('/aiffel/KoChatGPT/output_1_SFT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2dfde7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/transformers/generation/utils.py:1219: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Instruction(명령어):\n",
      "불고기용 고기 한우에요?\n",
      "\n",
      "### Response(응답):'저는 AI 어시스턴트이기 때문에 실제로 고기를 먹을 수 없습니다. 하지만 일반적으로 쇠고기는 건강에 좋은 재료로 많이 사용됩니다. 따라서 불고기용 고기는 건강에 좋지 않으므로, 구매 전에 건강 상태와 안전성을 확인하시는 것이 좋습니다.\\n\\n만약 \"불고기용 고기의 한\n",
      "\n",
      "### Instruction(명령어):\n",
      "리처드 닉슨이 43대 부통령직을 수행한 년도는?\n",
      "\n",
      "### Response(응답):'리처드 닉슨은 41대 부통령직을 수행했습니다. \"리처드 닉슨\"은 1952년 대선에서 공화당 후보로 출마한 리처드 닉슨이 출마하면서 처음 등장했습니다.\\n\\n1960년대 초반, 리처드 닉슨은 39대 부통령직을 맡았습니다.\\n출처: 클린턴\n",
      "\n",
      "### Instruction(명령어):\n",
      "시카고 오헤어 국제공항은 어디에 있어?\n",
      "\n",
      "### Response(응답):'시카고 오 헤어 국제공항은 미국 일리노이주 시카고에 위치해 있습니다.恩國際都市報道報道報道)에 따르면, 시카고는 미국 일리노이주 시카고에서 가장 중요한 국제공항 중 하나입니다.恩國濟州報道報道)의 보도에 따르면, 시카고는 미국에서 가장 중요한 도시 중 하나로 인정받고 있습니다.\n",
      "\n",
      "### Instruction(명령어):\n",
      "오늘 미세먼지 어때?\n",
      "\n",
      "### Response(응답):'미세먼지 농도는 어제와 비교해서 나아졌지만, 여전히 나쁜 수준입니다. 미세먼지 농도가 높은 날에는 실외 활동을 자제하는 것이 좋습니다. 또한, 미세먼지 농도를 줄이기 위해 공기청정기나 마스크를 사용하는 것이 좋습니다. 외출 후에는 반드시 마스크를 착용하고, 실내 공기 질을 유지하기 위한 노력을 기울여야\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline('text-generation', model='/aiffel/KoChatGPT/output_1_SFT', tokenizer=tokenizer)\n",
    "\n",
    "generation_args = dict(   \n",
    "    num_beams=4,\n",
    "    repetition_penalty=2.0,\n",
    "    no_repeat_ngram_size=4,\n",
    "    eos_token_id=375, # \\n   \n",
    "    max_new_tokens=64,\n",
    "    do_sample=True,\n",
    "    top_k=50,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "    )\n",
    "}\n",
    "\n",
    "list_prompt = ['불고기용 고기 한우에요?',\n",
    "               '리처드 닉슨이 43대 부통령직을 수행한 년도는?',\n",
    "               '시카고 오헤어 국제공항은 어디에 있어?',\n",
    "               '오늘 미세먼지 어때?']\n",
    "\n",
    "list_prompt = [PROMPT_DICT['prompt_input'].format_map({'prompt' : tmp}) for tmp in list_prompt]\n",
    "\n",
    "list_result = generator(list_prompt, **generation_args)   \n",
    "for prompt, result in zip(list_prompt, list_result):\n",
    "    print()\n",
    "    print((result[0]['generated_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23ae8b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642c0cdf",
   "metadata": {},
   "source": [
    "## Reward Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "badf2d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/aiffel/KoChatGPT/colossalai_ChatGPT_230319')\n",
    "\n",
    "import os\n",
    "import json\n",
    "from typing import Optional\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from chatgpt.dataset import RewardDataset\n",
    "from chatgpt.models.base import RewardModel\n",
    "from chatgpt.trainer import RewardModelTrainer\n",
    "from chatgpt.trainer.strategies import NaiveStrategy\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModel, AutoConfig\n",
    "from transformers.models.gpt2.configuration_gpt2 import GPT2Config\n",
    "from transformers.models.gpt2.modeling_gpt2 import GPT2Model\n",
    "import loralib as lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c400ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTRM_custom(RewardModel):\n",
    "\n",
    "    def __init__(self,\n",
    "                 pretrained: Optional[str] = None,\n",
    "                 config: Optional[GPT2Config] = None,\n",
    "                 checkpoint: bool = False,\n",
    "                 lora_rank: int = 0,\n",
    "                 lora_train_bias: str = 'none',\n",
    "                 tokenizer=None) -> None:\n",
    "        if pretrained is not None:\n",
    "            model = GPT2Model.from_pretrained(pretrained)\n",
    "            model.resize_token_embeddings(len(tokenizer))\n",
    "        elif config is not None:\n",
    "            model = GPT2Model(config)\n",
    "        else:\n",
    "            model = GPT2Model(GPT2Config())\n",
    "        if checkpoint:\n",
    "            model.gradient_checkpointing_enable()\n",
    "\n",
    "        value_head = nn.Linear(model.config.n_embd, 1)\n",
    "        super().__init__(model, value_head, lora_rank, lora_train_bias)\n",
    "\n",
    "        if pretrained is not None:\n",
    "            self.model = model\n",
    "            self.pretrained = pretrained\n",
    "\n",
    "\n",
    "    def save_pretrained(self, dir):\n",
    "        if self.pretrained is not None:\n",
    "            self.model.save_pretrained(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd5b7095",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at skt/kogpt2-base-v2 were not used when initializing GPT2Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('skt/kogpt2-base-v2')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "    padding_side=\"right\",\n",
    "    model_max_length=512,\n",
    ")\n",
    "\n",
    "with NaiveStrategy().model_init_context():\n",
    "        model = GPTRM_custom(pretrained='skt/kogpt2-base-v2', lora_rank=0, tokenizer=tokenizer).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2f37b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before data num: 10220\n",
      "after  data num: 30660\n",
      "data example: \n",
      "{'prompt': '애플은 리사를 어떻게 처리했어', 'chosen': '애플이 누구인지 명확히 알 수 없어서, 리사가 누구인지와 어떤 상황에서 처리되었는지에 대한 추가적인 정보가 필요합니다. 따라서, 보다 정확한 답변을 제공할 수 없습니다.', 'rejected': '애플은 리사를 위해 고객 서비스 부서에서 고객 다양한 컴퓨터 관련 문제에 대해 응답하는 데 필요한 모든 지원을 제공했습니다. 사용자가 하드웨어 문제를 경험할 때, 전문가들은 필요한 수리(수리, 추가 부품 제공, 소프트웨어 업그레이드 등)을 제공해 드릴 수 있습니다. 또한, 사용자가 사용 방법 문제나 기타 문제를 경험할 때, 대화 상대로 사용자를 지원할 수 있는 전문 고객 서비스 직원들이 사용자에게 상담하고 도움을 주는 데 도움이 될 수 있는 정보를 제공합니다. 또한, 인터넷에서 제공되는 정보를 통해 문제를 해결하거나 고객 서비스 웹 사이트를 통해 자신의 문제를 진단할 수 있도록 하는 등 다양한 방법으로 리사를 처리해 왔습니다.'}\n"
     ]
    }
   ],
   "source": [
    "with open('/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_2_RM.jsonl', \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "total_data_ranking2chosen = []\n",
    "for tmp in list_data_dict:\n",
    "    one_data_ranking2chosen = []\n",
    "\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][0] < tmp['ranking'][1]:\n",
    "        data['chosen'] = tmp['completion_0']\n",
    "        data['rejected'] = tmp['completion_1']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_1']\n",
    "        data['rejected'] = tmp['completion_0']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][0] < tmp['ranking'][2]:\n",
    "        data['chosen'] = tmp['completion_0']\n",
    "        data['rejected'] = tmp['completion_2']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_2']\n",
    "        data['rejected'] = tmp['completion_0']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][1] < tmp['ranking'][2]:\n",
    "        data['chosen'] = tmp['completion_1']\n",
    "        data['rejected'] = tmp['completion_2']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_2']\n",
    "        data['rejected'] = tmp['completion_1']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "\n",
    "\n",
    "    total_data_ranking2chosen.extend(one_data_ranking2chosen)\n",
    "\n",
    "print('before data num: %d'%(len(list_data_dict)))\n",
    "print('after  data num: %d'%(len(total_data_ranking2chosen)))\n",
    "print('data example: \\n%s'%total_data_ranking2chosen[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d59c1ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': '유아인이 류승완 감독을 만나 영화 베테랑의 시나리오를 받았던 곳은?', 'chosen': '유아인이 류승완 감독을 만나 영화 베테랑의 시나리오를 받았던 곳은 류승완의 사무실입니다.', 'rejected': '대구 영화사옥'}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(230319)\n",
    "random.shuffle(total_data_ranking2chosen)\n",
    "print(total_data_ranking2chosen[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "efe279c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1248.26it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 1270.45it/s]\n"
     ]
    }
   ],
   "source": [
    "# 데이터 셔플 후 일부만 학습\n",
    "train_data = total_data_ranking2chosen[:1000] \n",
    "eval_data = total_data_ranking2chosen[1000:1200]\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(eval_data))\n",
    "\n",
    "train_dataset = RewardDataset(train_data, tokenizer, 512)\n",
    "eval_dataset = RewardDataset(eval_data, tokenizer, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f9a1ebf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################################################\n",
      "## prompt ##\n",
      "흑고래의 무게는 어느 정도야\n",
      "######################################################################\n",
      "## chosen ##\n",
      "흑고래의 평균 몸무게는 약 25~40톤 정도이지만, 최대 몸무게는 50톤 이상에 이를 수 있습니다.\n",
      "######################################################################\n",
      "## rejected ##\n",
      "흑고래의 무게는 매우 다양하게 달라집니다. 약 200kg에서 10톤까지 달라질 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "print('#'*70)\n",
    "print('## prompt ##')\n",
    "print(train_data[idx]['prompt'])\n",
    "print('#'*70)\n",
    "print('## chosen ##')\n",
    "print(train_data[idx]['chosen'])\n",
    "print('#'*70)\n",
    "print('## rejected ##')\n",
    "print(train_data[idx]['rejected'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dff975d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = RewardModelTrainer(model=model,\n",
    "                             strategy=NaiveStrategy(),\n",
    "                             optim=Adam(model.parameters(), lr=5e-5),\n",
    "                             train_dataset=train_dataset,\n",
    "                             eval_dataset=eval_dataset,\n",
    "                             batch_size=4,\n",
    "                             max_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "20358b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train epoch:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   0%|          | 0/250 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   0%|          | 1/250 [00:00<03:50,  1.08it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   0%|          | 1/250 [00:00<03:50,  1.08it/s, loss=0.623]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   1%|          | 2/250 [00:01<03:42,  1.12it/s, loss=0.623]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   1%|          | 2/250 [00:01<03:42,  1.12it/s, loss=0.515]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   1%|          | 3/250 [00:02<03:38,  1.13it/s, loss=0.515]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   1%|          | 3/250 [00:02<03:38,  1.13it/s, loss=0.387]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   2%|▏         | 4/250 [00:03<03:36,  1.13it/s, loss=0.387]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   2%|▏         | 4/250 [00:03<03:36,  1.13it/s, loss=0.764]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   2%|▏         | 5/250 [00:04<03:35,  1.14it/s, loss=0.764]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   2%|▏         | 5/250 [00:04<03:35,  1.14it/s, loss=0.118]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   2%|▏         | 6/250 [00:05<03:34,  1.14it/s, loss=0.118]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   2%|▏         | 6/250 [00:05<03:34,  1.14it/s, loss=0.0614]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   3%|▎         | 7/250 [00:06<03:33,  1.14it/s, loss=0.0614]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   3%|▎         | 7/250 [00:06<03:33,  1.14it/s, loss=0.112] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   3%|▎         | 8/250 [00:07<03:32,  1.14it/s, loss=0.112]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   3%|▎         | 8/250 [00:07<03:32,  1.14it/s, loss=0.822]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   4%|▎         | 9/250 [00:07<03:31,  1.14it/s, loss=0.822]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   4%|▎         | 9/250 [00:07<03:31,  1.14it/s, loss=0.477]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   4%|▍         | 10/250 [00:08<03:30,  1.14it/s, loss=0.477]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   4%|▍         | 10/250 [00:08<03:30,  1.14it/s, loss=0.312]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   4%|▍         | 11/250 [00:09<03:29,  1.14it/s, loss=0.312]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   4%|▍         | 11/250 [00:09<03:29,  1.14it/s, loss=0.161]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   5%|▍         | 12/250 [00:10<03:29,  1.14it/s, loss=0.161]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   5%|▍         | 12/250 [00:10<03:29,  1.14it/s, loss=0.247]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   5%|▌         | 13/250 [00:11<03:28,  1.14it/s, loss=0.247]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   5%|▌         | 13/250 [00:11<03:28,  1.14it/s, loss=0.0169]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   6%|▌         | 14/250 [00:12<03:27,  1.14it/s, loss=0.0169]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   6%|▌         | 14/250 [00:12<03:27,  1.14it/s, loss=1.76]  \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   6%|▌         | 15/250 [00:13<03:27,  1.13it/s, loss=1.76]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   6%|▌         | 15/250 [00:13<03:27,  1.13it/s, loss=0.187]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   6%|▋         | 16/250 [00:14<03:26,  1.13it/s, loss=0.187]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   6%|▋         | 16/250 [00:14<03:26,  1.13it/s, loss=1.35] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   7%|▋         | 17/250 [00:14<03:25,  1.13it/s, loss=1.35]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   7%|▋         | 17/250 [00:15<03:25,  1.13it/s, loss=1.42]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   7%|▋         | 18/250 [00:15<03:24,  1.13it/s, loss=1.42]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   7%|▋         | 18/250 [00:15<03:24,  1.13it/s, loss=0.188]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   8%|▊         | 19/250 [00:16<03:24,  1.13it/s, loss=0.188]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   8%|▊         | 19/250 [00:16<03:24,  1.13it/s, loss=0.729]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   8%|▊         | 20/250 [00:17<03:23,  1.13it/s, loss=0.729]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   8%|▊         | 20/250 [00:17<03:23,  1.13it/s, loss=0.596]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   8%|▊         | 21/250 [00:18<03:22,  1.13it/s, loss=0.596]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   8%|▊         | 21/250 [00:18<03:22,  1.13it/s, loss=0.908]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   9%|▉         | 22/250 [00:19<03:21,  1.13it/s, loss=0.908]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   9%|▉         | 22/250 [00:19<03:21,  1.13it/s, loss=0.768]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   9%|▉         | 23/250 [00:20<03:20,  1.13it/s, loss=0.768]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   9%|▉         | 23/250 [00:20<03:20,  1.13it/s, loss=1.04] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  10%|▉         | 24/250 [00:21<03:19,  1.13it/s, loss=1.04]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  10%|▉         | 24/250 [00:21<03:19,  1.13it/s, loss=0.732]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  10%|█         | 25/250 [00:22<03:18,  1.13it/s, loss=0.732]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  10%|█         | 25/250 [00:22<03:18,  1.13it/s, loss=0.565]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  10%|█         | 26/250 [00:22<03:18,  1.13it/s, loss=0.565]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  10%|█         | 26/250 [00:22<03:18,  1.13it/s, loss=0.62] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  11%|█         | 27/250 [00:23<03:17,  1.13it/s, loss=0.62]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  11%|█         | 27/250 [00:23<03:17,  1.13it/s, loss=0.518]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  11%|█         | 28/250 [00:24<03:16,  1.13it/s, loss=0.518]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  11%|█         | 28/250 [00:24<03:16,  1.13it/s, loss=0.468]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  12%|█▏        | 29/250 [00:25<03:15,  1.13it/s, loss=0.468]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  12%|█▏        | 29/250 [00:25<03:15,  1.13it/s, loss=0.79] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  12%|█▏        | 30/250 [00:26<03:14,  1.13it/s, loss=0.79]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  12%|█▏        | 30/250 [00:26<03:14,  1.13it/s, loss=0.474]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  12%|█▏        | 31/250 [00:27<03:12,  1.14it/s, loss=0.474]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  12%|█▏        | 31/250 [00:27<03:12,  1.14it/s, loss=0.484]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  13%|█▎        | 32/250 [00:28<03:11,  1.14it/s, loss=0.484]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  13%|█▎        | 32/250 [00:28<03:11,  1.14it/s, loss=0.912]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  13%|█▎        | 33/250 [00:29<03:11,  1.14it/s, loss=0.912]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  13%|█▎        | 33/250 [00:29<03:11,  1.14it/s, loss=0.504]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  14%|█▎        | 34/250 [00:29<03:10,  1.14it/s, loss=0.504]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  14%|█▎        | 34/250 [00:30<03:10,  1.14it/s, loss=0.697]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  14%|█▍        | 35/250 [00:30<03:08,  1.14it/s, loss=0.697]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  14%|█▍        | 35/250 [00:30<03:08,  1.14it/s, loss=0.932]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  14%|█▍        | 36/250 [00:31<03:07,  1.14it/s, loss=0.932]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  14%|█▍        | 36/250 [00:31<03:07,  1.14it/s, loss=0.871]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  15%|█▍        | 37/250 [00:32<03:06,  1.14it/s, loss=0.871]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  15%|█▍        | 37/250 [00:32<03:06,  1.14it/s, loss=0.799]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  15%|█▌        | 38/250 [00:33<03:05,  1.14it/s, loss=0.799]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  15%|█▌        | 38/250 [00:33<03:05,  1.14it/s, loss=0.725]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  16%|█▌        | 39/250 [00:34<03:04,  1.14it/s, loss=0.725]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  16%|█▌        | 39/250 [00:34<03:04,  1.14it/s, loss=1.1]  \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  16%|█▌        | 40/250 [00:35<03:03,  1.15it/s, loss=1.1]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  16%|█▌        | 40/250 [00:35<03:03,  1.15it/s, loss=0.574]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  16%|█▋        | 41/250 [00:36<03:02,  1.15it/s, loss=0.574]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  16%|█▋        | 41/250 [00:36<03:02,  1.15it/s, loss=0.54] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  17%|█▋        | 42/250 [00:36<03:01,  1.15it/s, loss=0.54]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  17%|█▋        | 42/250 [00:36<03:01,  1.15it/s, loss=0.623]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  17%|█▋        | 43/250 [00:37<03:00,  1.15it/s, loss=0.623]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  17%|█▋        | 43/250 [00:37<03:00,  1.15it/s, loss=0.617]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  18%|█▊        | 44/250 [00:38<02:59,  1.15it/s, loss=0.617]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  18%|█▊        | 44/250 [00:38<02:59,  1.15it/s, loss=0.771]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  18%|█▊        | 45/250 [00:39<02:58,  1.15it/s, loss=0.771]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  18%|█▊        | 45/250 [00:39<02:58,  1.15it/s, loss=0.524]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  18%|█▊        | 46/250 [00:40<02:57,  1.15it/s, loss=0.524]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  18%|█▊        | 46/250 [00:40<02:57,  1.15it/s, loss=0.568]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  19%|█▉        | 47/250 [00:41<02:56,  1.15it/s, loss=0.568]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  19%|█▉        | 47/250 [00:41<02:56,  1.15it/s, loss=0.677]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  19%|█▉        | 48/250 [00:42<02:55,  1.15it/s, loss=0.677]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  19%|█▉        | 48/250 [00:42<02:55,  1.15it/s, loss=0.715]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  20%|█▉        | 49/250 [00:43<02:54,  1.15it/s, loss=0.715]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  20%|█▉        | 49/250 [00:43<02:54,  1.15it/s, loss=0.542]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  20%|██        | 50/250 [00:43<02:53,  1.15it/s, loss=0.542]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  20%|██        | 50/250 [00:43<02:53,  1.15it/s, loss=0.891]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  20%|██        | 51/250 [00:44<02:52,  1.15it/s, loss=0.891]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  20%|██        | 51/250 [00:44<02:52,  1.15it/s, loss=0.521]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  21%|██        | 52/250 [00:45<02:51,  1.15it/s, loss=0.521]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  21%|██        | 52/250 [00:45<02:51,  1.15it/s, loss=0.694]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  21%|██        | 53/250 [00:46<02:51,  1.15it/s, loss=0.694]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  21%|██        | 53/250 [00:46<02:51,  1.15it/s, loss=0.564]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  22%|██▏       | 54/250 [00:47<02:49,  1.15it/s, loss=0.564]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  22%|██▏       | 54/250 [00:47<02:49,  1.15it/s, loss=0.425]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  22%|██▏       | 55/250 [00:48<02:48,  1.15it/s, loss=0.425]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  22%|██▏       | 55/250 [00:48<02:48,  1.15it/s, loss=0.582]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  22%|██▏       | 56/250 [00:49<02:48,  1.15it/s, loss=0.582]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  22%|██▏       | 56/250 [00:49<02:48,  1.15it/s, loss=0.661]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  23%|██▎       | 57/250 [00:49<02:46,  1.16it/s, loss=0.661]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  23%|██▎       | 57/250 [00:50<02:46,  1.16it/s, loss=0.664]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  23%|██▎       | 58/250 [00:50<02:45,  1.16it/s, loss=0.664]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  23%|██▎       | 58/250 [00:50<02:45,  1.16it/s, loss=0.566]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  24%|██▎       | 59/250 [00:51<02:45,  1.15it/s, loss=0.566]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  24%|██▎       | 59/250 [00:51<02:45,  1.15it/s, loss=0.489]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  24%|██▍       | 60/250 [00:52<02:44,  1.15it/s, loss=0.489]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  24%|██▍       | 60/250 [00:52<02:44,  1.15it/s, loss=0.619]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  24%|██▍       | 61/250 [00:53<02:43,  1.16it/s, loss=0.619]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  24%|██▍       | 61/250 [00:53<02:43,  1.16it/s, loss=0.847]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  25%|██▍       | 62/250 [00:54<02:42,  1.16it/s, loss=0.847]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  25%|██▍       | 62/250 [00:54<02:42,  1.16it/s, loss=0.423]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  25%|██▌       | 63/250 [00:55<02:41,  1.16it/s, loss=0.423]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  25%|██▌       | 63/250 [00:55<02:41,  1.16it/s, loss=0.674]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  26%|██▌       | 64/250 [00:56<02:41,  1.16it/s, loss=0.674]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  26%|██▌       | 64/250 [00:56<02:41,  1.16it/s, loss=0.438]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  26%|██▌       | 65/250 [00:56<02:40,  1.15it/s, loss=0.438]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  26%|██▌       | 65/250 [00:56<02:40,  1.15it/s, loss=0.624]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  26%|██▋       | 66/250 [00:57<02:39,  1.15it/s, loss=0.624]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  26%|██▋       | 66/250 [00:57<02:39,  1.15it/s, loss=0.288]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  27%|██▋       | 67/250 [00:58<02:38,  1.15it/s, loss=0.288]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  27%|██▋       | 67/250 [00:58<02:38,  1.15it/s, loss=0.85] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  27%|██▋       | 68/250 [00:59<02:37,  1.15it/s, loss=0.85]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  27%|██▋       | 68/250 [00:59<02:37,  1.15it/s, loss=0.398]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  28%|██▊       | 69/250 [01:00<02:36,  1.15it/s, loss=0.398]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  28%|██▊       | 69/250 [01:00<02:36,  1.15it/s, loss=1.03] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  28%|██▊       | 70/250 [01:01<02:36,  1.15it/s, loss=1.03]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  28%|██▊       | 70/250 [01:01<02:36,  1.15it/s, loss=0.758]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  28%|██▊       | 71/250 [01:02<02:35,  1.15it/s, loss=0.758]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  28%|██▊       | 71/250 [01:02<02:35,  1.15it/s, loss=0.383]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  29%|██▉       | 72/250 [01:02<02:34,  1.15it/s, loss=0.383]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  29%|██▉       | 72/250 [01:02<02:34,  1.15it/s, loss=0.965]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  29%|██▉       | 73/250 [01:03<02:33,  1.16it/s, loss=0.965]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  29%|██▉       | 73/250 [01:03<02:33,  1.16it/s, loss=0.808]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  30%|██▉       | 74/250 [01:04<02:32,  1.15it/s, loss=0.808]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  30%|██▉       | 74/250 [01:04<02:32,  1.15it/s, loss=0.472]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  30%|███       | 75/250 [01:05<02:31,  1.15it/s, loss=0.472]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  30%|███       | 75/250 [01:05<02:31,  1.15it/s, loss=0.615]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  30%|███       | 76/250 [01:06<02:31,  1.15it/s, loss=0.615]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  30%|███       | 76/250 [01:06<02:31,  1.15it/s, loss=0.627]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  31%|███       | 77/250 [01:07<02:30,  1.15it/s, loss=0.627]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  31%|███       | 77/250 [01:07<02:30,  1.15it/s, loss=0.296]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  31%|███       | 78/250 [01:08<02:29,  1.15it/s, loss=0.296]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  31%|███       | 78/250 [01:08<02:29,  1.15it/s, loss=0.505]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  32%|███▏      | 79/250 [01:09<02:28,  1.15it/s, loss=0.505]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  32%|███▏      | 79/250 [01:09<02:28,  1.15it/s, loss=0.468]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  32%|███▏      | 80/250 [01:09<02:27,  1.15it/s, loss=0.468]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  32%|███▏      | 80/250 [01:09<02:27,  1.15it/s, loss=0.748]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  32%|███▏      | 81/250 [01:10<02:26,  1.15it/s, loss=0.748]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  32%|███▏      | 81/250 [01:10<02:26,  1.15it/s, loss=0.212]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  33%|███▎      | 82/250 [01:11<02:25,  1.15it/s, loss=0.212]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  33%|███▎      | 82/250 [01:11<02:25,  1.15it/s, loss=0.822]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  33%|███▎      | 83/250 [01:12<02:25,  1.15it/s, loss=0.822]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  33%|███▎      | 83/250 [01:12<02:25,  1.15it/s, loss=0.396]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  34%|███▎      | 84/250 [01:13<02:24,  1.15it/s, loss=0.396]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  34%|███▎      | 84/250 [01:13<02:24,  1.15it/s, loss=0.575]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  34%|███▍      | 85/250 [01:14<02:23,  1.15it/s, loss=0.575]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  34%|███▍      | 85/250 [01:14<02:23,  1.15it/s, loss=0.782]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  34%|███▍      | 86/250 [01:15<02:22,  1.15it/s, loss=0.782]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  34%|███▍      | 86/250 [01:15<02:22,  1.15it/s, loss=0.573]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  35%|███▍      | 87/250 [01:16<02:21,  1.15it/s, loss=0.573]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  35%|███▍      | 87/250 [01:16<02:21,  1.15it/s, loss=0.537]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  35%|███▌      | 88/250 [01:16<02:21,  1.15it/s, loss=0.537]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  35%|███▌      | 88/250 [01:16<02:21,  1.15it/s, loss=0.89] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  36%|███▌      | 89/250 [01:17<02:20,  1.15it/s, loss=0.89]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  36%|███▌      | 89/250 [01:17<02:20,  1.15it/s, loss=0.772]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  36%|███▌      | 90/250 [01:18<02:19,  1.15it/s, loss=0.772]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  36%|███▌      | 90/250 [01:18<02:19,  1.15it/s, loss=0.775]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  36%|███▋      | 91/250 [01:19<02:18,  1.15it/s, loss=0.775]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  36%|███▋      | 91/250 [01:19<02:18,  1.15it/s, loss=0.62] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  37%|███▋      | 92/250 [01:20<02:17,  1.15it/s, loss=0.62]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  37%|███▋      | 92/250 [01:20<02:17,  1.15it/s, loss=0.569]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  37%|███▋      | 93/250 [01:21<02:16,  1.15it/s, loss=0.569]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  37%|███▋      | 93/250 [01:21<02:16,  1.15it/s, loss=0.824]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  38%|███▊      | 94/250 [01:22<02:15,  1.15it/s, loss=0.824]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  38%|███▊      | 94/250 [01:22<02:15,  1.15it/s, loss=0.694]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  38%|███▊      | 95/250 [01:22<02:15,  1.15it/s, loss=0.694]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  38%|███▊      | 95/250 [01:23<02:15,  1.15it/s, loss=0.419]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  38%|███▊      | 96/250 [01:23<02:14,  1.15it/s, loss=0.419]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  38%|███▊      | 96/250 [01:23<02:14,  1.15it/s, loss=0.7]  \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  39%|███▉      | 97/250 [01:24<02:13,  1.15it/s, loss=0.7]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  39%|███▉      | 97/250 [01:24<02:13,  1.15it/s, loss=0.727]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  39%|███▉      | 98/250 [01:25<02:12,  1.15it/s, loss=0.727]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  39%|███▉      | 98/250 [01:25<02:12,  1.15it/s, loss=0.687]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  40%|███▉      | 99/250 [01:26<02:11,  1.15it/s, loss=0.687]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  40%|███▉      | 99/250 [01:26<02:11,  1.15it/s, loss=0.639]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  40%|████      | 100/250 [01:27<02:11,  1.14it/s, loss=0.639]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  40%|████      | 100/250 [01:27<02:11,  1.14it/s, loss=0.641]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  40%|████      | 101/250 [01:28<02:10,  1.14it/s, loss=0.641]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  40%|████      | 101/250 [01:28<02:10,  1.14it/s, loss=0.747]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  41%|████      | 102/250 [01:29<02:09,  1.15it/s, loss=0.747]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  41%|████      | 102/250 [01:29<02:09,  1.15it/s, loss=0.684]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  41%|████      | 103/250 [01:29<02:08,  1.15it/s, loss=0.684]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  41%|████      | 103/250 [01:29<02:08,  1.15it/s, loss=0.711]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  42%|████▏     | 104/250 [01:30<02:07,  1.15it/s, loss=0.711]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  42%|████▏     | 104/250 [01:30<02:07,  1.15it/s, loss=0.854]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  42%|████▏     | 105/250 [01:31<02:06,  1.14it/s, loss=0.854]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  42%|████▏     | 105/250 [01:31<02:06,  1.14it/s, loss=0.626]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  42%|████▏     | 106/250 [01:32<02:05,  1.14it/s, loss=0.626]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  42%|████▏     | 106/250 [01:32<02:05,  1.14it/s, loss=0.641]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  43%|████▎     | 107/250 [01:33<02:05,  1.14it/s, loss=0.641]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  43%|████▎     | 107/250 [01:33<02:05,  1.14it/s, loss=0.738]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  43%|████▎     | 108/250 [01:34<02:04,  1.14it/s, loss=0.738]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  43%|████▎     | 108/250 [01:34<02:04,  1.14it/s, loss=0.574]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  44%|████▎     | 109/250 [01:35<02:03,  1.15it/s, loss=0.574]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  44%|████▎     | 109/250 [01:35<02:03,  1.15it/s, loss=0.679]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  44%|████▍     | 110/250 [01:36<02:02,  1.15it/s, loss=0.679]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  44%|████▍     | 110/250 [01:36<02:02,  1.15it/s, loss=0.655]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  44%|████▍     | 111/250 [01:36<02:01,  1.15it/s, loss=0.655]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  44%|████▍     | 111/250 [01:36<02:01,  1.15it/s, loss=0.601]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  45%|████▍     | 112/250 [01:37<02:00,  1.15it/s, loss=0.601]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  45%|████▍     | 112/250 [01:37<02:00,  1.15it/s, loss=0.647]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  45%|████▌     | 113/250 [01:38<01:59,  1.15it/s, loss=0.647]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  45%|████▌     | 113/250 [01:38<01:59,  1.15it/s, loss=0.716]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  46%|████▌     | 114/250 [01:39<01:58,  1.14it/s, loss=0.716]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  46%|████▌     | 114/250 [01:39<01:58,  1.14it/s, loss=0.859]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  46%|████▌     | 115/250 [01:40<01:57,  1.14it/s, loss=0.859]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  46%|████▌     | 115/250 [01:40<01:57,  1.14it/s, loss=0.744]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  46%|████▋     | 116/250 [01:41<01:57,  1.14it/s, loss=0.744]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  46%|████▋     | 116/250 [01:41<01:57,  1.14it/s, loss=0.59] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  47%|████▋     | 117/250 [01:42<01:56,  1.15it/s, loss=0.59]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  47%|████▋     | 117/250 [01:42<01:56,  1.15it/s, loss=0.516]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  47%|████▋     | 118/250 [01:43<01:55,  1.15it/s, loss=0.516]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  47%|████▋     | 118/250 [01:43<01:55,  1.15it/s, loss=0.457]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  48%|████▊     | 119/250 [01:43<01:54,  1.15it/s, loss=0.457]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  48%|████▊     | 119/250 [01:43<01:54,  1.15it/s, loss=0.477]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  48%|████▊     | 120/250 [01:44<01:53,  1.15it/s, loss=0.477]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  48%|████▊     | 120/250 [01:44<01:53,  1.15it/s, loss=1.16] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  48%|████▊     | 121/250 [01:45<01:52,  1.15it/s, loss=1.16]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  48%|████▊     | 121/250 [01:45<01:52,  1.15it/s, loss=0.794]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  49%|████▉     | 122/250 [01:46<01:51,  1.15it/s, loss=0.794]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  49%|████▉     | 122/250 [01:46<01:51,  1.15it/s, loss=0.673]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  49%|████▉     | 123/250 [01:47<01:50,  1.15it/s, loss=0.673]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  49%|████▉     | 123/250 [01:47<01:50,  1.15it/s, loss=0.495]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  50%|████▉     | 124/250 [01:48<01:49,  1.15it/s, loss=0.495]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  50%|████▉     | 124/250 [01:48<01:49,  1.15it/s, loss=0.659]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  50%|█████     | 125/250 [01:49<01:48,  1.15it/s, loss=0.659]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  50%|█████     | 125/250 [01:49<01:48,  1.15it/s, loss=0.662]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  50%|█████     | 126/250 [01:50<01:48,  1.15it/s, loss=0.662]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  50%|█████     | 126/250 [01:50<01:48,  1.15it/s, loss=0.668]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  51%|█████     | 127/250 [01:50<01:47,  1.15it/s, loss=0.668]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  51%|█████     | 127/250 [01:50<01:47,  1.15it/s, loss=0.596]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  51%|█████     | 128/250 [01:51<01:46,  1.15it/s, loss=0.596]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  51%|█████     | 128/250 [01:51<01:46,  1.15it/s, loss=0.601]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  52%|█████▏    | 129/250 [01:52<01:45,  1.15it/s, loss=0.601]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  52%|█████▏    | 129/250 [01:52<01:45,  1.15it/s, loss=0.628]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  52%|█████▏    | 130/250 [01:53<01:44,  1.15it/s, loss=0.628]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  52%|█████▏    | 130/250 [01:53<01:44,  1.15it/s, loss=0.604]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  52%|█████▏    | 131/250 [01:54<01:43,  1.15it/s, loss=0.604]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  52%|█████▏    | 131/250 [01:54<01:43,  1.15it/s, loss=0.924]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  53%|█████▎    | 132/250 [01:55<01:42,  1.15it/s, loss=0.924]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  53%|█████▎    | 132/250 [01:55<01:42,  1.15it/s, loss=0.606]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  53%|█████▎    | 133/250 [01:56<01:42,  1.15it/s, loss=0.606]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  53%|█████▎    | 133/250 [01:56<01:42,  1.15it/s, loss=0.834]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  54%|█████▎    | 134/250 [01:57<01:41,  1.15it/s, loss=0.834]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  54%|█████▎    | 134/250 [01:57<01:41,  1.15it/s, loss=0.762]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  54%|█████▍    | 135/250 [01:57<01:40,  1.15it/s, loss=0.762]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  54%|█████▍    | 135/250 [01:57<01:40,  1.15it/s, loss=0.681]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  54%|█████▍    | 136/250 [01:58<01:39,  1.15it/s, loss=0.681]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  54%|█████▍    | 136/250 [01:58<01:39,  1.15it/s, loss=0.624]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  55%|█████▍    | 137/250 [01:59<01:38,  1.15it/s, loss=0.624]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  55%|█████▍    | 137/250 [01:59<01:38,  1.15it/s, loss=0.569]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  55%|█████▌    | 138/250 [02:00<01:37,  1.15it/s, loss=0.569]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  55%|█████▌    | 138/250 [02:00<01:37,  1.15it/s, loss=0.66] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  56%|█████▌    | 139/250 [02:01<01:36,  1.15it/s, loss=0.66]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  56%|█████▌    | 139/250 [02:01<01:36,  1.15it/s, loss=0.509]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  56%|█████▌    | 140/250 [02:02<01:35,  1.15it/s, loss=0.509]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  56%|█████▌    | 140/250 [02:02<01:35,  1.15it/s, loss=0.55] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  56%|█████▋    | 141/250 [02:03<01:34,  1.15it/s, loss=0.55]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  56%|█████▋    | 141/250 [02:03<01:34,  1.15it/s, loss=0.638]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  57%|█████▋    | 142/250 [02:03<01:33,  1.15it/s, loss=0.638]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  57%|█████▋    | 142/250 [02:04<01:33,  1.15it/s, loss=0.755]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  57%|█████▋    | 143/250 [02:04<01:33,  1.15it/s, loss=0.755]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  57%|█████▋    | 143/250 [02:04<01:33,  1.15it/s, loss=0.547]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  58%|█████▊    | 144/250 [02:05<01:32,  1.15it/s, loss=0.547]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  58%|█████▊    | 144/250 [02:05<01:32,  1.15it/s, loss=0.523]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  58%|█████▊    | 145/250 [02:06<01:31,  1.15it/s, loss=0.523]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  58%|█████▊    | 145/250 [02:06<01:31,  1.15it/s, loss=0.666]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  58%|█████▊    | 146/250 [02:07<01:30,  1.15it/s, loss=0.666]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  58%|█████▊    | 146/250 [02:07<01:30,  1.15it/s, loss=0.811]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  59%|█████▉    | 147/250 [02:08<01:29,  1.15it/s, loss=0.811]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  59%|█████▉    | 147/250 [02:08<01:29,  1.15it/s, loss=0.41] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  59%|█████▉    | 148/250 [02:09<01:28,  1.15it/s, loss=0.41]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  59%|█████▉    | 148/250 [02:09<01:28,  1.15it/s, loss=0.701]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  60%|█████▉    | 149/250 [02:10<01:27,  1.15it/s, loss=0.701]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  60%|█████▉    | 149/250 [02:10<01:27,  1.15it/s, loss=0.73] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  60%|██████    | 150/250 [02:10<01:26,  1.15it/s, loss=0.73]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  60%|██████    | 150/250 [02:10<01:26,  1.15it/s, loss=0.556]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  60%|██████    | 151/250 [02:11<01:26,  1.15it/s, loss=0.556]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  60%|██████    | 151/250 [02:11<01:26,  1.15it/s, loss=0.34] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  61%|██████    | 152/250 [02:12<01:25,  1.15it/s, loss=0.34]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  61%|██████    | 152/250 [02:12<01:25,  1.15it/s, loss=0.58]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  61%|██████    | 153/250 [02:13<01:24,  1.15it/s, loss=0.58]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  61%|██████    | 153/250 [02:13<01:24,  1.15it/s, loss=0.593]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  62%|██████▏   | 154/250 [02:14<01:23,  1.15it/s, loss=0.593]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  62%|██████▏   | 154/250 [02:14<01:23,  1.15it/s, loss=0.971]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  62%|██████▏   | 155/250 [02:15<01:22,  1.15it/s, loss=0.971]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  62%|██████▏   | 155/250 [02:15<01:22,  1.15it/s, loss=0.931]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  62%|██████▏   | 156/250 [02:16<01:21,  1.15it/s, loss=0.931]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  62%|██████▏   | 156/250 [02:16<01:21,  1.15it/s, loss=0.518]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  63%|██████▎   | 157/250 [02:17<01:20,  1.15it/s, loss=0.518]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  63%|██████▎   | 157/250 [02:17<01:20,  1.15it/s, loss=0.534]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  63%|██████▎   | 158/250 [02:17<01:20,  1.15it/s, loss=0.534]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  63%|██████▎   | 158/250 [02:17<01:20,  1.15it/s, loss=0.722]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  64%|██████▎   | 159/250 [02:18<01:19,  1.15it/s, loss=0.722]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  64%|██████▎   | 159/250 [02:18<01:19,  1.15it/s, loss=0.722]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  64%|██████▍   | 160/250 [02:19<01:18,  1.15it/s, loss=0.722]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  64%|██████▍   | 160/250 [02:19<01:18,  1.15it/s, loss=0.454]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  64%|██████▍   | 161/250 [02:20<01:17,  1.15it/s, loss=0.454]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  64%|██████▍   | 161/250 [02:20<01:17,  1.15it/s, loss=0.741]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  65%|██████▍   | 162/250 [02:21<01:16,  1.15it/s, loss=0.741]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  65%|██████▍   | 162/250 [02:21<01:16,  1.15it/s, loss=0.553]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  65%|██████▌   | 163/250 [02:22<01:15,  1.15it/s, loss=0.553]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  65%|██████▌   | 163/250 [02:22<01:15,  1.15it/s, loss=0.398]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  66%|██████▌   | 164/250 [02:23<01:14,  1.15it/s, loss=0.398]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  66%|██████▌   | 164/250 [02:23<01:14,  1.15it/s, loss=0.545]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  66%|██████▌   | 165/250 [02:24<01:14,  1.15it/s, loss=0.545]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  66%|██████▌   | 165/250 [02:24<01:14,  1.15it/s, loss=0.941]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  66%|██████▋   | 166/250 [02:24<01:13,  1.15it/s, loss=0.941]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  66%|██████▋   | 166/250 [02:24<01:13,  1.15it/s, loss=0.32] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  67%|██████▋   | 167/250 [02:25<01:12,  1.15it/s, loss=0.32]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  67%|██████▋   | 167/250 [02:25<01:12,  1.15it/s, loss=0.437]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  67%|██████▋   | 168/250 [02:26<01:11,  1.15it/s, loss=0.437]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  67%|██████▋   | 168/250 [02:26<01:11,  1.15it/s, loss=0.591]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  68%|██████▊   | 169/250 [02:27<01:10,  1.15it/s, loss=0.591]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  68%|██████▊   | 169/250 [02:27<01:10,  1.15it/s, loss=0.439]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  68%|██████▊   | 170/250 [02:28<01:09,  1.15it/s, loss=0.439]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  68%|██████▊   | 170/250 [02:28<01:09,  1.15it/s, loss=0.855]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  68%|██████▊   | 171/250 [02:29<01:08,  1.15it/s, loss=0.855]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  68%|██████▊   | 171/250 [02:29<01:08,  1.15it/s, loss=0.681]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  69%|██████▉   | 172/250 [02:30<01:07,  1.15it/s, loss=0.681]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  69%|██████▉   | 172/250 [02:30<01:07,  1.15it/s, loss=0.85] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  69%|██████▉   | 173/250 [02:30<01:06,  1.15it/s, loss=0.85]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  69%|██████▉   | 173/250 [02:31<01:06,  1.15it/s, loss=0.491]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  70%|██████▉   | 174/250 [02:31<01:06,  1.15it/s, loss=0.491]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  70%|██████▉   | 174/250 [02:31<01:06,  1.15it/s, loss=0.384]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  70%|███████   | 175/250 [02:32<01:05,  1.15it/s, loss=0.384]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  70%|███████   | 175/250 [02:32<01:05,  1.15it/s, loss=0.525]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  70%|███████   | 176/250 [02:33<01:04,  1.15it/s, loss=0.525]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  70%|███████   | 176/250 [02:33<01:04,  1.15it/s, loss=0.446]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  71%|███████   | 177/250 [02:34<01:03,  1.15it/s, loss=0.446]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  71%|███████   | 177/250 [02:34<01:03,  1.15it/s, loss=0.392]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  71%|███████   | 178/250 [02:35<01:02,  1.15it/s, loss=0.392]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  71%|███████   | 178/250 [02:35<01:02,  1.15it/s, loss=0.352]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  72%|███████▏  | 179/250 [02:36<01:01,  1.15it/s, loss=0.352]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  72%|███████▏  | 179/250 [02:36<01:01,  1.15it/s, loss=0.535]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  72%|███████▏  | 180/250 [02:37<01:00,  1.15it/s, loss=0.535]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  72%|███████▏  | 180/250 [02:37<01:00,  1.15it/s, loss=0.626]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  72%|███████▏  | 181/250 [02:37<01:00,  1.15it/s, loss=0.626]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  72%|███████▏  | 181/250 [02:37<01:00,  1.15it/s, loss=0.375]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  73%|███████▎  | 182/250 [02:38<00:59,  1.15it/s, loss=0.375]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  73%|███████▎  | 182/250 [02:38<00:59,  1.15it/s, loss=1.22] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  73%|███████▎  | 183/250 [02:39<00:58,  1.15it/s, loss=1.22]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  73%|███████▎  | 183/250 [02:39<00:58,  1.15it/s, loss=1.14]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  74%|███████▎  | 184/250 [02:40<00:57,  1.15it/s, loss=1.14]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  74%|███████▎  | 184/250 [02:40<00:57,  1.15it/s, loss=0.819]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  74%|███████▍  | 185/250 [02:41<00:56,  1.15it/s, loss=0.819]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  74%|███████▍  | 185/250 [02:41<00:56,  1.15it/s, loss=0.756]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  74%|███████▍  | 186/250 [02:42<00:55,  1.15it/s, loss=0.756]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  74%|███████▍  | 186/250 [02:42<00:55,  1.15it/s, loss=0.373]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  75%|███████▍  | 187/250 [02:43<00:54,  1.15it/s, loss=0.373]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  75%|███████▍  | 187/250 [02:43<00:54,  1.15it/s, loss=0.427]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  75%|███████▌  | 188/250 [02:44<00:53,  1.15it/s, loss=0.427]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  75%|███████▌  | 188/250 [02:44<00:53,  1.15it/s, loss=0.621]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  76%|███████▌  | 189/250 [02:44<00:53,  1.15it/s, loss=0.621]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  76%|███████▌  | 189/250 [02:44<00:53,  1.15it/s, loss=0.977]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  76%|███████▌  | 190/250 [02:45<00:52,  1.15it/s, loss=0.977]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  76%|███████▌  | 190/250 [02:45<00:52,  1.15it/s, loss=0.433]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  76%|███████▋  | 191/250 [02:46<00:51,  1.15it/s, loss=0.433]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  76%|███████▋  | 191/250 [02:46<00:51,  1.15it/s, loss=0.349]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  77%|███████▋  | 192/250 [02:47<00:50,  1.15it/s, loss=0.349]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  77%|███████▋  | 192/250 [02:47<00:50,  1.15it/s, loss=0.432]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  77%|███████▋  | 193/250 [02:48<00:49,  1.15it/s, loss=0.432]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  77%|███████▋  | 193/250 [02:48<00:49,  1.15it/s, loss=0.893]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  78%|███████▊  | 194/250 [02:49<00:48,  1.15it/s, loss=0.893]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  78%|███████▊  | 194/250 [02:49<00:48,  1.15it/s, loss=0.713]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  78%|███████▊  | 195/250 [02:50<00:47,  1.15it/s, loss=0.713]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  78%|███████▊  | 195/250 [02:50<00:47,  1.15it/s, loss=0.446]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  78%|███████▊  | 196/250 [02:51<00:46,  1.15it/s, loss=0.446]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  78%|███████▊  | 196/250 [02:51<00:46,  1.15it/s, loss=0.904]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  79%|███████▉  | 197/250 [02:51<00:46,  1.15it/s, loss=0.904]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  79%|███████▉  | 197/250 [02:51<00:46,  1.15it/s, loss=0.627]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  79%|███████▉  | 198/250 [02:52<00:45,  1.15it/s, loss=0.627]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  79%|███████▉  | 198/250 [02:52<00:45,  1.15it/s, loss=0.599]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  80%|███████▉  | 199/250 [02:53<00:44,  1.15it/s, loss=0.599]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  80%|███████▉  | 199/250 [02:53<00:44,  1.15it/s, loss=0.448]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  80%|████████  | 200/250 [02:54<00:43,  1.15it/s, loss=0.448]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  80%|████████  | 200/250 [02:54<00:43,  1.15it/s, loss=0.494]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  80%|████████  | 201/250 [02:55<00:42,  1.15it/s, loss=0.494]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  80%|████████  | 201/250 [02:55<00:42,  1.15it/s, loss=0.511]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  81%|████████  | 202/250 [02:56<00:41,  1.15it/s, loss=0.511]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  81%|████████  | 202/250 [02:56<00:41,  1.15it/s, loss=0.768]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  81%|████████  | 203/250 [02:57<00:40,  1.15it/s, loss=0.768]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  81%|████████  | 203/250 [02:57<00:40,  1.15it/s, loss=0.659]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  82%|████████▏ | 204/250 [02:57<00:39,  1.15it/s, loss=0.659]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  82%|████████▏ | 204/250 [02:57<00:39,  1.15it/s, loss=0.511]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  82%|████████▏ | 205/250 [02:58<00:39,  1.15it/s, loss=0.511]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  82%|████████▏ | 205/250 [02:58<00:39,  1.15it/s, loss=0.597]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  82%|████████▏ | 206/250 [02:59<00:38,  1.15it/s, loss=0.597]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  82%|████████▏ | 206/250 [02:59<00:38,  1.15it/s, loss=0.753]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  83%|████████▎ | 207/250 [03:00<00:37,  1.15it/s, loss=0.753]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  83%|████████▎ | 207/250 [03:00<00:37,  1.15it/s, loss=0.543]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  83%|████████▎ | 208/250 [03:01<00:36,  1.15it/s, loss=0.543]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  83%|████████▎ | 208/250 [03:01<00:36,  1.15it/s, loss=0.667]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  84%|████████▎ | 209/250 [03:02<00:35,  1.15it/s, loss=0.667]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  84%|████████▎ | 209/250 [03:02<00:35,  1.15it/s, loss=0.681]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  84%|████████▍ | 210/250 [03:03<00:34,  1.15it/s, loss=0.681]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  84%|████████▍ | 210/250 [03:03<00:34,  1.15it/s, loss=0.73] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  84%|████████▍ | 211/250 [03:04<00:33,  1.15it/s, loss=0.73]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  84%|████████▍ | 211/250 [03:04<00:33,  1.15it/s, loss=0.427]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  85%|████████▍ | 212/250 [03:04<00:32,  1.15it/s, loss=0.427]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  85%|████████▍ | 212/250 [03:04<00:32,  1.15it/s, loss=0.535]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  85%|████████▌ | 213/250 [03:05<00:32,  1.15it/s, loss=0.535]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  85%|████████▌ | 213/250 [03:05<00:32,  1.15it/s, loss=0.362]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  86%|████████▌ | 214/250 [03:06<00:31,  1.15it/s, loss=0.362]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  86%|████████▌ | 214/250 [03:06<00:31,  1.15it/s, loss=1.14] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  86%|████████▌ | 215/250 [03:07<00:30,  1.15it/s, loss=1.14]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  86%|████████▌ | 215/250 [03:07<00:30,  1.15it/s, loss=0.481]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  86%|████████▋ | 216/250 [03:08<00:29,  1.15it/s, loss=0.481]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  86%|████████▋ | 216/250 [03:08<00:29,  1.15it/s, loss=0.869]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  87%|████████▋ | 217/250 [03:09<00:28,  1.15it/s, loss=0.869]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  87%|████████▋ | 217/250 [03:09<00:28,  1.15it/s, loss=0.946]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  87%|████████▋ | 218/250 [03:10<00:27,  1.15it/s, loss=0.946]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  87%|████████▋ | 218/250 [03:10<00:27,  1.15it/s, loss=0.539]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  88%|████████▊ | 219/250 [03:11<00:26,  1.15it/s, loss=0.539]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  88%|████████▊ | 219/250 [03:11<00:26,  1.15it/s, loss=0.41] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  88%|████████▊ | 220/250 [03:11<00:26,  1.15it/s, loss=0.41]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  88%|████████▊ | 220/250 [03:11<00:26,  1.15it/s, loss=0.653]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  88%|████████▊ | 221/250 [03:12<00:25,  1.15it/s, loss=0.653]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  88%|████████▊ | 221/250 [03:12<00:25,  1.15it/s, loss=0.66] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  89%|████████▉ | 222/250 [03:13<00:24,  1.15it/s, loss=0.66]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  89%|████████▉ | 222/250 [03:13<00:24,  1.15it/s, loss=0.362]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  89%|████████▉ | 223/250 [03:14<00:23,  1.15it/s, loss=0.362]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  89%|████████▉ | 223/250 [03:14<00:23,  1.15it/s, loss=0.719]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  90%|████████▉ | 224/250 [03:15<00:22,  1.15it/s, loss=0.719]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  90%|████████▉ | 224/250 [03:15<00:22,  1.15it/s, loss=0.76] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  90%|█████████ | 225/250 [03:16<00:21,  1.15it/s, loss=0.76]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  90%|█████████ | 225/250 [03:16<00:21,  1.15it/s, loss=0.636]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  90%|█████████ | 226/250 [03:17<00:20,  1.15it/s, loss=0.636]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  90%|█████████ | 226/250 [03:17<00:20,  1.15it/s, loss=0.653]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  91%|█████████ | 227/250 [03:17<00:20,  1.15it/s, loss=0.653]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  91%|█████████ | 227/250 [03:17<00:20,  1.15it/s, loss=0.687]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  91%|█████████ | 228/250 [03:18<00:19,  1.15it/s, loss=0.687]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  91%|█████████ | 228/250 [03:18<00:19,  1.15it/s, loss=0.507]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  92%|█████████▏| 229/250 [03:19<00:18,  1.15it/s, loss=0.507]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  92%|█████████▏| 229/250 [03:19<00:18,  1.15it/s, loss=0.705]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  92%|█████████▏| 230/250 [03:20<00:17,  1.15it/s, loss=0.705]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  92%|█████████▏| 230/250 [03:20<00:17,  1.15it/s, loss=0.71] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  92%|█████████▏| 231/250 [03:21<00:16,  1.15it/s, loss=0.71]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  92%|█████████▏| 231/250 [03:21<00:16,  1.15it/s, loss=0.423]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  93%|█████████▎| 232/250 [03:22<00:15,  1.15it/s, loss=0.423]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  93%|█████████▎| 232/250 [03:22<00:15,  1.15it/s, loss=0.761]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  93%|█████████▎| 233/250 [03:23<00:14,  1.15it/s, loss=0.761]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  93%|█████████▎| 233/250 [03:23<00:14,  1.15it/s, loss=0.54] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  94%|█████████▎| 234/250 [03:24<00:13,  1.15it/s, loss=0.54]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  94%|█████████▎| 234/250 [03:24<00:13,  1.15it/s, loss=0.58]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  94%|█████████▍| 235/250 [03:24<00:13,  1.15it/s, loss=0.58]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  94%|█████████▍| 235/250 [03:24<00:13,  1.15it/s, loss=0.843]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  94%|█████████▍| 236/250 [03:25<00:12,  1.15it/s, loss=0.843]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  94%|█████████▍| 236/250 [03:25<00:12,  1.15it/s, loss=0.536]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  95%|█████████▍| 237/250 [03:26<00:11,  1.15it/s, loss=0.536]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  95%|█████████▍| 237/250 [03:26<00:11,  1.15it/s, loss=0.601]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  95%|█████████▌| 238/250 [03:27<00:10,  1.15it/s, loss=0.601]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  95%|█████████▌| 238/250 [03:27<00:10,  1.15it/s, loss=0.722]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  96%|█████████▌| 239/250 [03:28<00:09,  1.15it/s, loss=0.722]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  96%|█████████▌| 239/250 [03:28<00:09,  1.15it/s, loss=0.643]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  96%|█████████▌| 240/250 [03:29<00:08,  1.15it/s, loss=0.643]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  96%|█████████▌| 240/250 [03:29<00:08,  1.15it/s, loss=0.57] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  96%|█████████▋| 241/250 [03:30<00:07,  1.15it/s, loss=0.57]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  96%|█████████▋| 241/250 [03:30<00:07,  1.15it/s, loss=0.592]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  97%|█████████▋| 242/250 [03:31<00:06,  1.15it/s, loss=0.592]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  97%|█████████▋| 242/250 [03:31<00:06,  1.15it/s, loss=0.74] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  97%|█████████▋| 243/250 [03:31<00:06,  1.15it/s, loss=0.74]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  97%|█████████▋| 243/250 [03:31<00:06,  1.15it/s, loss=0.574]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  98%|█████████▊| 244/250 [03:32<00:05,  1.15it/s, loss=0.574]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  98%|█████████▊| 244/250 [03:32<00:05,  1.15it/s, loss=0.642]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  98%|█████████▊| 245/250 [03:33<00:04,  1.15it/s, loss=0.642]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  98%|█████████▊| 245/250 [03:33<00:04,  1.15it/s, loss=0.729]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  98%|█████████▊| 246/250 [03:34<00:03,  1.15it/s, loss=0.729]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  98%|█████████▊| 246/250 [03:34<00:03,  1.15it/s, loss=0.819]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  99%|█████████▉| 247/250 [03:35<00:02,  1.15it/s, loss=0.819]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  99%|█████████▉| 247/250 [03:35<00:02,  1.15it/s, loss=0.341]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  99%|█████████▉| 248/250 [03:36<00:01,  1.15it/s, loss=0.341]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  99%|█████████▉| 248/250 [03:36<00:01,  1.15it/s, loss=1.33] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0: 100%|█████████▉| 249/250 [03:37<00:00,  1.15it/s, loss=1.33]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0: 100%|█████████▉| 249/250 [03:37<00:00,  1.15it/s, loss=0.676]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0: 100%|██████████| 250/250 [03:37<00:00,  1.15it/s, loss=0.676]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0: 100%|██████████| 250/250 [03:38<00:00,  1.15it/s, loss=0.499]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Train epoch:  33%|███▎      | 1/3 [03:52<07:44, 232.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0: 100%|██████████| 250/250 [03:52<00:00,  1.08it/s, loss=0.625, dist_mean=0.319]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Train step of epoch 1:   0%|          | 0/250 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   0%|          | 1/250 [00:00<03:31,  1.18it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   0%|          | 1/250 [00:00<03:31,  1.18it/s, loss=0.464]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   1%|          | 2/250 [00:01<03:34,  1.16it/s, loss=0.464]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   1%|          | 2/250 [00:01<03:34,  1.16it/s, loss=0.423]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   1%|          | 3/250 [00:02<03:34,  1.15it/s, loss=0.423]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   1%|          | 3/250 [00:02<03:34,  1.15it/s, loss=0.492]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   2%|▏         | 4/250 [00:03<03:33,  1.15it/s, loss=0.492]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   2%|▏         | 4/250 [00:03<03:33,  1.15it/s, loss=0.478]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   2%|▏         | 5/250 [00:04<03:33,  1.15it/s, loss=0.478]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   2%|▏         | 5/250 [00:04<03:33,  1.15it/s, loss=0.412]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   2%|▏         | 6/250 [00:05<03:32,  1.15it/s, loss=0.412]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   2%|▏         | 6/250 [00:05<03:32,  1.15it/s, loss=0.362]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   3%|▎         | 7/250 [00:06<03:31,  1.15it/s, loss=0.362]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   3%|▎         | 7/250 [00:06<03:31,  1.15it/s, loss=0.406]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   3%|▎         | 8/250 [00:06<03:30,  1.15it/s, loss=0.406]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   3%|▎         | 8/250 [00:06<03:30,  1.15it/s, loss=0.441]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   4%|▎         | 9/250 [00:07<03:30,  1.15it/s, loss=0.441]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   4%|▎         | 9/250 [00:07<03:30,  1.15it/s, loss=0.44] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   4%|▍         | 10/250 [00:08<03:29,  1.15it/s, loss=0.44]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   4%|▍         | 10/250 [00:08<03:29,  1.15it/s, loss=0.331]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   4%|▍         | 11/250 [00:09<03:28,  1.15it/s, loss=0.331]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   4%|▍         | 11/250 [00:09<03:28,  1.15it/s, loss=0.367]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   5%|▍         | 12/250 [00:10<03:27,  1.15it/s, loss=0.367]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   5%|▍         | 12/250 [00:10<03:27,  1.15it/s, loss=0.385]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   5%|▌         | 13/250 [00:11<03:26,  1.15it/s, loss=0.385]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   5%|▌         | 13/250 [00:11<03:26,  1.15it/s, loss=0.0917]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   6%|▌         | 14/250 [00:12<03:25,  1.15it/s, loss=0.0917]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   6%|▌         | 14/250 [00:12<03:25,  1.15it/s, loss=0.729] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   6%|▌         | 15/250 [00:13<03:24,  1.15it/s, loss=0.729]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   6%|▌         | 15/250 [00:13<03:24,  1.15it/s, loss=0.293]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   6%|▋         | 16/250 [00:13<03:24,  1.15it/s, loss=0.293]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   6%|▋         | 16/250 [00:13<03:24,  1.15it/s, loss=0.409]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   7%|▋         | 17/250 [00:14<03:23,  1.15it/s, loss=0.409]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   7%|▋         | 17/250 [00:14<03:23,  1.15it/s, loss=0.423]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   7%|▋         | 18/250 [00:15<03:22,  1.15it/s, loss=0.423]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   7%|▋         | 18/250 [00:15<03:22,  1.15it/s, loss=0.121]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   8%|▊         | 19/250 [00:16<03:21,  1.15it/s, loss=0.121]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   8%|▊         | 19/250 [00:16<03:21,  1.15it/s, loss=0.912]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   8%|▊         | 20/250 [00:17<03:20,  1.15it/s, loss=0.912]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   8%|▊         | 20/250 [00:17<03:20,  1.15it/s, loss=0.0899]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   8%|▊         | 21/250 [00:18<03:19,  1.15it/s, loss=0.0899]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   8%|▊         | 21/250 [00:18<03:19,  1.15it/s, loss=1.08]  \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   9%|▉         | 22/250 [00:19<03:18,  1.15it/s, loss=1.08]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   9%|▉         | 22/250 [00:19<03:18,  1.15it/s, loss=1.22]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   9%|▉         | 23/250 [00:20<03:18,  1.15it/s, loss=1.22]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:   9%|▉         | 23/250 [00:20<03:18,  1.15it/s, loss=0.674]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  10%|▉         | 24/250 [00:20<03:17,  1.15it/s, loss=0.674]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  10%|▉         | 24/250 [00:20<03:17,  1.15it/s, loss=0.573]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  10%|█         | 25/250 [00:21<03:16,  1.15it/s, loss=0.573]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  10%|█         | 25/250 [00:21<03:16,  1.15it/s, loss=0.258]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  10%|█         | 26/250 [00:22<03:15,  1.15it/s, loss=0.258]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  10%|█         | 26/250 [00:22<03:15,  1.15it/s, loss=0.79] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  11%|█         | 27/250 [00:23<03:14,  1.15it/s, loss=0.79]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  11%|█         | 27/250 [00:23<03:14,  1.15it/s, loss=0.556]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  11%|█         | 28/250 [00:24<03:13,  1.15it/s, loss=0.556]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  11%|█         | 28/250 [00:24<03:13,  1.15it/s, loss=0.297]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  12%|█▏        | 29/250 [00:25<03:12,  1.15it/s, loss=0.297]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  12%|█▏        | 29/250 [00:25<03:12,  1.15it/s, loss=0.371]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  12%|█▏        | 30/250 [00:26<03:12,  1.14it/s, loss=0.371]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  12%|█▏        | 30/250 [00:26<03:12,  1.14it/s, loss=0.287]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  12%|█▏        | 31/250 [00:27<03:11,  1.14it/s, loss=0.287]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  12%|█▏        | 31/250 [00:27<03:11,  1.14it/s, loss=0.238]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  13%|█▎        | 32/250 [00:27<03:10,  1.14it/s, loss=0.238]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  13%|█▎        | 32/250 [00:27<03:10,  1.14it/s, loss=0.994]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  13%|█▎        | 33/250 [00:28<03:09,  1.14it/s, loss=0.994]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  13%|█▎        | 33/250 [00:28<03:09,  1.14it/s, loss=0.382]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  14%|█▎        | 34/250 [00:29<03:08,  1.14it/s, loss=0.382]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  14%|█▎        | 34/250 [00:29<03:08,  1.14it/s, loss=0.575]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  14%|█▍        | 35/250 [00:30<03:07,  1.14it/s, loss=0.575]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  14%|█▍        | 35/250 [00:30<03:07,  1.14it/s, loss=0.524]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  14%|█▍        | 36/250 [00:31<03:06,  1.15it/s, loss=0.524]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  14%|█▍        | 36/250 [00:31<03:06,  1.15it/s, loss=0.694]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  15%|█▍        | 37/250 [00:32<03:06,  1.15it/s, loss=0.694]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  15%|█▍        | 37/250 [00:32<03:06,  1.15it/s, loss=0.734]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  15%|█▌        | 38/250 [00:33<03:05,  1.14it/s, loss=0.734]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  15%|█▌        | 38/250 [00:33<03:05,  1.14it/s, loss=0.462]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  16%|█▌        | 39/250 [00:33<03:04,  1.15it/s, loss=0.462]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  16%|█▌        | 39/250 [00:34<03:04,  1.15it/s, loss=0.779]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  16%|█▌        | 40/250 [00:34<03:03,  1.15it/s, loss=0.779]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  16%|█▌        | 40/250 [00:34<03:03,  1.15it/s, loss=0.427]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  16%|█▋        | 41/250 [00:35<03:02,  1.15it/s, loss=0.427]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  16%|█▋        | 41/250 [00:35<03:02,  1.15it/s, loss=0.279]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  17%|█▋        | 42/250 [00:36<03:01,  1.15it/s, loss=0.279]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  17%|█▋        | 42/250 [00:36<03:01,  1.15it/s, loss=0.456]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  17%|█▋        | 43/250 [00:37<03:00,  1.15it/s, loss=0.456]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  17%|█▋        | 43/250 [00:37<03:00,  1.15it/s, loss=0.367]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  18%|█▊        | 44/250 [00:38<02:59,  1.15it/s, loss=0.367]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  18%|█▊        | 44/250 [00:38<02:59,  1.15it/s, loss=0.72] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  18%|█▊        | 45/250 [00:39<02:58,  1.15it/s, loss=0.72]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  18%|█▊        | 45/250 [00:39<02:58,  1.15it/s, loss=0.51]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  18%|█▊        | 46/250 [00:40<02:58,  1.15it/s, loss=0.51]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  18%|█▊        | 46/250 [00:40<02:58,  1.15it/s, loss=0.483]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  19%|█▉        | 47/250 [00:40<02:57,  1.15it/s, loss=0.483]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  19%|█▉        | 47/250 [00:40<02:57,  1.15it/s, loss=0.488]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  19%|█▉        | 48/250 [00:41<02:56,  1.15it/s, loss=0.488]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  19%|█▉        | 48/250 [00:41<02:56,  1.15it/s, loss=0.721]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  20%|█▉        | 49/250 [00:42<02:55,  1.14it/s, loss=0.721]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  20%|█▉        | 49/250 [00:42<02:55,  1.14it/s, loss=0.386]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  20%|██        | 50/250 [00:43<02:54,  1.15it/s, loss=0.386]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  20%|██        | 50/250 [00:43<02:54,  1.15it/s, loss=1.02] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  20%|██        | 51/250 [00:44<02:53,  1.15it/s, loss=1.02]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  20%|██        | 51/250 [00:44<02:53,  1.15it/s, loss=0.346]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  21%|██        | 52/250 [00:45<02:52,  1.15it/s, loss=0.346]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  21%|██        | 52/250 [00:45<02:52,  1.15it/s, loss=0.622]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  21%|██        | 53/250 [00:46<02:51,  1.15it/s, loss=0.622]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  21%|██        | 53/250 [00:46<02:51,  1.15it/s, loss=0.58] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  22%|██▏       | 54/250 [00:47<02:51,  1.15it/s, loss=0.58]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  22%|██▏       | 54/250 [00:47<02:51,  1.15it/s, loss=0.134]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  22%|██▏       | 55/250 [00:47<02:50,  1.14it/s, loss=0.134]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  22%|██▏       | 55/250 [00:47<02:50,  1.14it/s, loss=0.308]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  22%|██▏       | 56/250 [00:48<02:49,  1.14it/s, loss=0.308]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  22%|██▏       | 56/250 [00:48<02:49,  1.14it/s, loss=0.553]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  23%|██▎       | 57/250 [00:49<02:48,  1.14it/s, loss=0.553]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  23%|██▎       | 57/250 [00:49<02:48,  1.14it/s, loss=0.549]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  23%|██▎       | 58/250 [00:50<02:47,  1.14it/s, loss=0.549]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  23%|██▎       | 58/250 [00:50<02:47,  1.14it/s, loss=0.689]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  24%|██▎       | 59/250 [00:51<02:46,  1.15it/s, loss=0.689]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  24%|██▎       | 59/250 [00:51<02:46,  1.15it/s, loss=0.189]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  24%|██▍       | 60/250 [00:52<02:45,  1.15it/s, loss=0.189]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  24%|██▍       | 60/250 [00:52<02:45,  1.15it/s, loss=0.372]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  24%|██▍       | 61/250 [00:53<02:44,  1.15it/s, loss=0.372]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  24%|██▍       | 61/250 [00:53<02:44,  1.15it/s, loss=0.737]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  25%|██▍       | 62/250 [00:54<02:44,  1.15it/s, loss=0.737]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  25%|██▍       | 62/250 [00:54<02:44,  1.15it/s, loss=0.281]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  25%|██▌       | 63/250 [00:54<02:43,  1.15it/s, loss=0.281]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  25%|██▌       | 63/250 [00:54<02:43,  1.15it/s, loss=0.599]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  26%|██▌       | 64/250 [00:55<02:42,  1.15it/s, loss=0.599]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  26%|██▌       | 64/250 [00:55<02:42,  1.15it/s, loss=0.194]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  26%|██▌       | 65/250 [00:56<02:41,  1.15it/s, loss=0.194]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  26%|██▌       | 65/250 [00:56<02:41,  1.15it/s, loss=0.365]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  26%|██▋       | 66/250 [00:57<02:40,  1.15it/s, loss=0.365]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  26%|██▋       | 66/250 [00:57<02:40,  1.15it/s, loss=0.0699]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  27%|██▋       | 67/250 [00:58<02:39,  1.15it/s, loss=0.0699]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  27%|██▋       | 67/250 [00:58<02:39,  1.15it/s, loss=0.84]  \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  27%|██▋       | 68/250 [00:59<02:38,  1.15it/s, loss=0.84]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  27%|██▋       | 68/250 [00:59<02:38,  1.15it/s, loss=0.123]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  28%|██▊       | 69/250 [01:00<02:37,  1.15it/s, loss=0.123]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  28%|██▊       | 69/250 [01:00<02:37,  1.15it/s, loss=1.03] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  28%|██▊       | 70/250 [01:01<02:36,  1.15it/s, loss=1.03]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  28%|██▊       | 70/250 [01:01<02:36,  1.15it/s, loss=0.891]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  28%|██▊       | 71/250 [01:01<02:36,  1.15it/s, loss=0.891]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  28%|██▊       | 71/250 [01:01<02:36,  1.15it/s, loss=0.346]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  29%|██▉       | 72/250 [01:02<02:35,  1.15it/s, loss=0.346]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  29%|██▉       | 72/250 [01:02<02:35,  1.15it/s, loss=0.73] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  29%|██▉       | 73/250 [01:03<02:34,  1.15it/s, loss=0.73]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  29%|██▉       | 73/250 [01:03<02:34,  1.15it/s, loss=0.732]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  30%|██▉       | 74/250 [01:04<02:33,  1.15it/s, loss=0.732]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  30%|██▉       | 74/250 [01:04<02:33,  1.15it/s, loss=0.203]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  30%|███       | 75/250 [01:05<02:32,  1.15it/s, loss=0.203]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  30%|███       | 75/250 [01:05<02:32,  1.15it/s, loss=0.567]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  30%|███       | 76/250 [01:06<02:31,  1.15it/s, loss=0.567]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  30%|███       | 76/250 [01:06<02:31,  1.15it/s, loss=0.716]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  31%|███       | 77/250 [01:07<02:30,  1.15it/s, loss=0.716]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  31%|███       | 77/250 [01:07<02:30,  1.15it/s, loss=0.179]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  31%|███       | 78/250 [01:08<02:30,  1.14it/s, loss=0.179]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  31%|███       | 78/250 [01:08<02:30,  1.14it/s, loss=0.466]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  32%|███▏      | 79/250 [01:08<02:29,  1.14it/s, loss=0.466]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  32%|███▏      | 79/250 [01:08<02:29,  1.14it/s, loss=0.386]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  32%|███▏      | 80/250 [01:09<02:28,  1.15it/s, loss=0.386]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  32%|███▏      | 80/250 [01:09<02:28,  1.15it/s, loss=0.693]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  32%|███▏      | 81/250 [01:10<02:27,  1.15it/s, loss=0.693]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  32%|███▏      | 81/250 [01:10<02:27,  1.15it/s, loss=0.201]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  33%|███▎      | 82/250 [01:11<02:26,  1.15it/s, loss=0.201]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  33%|███▎      | 82/250 [01:11<02:26,  1.15it/s, loss=0.99] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  33%|███▎      | 83/250 [01:12<02:25,  1.15it/s, loss=0.99]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  33%|███▎      | 83/250 [01:12<02:25,  1.15it/s, loss=0.365]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  34%|███▎      | 84/250 [01:13<02:24,  1.15it/s, loss=0.365]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  34%|███▎      | 84/250 [01:13<02:24,  1.15it/s, loss=0.474]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  34%|███▍      | 85/250 [01:14<02:24,  1.15it/s, loss=0.474]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  34%|███▍      | 85/250 [01:14<02:24,  1.15it/s, loss=0.476]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  34%|███▍      | 86/250 [01:15<02:23,  1.15it/s, loss=0.476]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  34%|███▍      | 86/250 [01:15<02:23,  1.15it/s, loss=0.602]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  35%|███▍      | 87/250 [01:15<02:22,  1.15it/s, loss=0.602]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  35%|███▍      | 87/250 [01:15<02:22,  1.15it/s, loss=0.402]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  35%|███▌      | 88/250 [01:16<02:21,  1.15it/s, loss=0.402]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  35%|███▌      | 88/250 [01:16<02:21,  1.15it/s, loss=0.836]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  36%|███▌      | 89/250 [01:17<02:20,  1.15it/s, loss=0.836]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  36%|███▌      | 89/250 [01:17<02:20,  1.15it/s, loss=0.549]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  36%|███▌      | 90/250 [01:18<02:19,  1.15it/s, loss=0.549]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  36%|███▌      | 90/250 [01:18<02:19,  1.15it/s, loss=0.601]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  36%|███▋      | 91/250 [01:19<02:18,  1.15it/s, loss=0.601]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  36%|███▋      | 91/250 [01:19<02:18,  1.15it/s, loss=0.483]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  37%|███▋      | 92/250 [01:20<02:17,  1.15it/s, loss=0.483]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  37%|███▋      | 92/250 [01:20<02:17,  1.15it/s, loss=0.458]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  37%|███▋      | 93/250 [01:21<02:16,  1.15it/s, loss=0.458]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  37%|███▋      | 93/250 [01:21<02:16,  1.15it/s, loss=0.655]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  38%|███▊      | 94/250 [01:21<02:15,  1.15it/s, loss=0.655]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  38%|███▊      | 94/250 [01:21<02:15,  1.15it/s, loss=0.689]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  38%|███▊      | 95/250 [01:22<02:15,  1.15it/s, loss=0.689]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  38%|███▊      | 95/250 [01:22<02:15,  1.15it/s, loss=0.283]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  38%|███▊      | 96/250 [01:23<02:14,  1.15it/s, loss=0.283]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  38%|███▊      | 96/250 [01:23<02:14,  1.15it/s, loss=0.584]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  39%|███▉      | 97/250 [01:24<02:13,  1.15it/s, loss=0.584]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  39%|███▉      | 97/250 [01:24<02:13,  1.15it/s, loss=0.735]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  39%|███▉      | 98/250 [01:25<02:12,  1.14it/s, loss=0.735]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  39%|███▉      | 98/250 [01:25<02:12,  1.14it/s, loss=0.621]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  40%|███▉      | 99/250 [01:26<02:12,  1.14it/s, loss=0.621]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  40%|███▉      | 99/250 [01:26<02:12,  1.14it/s, loss=0.459]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  40%|████      | 100/250 [01:27<02:11,  1.14it/s, loss=0.459]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  40%|████      | 100/250 [01:27<02:11,  1.14it/s, loss=0.656]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  40%|████      | 101/250 [01:28<02:10,  1.14it/s, loss=0.656]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  40%|████      | 101/250 [01:28<02:10,  1.14it/s, loss=0.87] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  41%|████      | 102/250 [01:28<02:09,  1.15it/s, loss=0.87]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  41%|████      | 102/250 [01:28<02:09,  1.15it/s, loss=0.716]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  41%|████      | 103/250 [01:29<02:08,  1.15it/s, loss=0.716]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  41%|████      | 103/250 [01:29<02:08,  1.15it/s, loss=0.626]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  42%|████▏     | 104/250 [01:30<02:07,  1.14it/s, loss=0.626]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  42%|████▏     | 104/250 [01:30<02:07,  1.14it/s, loss=0.688]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  42%|████▏     | 105/250 [01:31<02:06,  1.15it/s, loss=0.688]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  42%|████▏     | 105/250 [01:31<02:06,  1.15it/s, loss=0.571]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  42%|████▏     | 106/250 [01:32<02:05,  1.14it/s, loss=0.571]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  42%|████▏     | 106/250 [01:32<02:05,  1.14it/s, loss=0.515]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  43%|████▎     | 107/250 [01:33<02:04,  1.15it/s, loss=0.515]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  43%|████▎     | 107/250 [01:33<02:04,  1.15it/s, loss=0.577]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  43%|████▎     | 108/250 [01:34<02:04,  1.14it/s, loss=0.577]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  43%|████▎     | 108/250 [01:34<02:04,  1.14it/s, loss=0.24] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  44%|████▎     | 109/250 [01:35<02:03,  1.15it/s, loss=0.24]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  44%|████▎     | 109/250 [01:35<02:03,  1.15it/s, loss=0.811]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  44%|████▍     | 110/250 [01:35<02:02,  1.15it/s, loss=0.811]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  44%|████▍     | 110/250 [01:35<02:02,  1.15it/s, loss=0.539]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  44%|████▍     | 111/250 [01:36<02:01,  1.15it/s, loss=0.539]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  44%|████▍     | 111/250 [01:36<02:01,  1.15it/s, loss=0.499]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  45%|████▍     | 112/250 [01:37<02:00,  1.15it/s, loss=0.499]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  45%|████▍     | 112/250 [01:37<02:00,  1.15it/s, loss=0.387]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  45%|████▌     | 113/250 [01:38<01:59,  1.15it/s, loss=0.387]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  45%|████▌     | 113/250 [01:38<01:59,  1.15it/s, loss=0.909]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  46%|████▌     | 114/250 [01:39<01:58,  1.15it/s, loss=0.909]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  46%|████▌     | 114/250 [01:39<01:58,  1.15it/s, loss=0.494]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  46%|████▌     | 115/250 [01:40<01:57,  1.15it/s, loss=0.494]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  46%|████▌     | 115/250 [01:40<01:57,  1.15it/s, loss=0.627]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  46%|████▋     | 116/250 [01:41<01:57,  1.15it/s, loss=0.627]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  46%|████▋     | 116/250 [01:41<01:57,  1.15it/s, loss=0.366]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  47%|████▋     | 117/250 [01:42<01:56,  1.15it/s, loss=0.366]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  47%|████▋     | 117/250 [01:42<01:56,  1.15it/s, loss=0.191]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  47%|████▋     | 118/250 [01:42<01:55,  1.15it/s, loss=0.191]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  47%|████▋     | 118/250 [01:42<01:55,  1.15it/s, loss=0.228]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  48%|████▊     | 119/250 [01:43<01:54,  1.15it/s, loss=0.228]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  48%|████▊     | 119/250 [01:43<01:54,  1.15it/s, loss=0.607]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  48%|████▊     | 120/250 [01:44<01:53,  1.15it/s, loss=0.607]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  48%|████▊     | 120/250 [01:44<01:53,  1.15it/s, loss=1.27] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  48%|████▊     | 121/250 [01:45<01:52,  1.15it/s, loss=1.27]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  48%|████▊     | 121/250 [01:45<01:52,  1.15it/s, loss=1.05]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  49%|████▉     | 122/250 [01:46<01:51,  1.15it/s, loss=1.05]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  49%|████▉     | 122/250 [01:46<01:51,  1.15it/s, loss=0.767]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  49%|████▉     | 123/250 [01:47<01:50,  1.15it/s, loss=0.767]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  49%|████▉     | 123/250 [01:47<01:50,  1.15it/s, loss=0.223]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  50%|████▉     | 124/250 [01:48<01:49,  1.15it/s, loss=0.223]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  50%|████▉     | 124/250 [01:48<01:49,  1.15it/s, loss=0.643]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  50%|█████     | 125/250 [01:49<01:49,  1.15it/s, loss=0.643]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  50%|█████     | 125/250 [01:49<01:49,  1.15it/s, loss=0.319]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  50%|█████     | 126/250 [01:49<01:48,  1.15it/s, loss=0.319]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  50%|█████     | 126/250 [01:49<01:48,  1.15it/s, loss=0.634]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  51%|█████     | 127/250 [01:50<01:47,  1.15it/s, loss=0.634]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  51%|█████     | 127/250 [01:50<01:47,  1.15it/s, loss=0.521]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  51%|█████     | 128/250 [01:51<01:46,  1.15it/s, loss=0.521]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  51%|█████     | 128/250 [01:51<01:46,  1.15it/s, loss=0.515]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  52%|█████▏    | 129/250 [01:52<01:45,  1.15it/s, loss=0.515]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  52%|█████▏    | 129/250 [01:52<01:45,  1.15it/s, loss=0.451]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  52%|█████▏    | 130/250 [01:53<01:44,  1.15it/s, loss=0.451]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  52%|█████▏    | 130/250 [01:53<01:44,  1.15it/s, loss=0.906]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  52%|█████▏    | 131/250 [01:54<01:43,  1.15it/s, loss=0.906]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  52%|█████▏    | 131/250 [01:54<01:43,  1.15it/s, loss=0.82] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  53%|█████▎    | 132/250 [01:55<01:42,  1.15it/s, loss=0.82]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  53%|█████▎    | 132/250 [01:55<01:42,  1.15it/s, loss=0.845]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  53%|█████▎    | 133/250 [01:56<01:41,  1.15it/s, loss=0.845]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  53%|█████▎    | 133/250 [01:56<01:41,  1.15it/s, loss=0.652]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  54%|█████▎    | 134/250 [01:56<01:41,  1.15it/s, loss=0.652]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  54%|█████▎    | 134/250 [01:56<01:41,  1.15it/s, loss=0.586]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  54%|█████▍    | 135/250 [01:57<01:40,  1.15it/s, loss=0.586]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  54%|█████▍    | 135/250 [01:57<01:40,  1.15it/s, loss=0.618]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  54%|█████▍    | 136/250 [01:58<01:39,  1.15it/s, loss=0.618]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  54%|█████▍    | 136/250 [01:58<01:39,  1.15it/s, loss=0.506]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  55%|█████▍    | 137/250 [01:59<01:38,  1.15it/s, loss=0.506]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  55%|█████▍    | 137/250 [01:59<01:38,  1.15it/s, loss=0.581]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  55%|█████▌    | 138/250 [02:00<01:37,  1.15it/s, loss=0.581]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  55%|█████▌    | 138/250 [02:00<01:37,  1.15it/s, loss=0.639]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  56%|█████▌    | 139/250 [02:01<01:36,  1.15it/s, loss=0.639]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  56%|█████▌    | 139/250 [02:01<01:36,  1.15it/s, loss=0.407]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  56%|█████▌    | 140/250 [02:02<01:35,  1.15it/s, loss=0.407]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  56%|█████▌    | 140/250 [02:02<01:35,  1.15it/s, loss=0.569]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  56%|█████▋    | 141/250 [02:02<01:34,  1.15it/s, loss=0.569]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  56%|█████▋    | 141/250 [02:02<01:34,  1.15it/s, loss=0.547]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  57%|█████▋    | 142/250 [02:03<01:33,  1.15it/s, loss=0.547]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  57%|█████▋    | 142/250 [02:03<01:33,  1.15it/s, loss=0.673]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  57%|█████▋    | 143/250 [02:04<01:33,  1.15it/s, loss=0.673]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  57%|█████▋    | 143/250 [02:04<01:33,  1.15it/s, loss=0.487]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  58%|█████▊    | 144/250 [02:05<01:32,  1.15it/s, loss=0.487]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  58%|█████▊    | 144/250 [02:05<01:32,  1.15it/s, loss=0.33] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  58%|█████▊    | 145/250 [02:06<01:31,  1.15it/s, loss=0.33]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  58%|█████▊    | 145/250 [02:06<01:31,  1.15it/s, loss=0.579]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  58%|█████▊    | 146/250 [02:07<01:30,  1.15it/s, loss=0.579]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  58%|█████▊    | 146/250 [02:07<01:30,  1.15it/s, loss=0.796]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  59%|█████▉    | 147/250 [02:08<01:29,  1.15it/s, loss=0.796]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  59%|█████▉    | 147/250 [02:08<01:29,  1.15it/s, loss=0.283]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  59%|█████▉    | 148/250 [02:09<01:28,  1.15it/s, loss=0.283]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  59%|█████▉    | 148/250 [02:09<01:28,  1.15it/s, loss=0.406]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  60%|█████▉    | 149/250 [02:09<01:28,  1.15it/s, loss=0.406]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  60%|█████▉    | 149/250 [02:09<01:28,  1.15it/s, loss=0.449]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  60%|██████    | 150/250 [02:10<01:27,  1.14it/s, loss=0.449]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  60%|██████    | 150/250 [02:10<01:27,  1.14it/s, loss=0.446]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  60%|██████    | 151/250 [02:11<01:26,  1.14it/s, loss=0.446]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  60%|██████    | 151/250 [02:11<01:26,  1.14it/s, loss=0.113]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  61%|██████    | 152/250 [02:12<01:25,  1.15it/s, loss=0.113]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  61%|██████    | 152/250 [02:12<01:25,  1.15it/s, loss=0.477]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  61%|██████    | 153/250 [02:13<01:24,  1.15it/s, loss=0.477]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  61%|██████    | 153/250 [02:13<01:24,  1.15it/s, loss=0.898]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  62%|██████▏   | 154/250 [02:14<01:23,  1.15it/s, loss=0.898]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  62%|██████▏   | 154/250 [02:14<01:23,  1.15it/s, loss=0.812]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  62%|██████▏   | 155/250 [02:15<01:22,  1.15it/s, loss=0.812]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  62%|██████▏   | 155/250 [02:15<01:22,  1.15it/s, loss=0.679]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  62%|██████▏   | 156/250 [02:16<01:21,  1.15it/s, loss=0.679]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  62%|██████▏   | 156/250 [02:16<01:21,  1.15it/s, loss=0.153]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  63%|██████▎   | 157/250 [02:16<01:20,  1.15it/s, loss=0.153]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  63%|██████▎   | 157/250 [02:16<01:20,  1.15it/s, loss=0.383]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  63%|██████▎   | 158/250 [02:17<01:20,  1.15it/s, loss=0.383]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  63%|██████▎   | 158/250 [02:17<01:20,  1.15it/s, loss=0.784]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  64%|██████▎   | 159/250 [02:18<01:19,  1.15it/s, loss=0.784]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  64%|██████▎   | 159/250 [02:18<01:19,  1.15it/s, loss=0.537]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  64%|██████▍   | 160/250 [02:19<01:18,  1.15it/s, loss=0.537]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  64%|██████▍   | 160/250 [02:19<01:18,  1.15it/s, loss=0.329]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  64%|██████▍   | 161/250 [02:20<01:17,  1.15it/s, loss=0.329]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  64%|██████▍   | 161/250 [02:20<01:17,  1.15it/s, loss=0.781]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  65%|██████▍   | 162/250 [02:21<01:16,  1.15it/s, loss=0.781]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  65%|██████▍   | 162/250 [02:21<01:16,  1.15it/s, loss=0.378]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  65%|██████▌   | 163/250 [02:22<01:15,  1.15it/s, loss=0.378]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  65%|██████▌   | 163/250 [02:22<01:15,  1.15it/s, loss=0.271]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  66%|██████▌   | 164/250 [02:23<01:14,  1.15it/s, loss=0.271]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  66%|██████▌   | 164/250 [02:23<01:14,  1.15it/s, loss=0.436]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  66%|██████▌   | 165/250 [02:23<01:13,  1.15it/s, loss=0.436]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  66%|██████▌   | 165/250 [02:23<01:13,  1.15it/s, loss=1.02] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  66%|██████▋   | 166/250 [02:24<01:13,  1.15it/s, loss=1.02]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  66%|██████▋   | 166/250 [02:24<01:13,  1.15it/s, loss=0.341]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  67%|██████▋   | 167/250 [02:25<01:12,  1.15it/s, loss=0.341]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  67%|██████▋   | 167/250 [02:25<01:12,  1.15it/s, loss=0.325]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  67%|██████▋   | 168/250 [02:26<01:11,  1.15it/s, loss=0.325]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  67%|██████▋   | 168/250 [02:26<01:11,  1.15it/s, loss=0.508]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  68%|██████▊   | 169/250 [02:27<01:10,  1.15it/s, loss=0.508]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  68%|██████▊   | 169/250 [02:27<01:10,  1.15it/s, loss=0.245]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  68%|██████▊   | 170/250 [02:28<01:09,  1.15it/s, loss=0.245]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  68%|██████▊   | 170/250 [02:28<01:09,  1.15it/s, loss=0.425]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  68%|██████▊   | 171/250 [02:29<01:08,  1.15it/s, loss=0.425]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  68%|██████▊   | 171/250 [02:29<01:08,  1.15it/s, loss=0.566]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  69%|██████▉   | 172/250 [02:29<01:07,  1.15it/s, loss=0.566]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  69%|██████▉   | 172/250 [02:29<01:07,  1.15it/s, loss=0.612]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  69%|██████▉   | 173/250 [02:30<01:07,  1.15it/s, loss=0.612]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  69%|██████▉   | 173/250 [02:30<01:07,  1.15it/s, loss=0.929]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  70%|██████▉   | 174/250 [02:31<01:06,  1.15it/s, loss=0.929]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  70%|██████▉   | 174/250 [02:31<01:06,  1.15it/s, loss=0.257]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  70%|███████   | 175/250 [02:32<01:05,  1.15it/s, loss=0.257]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  70%|███████   | 175/250 [02:32<01:05,  1.15it/s, loss=0.393]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  70%|███████   | 176/250 [02:33<01:04,  1.15it/s, loss=0.393]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  70%|███████   | 176/250 [02:33<01:04,  1.15it/s, loss=0.227]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  71%|███████   | 177/250 [02:34<01:03,  1.15it/s, loss=0.227]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  71%|███████   | 177/250 [02:34<01:03,  1.15it/s, loss=0.283]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  71%|███████   | 178/250 [02:35<01:02,  1.15it/s, loss=0.283]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  71%|███████   | 178/250 [02:35<01:02,  1.15it/s, loss=0.244]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  72%|███████▏  | 179/250 [02:36<01:01,  1.15it/s, loss=0.244]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  72%|███████▏  | 179/250 [02:36<01:01,  1.15it/s, loss=0.441]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  72%|███████▏  | 180/250 [02:36<01:00,  1.15it/s, loss=0.441]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  72%|███████▏  | 180/250 [02:36<01:00,  1.15it/s, loss=0.297]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  72%|███████▏  | 181/250 [02:37<00:59,  1.15it/s, loss=0.297]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  72%|███████▏  | 181/250 [02:37<00:59,  1.15it/s, loss=0.0941]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  73%|███████▎  | 182/250 [02:38<00:59,  1.15it/s, loss=0.0941]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  73%|███████▎  | 182/250 [02:38<00:59,  1.15it/s, loss=1.35]  \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  73%|███████▎  | 183/250 [02:39<00:58,  1.15it/s, loss=1.35]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  73%|███████▎  | 183/250 [02:39<00:58,  1.15it/s, loss=0.185]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  74%|███████▎  | 184/250 [02:40<00:57,  1.15it/s, loss=0.185]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  74%|███████▎  | 184/250 [02:40<00:57,  1.15it/s, loss=0.469]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  74%|███████▍  | 185/250 [02:41<00:56,  1.15it/s, loss=0.469]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  74%|███████▍  | 185/250 [02:41<00:56,  1.15it/s, loss=0.801]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  74%|███████▍  | 186/250 [02:42<00:55,  1.15it/s, loss=0.801]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  74%|███████▍  | 186/250 [02:42<00:55,  1.15it/s, loss=0.132]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  75%|███████▍  | 187/250 [02:43<00:54,  1.15it/s, loss=0.132]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  75%|███████▍  | 187/250 [02:43<00:54,  1.15it/s, loss=0.272]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  75%|███████▌  | 188/250 [02:43<00:53,  1.15it/s, loss=0.272]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  75%|███████▌  | 188/250 [02:43<00:53,  1.15it/s, loss=0.304]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  76%|███████▌  | 189/250 [02:44<00:53,  1.15it/s, loss=0.304]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  76%|███████▌  | 189/250 [02:44<00:53,  1.15it/s, loss=0.728]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  76%|███████▌  | 190/250 [02:45<00:52,  1.15it/s, loss=0.728]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  76%|███████▌  | 190/250 [02:45<00:52,  1.15it/s, loss=0.0616]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  76%|███████▋  | 191/250 [02:46<00:51,  1.15it/s, loss=0.0616]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  76%|███████▋  | 191/250 [02:46<00:51,  1.15it/s, loss=0.0847]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  77%|███████▋  | 192/250 [02:47<00:50,  1.15it/s, loss=0.0847]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  77%|███████▋  | 192/250 [02:47<00:50,  1.15it/s, loss=0.716] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  77%|███████▋  | 193/250 [02:48<00:49,  1.15it/s, loss=0.716]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  77%|███████▋  | 193/250 [02:48<00:49,  1.15it/s, loss=0.933]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  78%|███████▊  | 194/250 [02:49<00:48,  1.15it/s, loss=0.933]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  78%|███████▊  | 194/250 [02:49<00:48,  1.15it/s, loss=0.559]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  78%|███████▊  | 195/250 [02:49<00:47,  1.15it/s, loss=0.559]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  78%|███████▊  | 195/250 [02:50<00:47,  1.15it/s, loss=0.429]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  78%|███████▊  | 196/250 [02:50<00:47,  1.15it/s, loss=0.429]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  78%|███████▊  | 196/250 [02:50<00:47,  1.15it/s, loss=0.631]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  79%|███████▉  | 197/250 [02:51<00:46,  1.15it/s, loss=0.631]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  79%|███████▉  | 197/250 [02:51<00:46,  1.15it/s, loss=0.48] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  79%|███████▉  | 198/250 [02:52<00:45,  1.15it/s, loss=0.48]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  79%|███████▉  | 198/250 [02:52<00:45,  1.15it/s, loss=0.406]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  80%|███████▉  | 199/250 [02:53<00:44,  1.15it/s, loss=0.406]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  80%|███████▉  | 199/250 [02:53<00:44,  1.15it/s, loss=0.262]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  80%|████████  | 200/250 [02:54<00:43,  1.15it/s, loss=0.262]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  80%|████████  | 200/250 [02:54<00:43,  1.15it/s, loss=0.279]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  80%|████████  | 201/250 [02:55<00:42,  1.15it/s, loss=0.279]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  80%|████████  | 201/250 [02:55<00:42,  1.15it/s, loss=0.278]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  81%|████████  | 202/250 [02:56<00:41,  1.15it/s, loss=0.278]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  81%|████████  | 202/250 [02:56<00:41,  1.15it/s, loss=0.583]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  81%|████████  | 203/250 [02:56<00:40,  1.15it/s, loss=0.583]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  81%|████████  | 203/250 [02:56<00:40,  1.15it/s, loss=0.453]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  82%|████████▏ | 204/250 [02:57<00:40,  1.15it/s, loss=0.453]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  82%|████████▏ | 204/250 [02:57<00:40,  1.15it/s, loss=0.359]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  82%|████████▏ | 205/250 [02:58<00:39,  1.15it/s, loss=0.359]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  82%|████████▏ | 205/250 [02:58<00:39,  1.15it/s, loss=0.34] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  82%|████████▏ | 206/250 [02:59<00:38,  1.15it/s, loss=0.34]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  82%|████████▏ | 206/250 [02:59<00:38,  1.15it/s, loss=0.731]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  83%|████████▎ | 207/250 [03:00<00:37,  1.15it/s, loss=0.731]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  83%|████████▎ | 207/250 [03:00<00:37,  1.15it/s, loss=0.279]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  83%|████████▎ | 208/250 [03:01<00:36,  1.15it/s, loss=0.279]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  83%|████████▎ | 208/250 [03:01<00:36,  1.15it/s, loss=0.46] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  84%|████████▎ | 209/250 [03:02<00:35,  1.15it/s, loss=0.46]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  84%|████████▎ | 209/250 [03:02<00:35,  1.15it/s, loss=0.59]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  84%|████████▍ | 210/250 [03:03<00:34,  1.15it/s, loss=0.59]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  84%|████████▍ | 210/250 [03:03<00:34,  1.15it/s, loss=0.282]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  84%|████████▍ | 211/250 [03:03<00:33,  1.15it/s, loss=0.282]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  84%|████████▍ | 211/250 [03:03<00:33,  1.15it/s, loss=0.226]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  85%|████████▍ | 212/250 [03:04<00:33,  1.15it/s, loss=0.226]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  85%|████████▍ | 212/250 [03:04<00:33,  1.15it/s, loss=0.959]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  85%|████████▌ | 213/250 [03:05<00:32,  1.15it/s, loss=0.959]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  85%|████████▌ | 213/250 [03:05<00:32,  1.15it/s, loss=0.249]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  86%|████████▌ | 214/250 [03:06<00:31,  1.15it/s, loss=0.249]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  86%|████████▌ | 214/250 [03:06<00:31,  1.15it/s, loss=0.919]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  86%|████████▌ | 215/250 [03:07<00:30,  1.15it/s, loss=0.919]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  86%|████████▌ | 215/250 [03:07<00:30,  1.15it/s, loss=0.149]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  86%|████████▋ | 216/250 [03:08<00:29,  1.15it/s, loss=0.149]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  86%|████████▋ | 216/250 [03:08<00:29,  1.15it/s, loss=0.479]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  87%|████████▋ | 217/250 [03:09<00:28,  1.15it/s, loss=0.479]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  87%|████████▋ | 217/250 [03:09<00:28,  1.15it/s, loss=1.14] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  87%|████████▋ | 218/250 [03:10<00:27,  1.15it/s, loss=1.14]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  87%|████████▋ | 218/250 [03:10<00:27,  1.15it/s, loss=0.783]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  88%|████████▊ | 219/250 [03:10<00:27,  1.15it/s, loss=0.783]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  88%|████████▊ | 219/250 [03:10<00:27,  1.15it/s, loss=0.2]  \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  88%|████████▊ | 220/250 [03:11<00:26,  1.15it/s, loss=0.2]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  88%|████████▊ | 220/250 [03:11<00:26,  1.15it/s, loss=0.517]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  88%|████████▊ | 221/250 [03:12<00:25,  1.15it/s, loss=0.517]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  88%|████████▊ | 221/250 [03:12<00:25,  1.15it/s, loss=0.458]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  89%|████████▉ | 222/250 [03:13<00:24,  1.15it/s, loss=0.458]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  89%|████████▉ | 222/250 [03:13<00:24,  1.15it/s, loss=0.135]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  89%|████████▉ | 223/250 [03:14<00:23,  1.15it/s, loss=0.135]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  89%|████████▉ | 223/250 [03:14<00:23,  1.15it/s, loss=0.774]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  90%|████████▉ | 224/250 [03:15<00:22,  1.15it/s, loss=0.774]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  90%|████████▉ | 224/250 [03:15<00:22,  1.15it/s, loss=0.752]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  90%|█████████ | 225/250 [03:16<00:21,  1.15it/s, loss=0.752]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  90%|█████████ | 225/250 [03:16<00:21,  1.15it/s, loss=0.477]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  90%|█████████ | 226/250 [03:16<00:20,  1.15it/s, loss=0.477]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  90%|█████████ | 226/250 [03:16<00:20,  1.15it/s, loss=0.624]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  91%|█████████ | 227/250 [03:17<00:20,  1.15it/s, loss=0.624]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  91%|█████████ | 227/250 [03:17<00:20,  1.15it/s, loss=0.477]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  91%|█████████ | 228/250 [03:18<00:19,  1.15it/s, loss=0.477]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  91%|█████████ | 228/250 [03:18<00:19,  1.15it/s, loss=0.425]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  92%|█████████▏| 229/250 [03:19<00:18,  1.15it/s, loss=0.425]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  92%|█████████▏| 229/250 [03:19<00:18,  1.15it/s, loss=0.555]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  92%|█████████▏| 230/250 [03:20<00:17,  1.15it/s, loss=0.555]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  92%|█████████▏| 230/250 [03:20<00:17,  1.15it/s, loss=0.38] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  92%|█████████▏| 231/250 [03:21<00:16,  1.15it/s, loss=0.38]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  92%|█████████▏| 231/250 [03:21<00:16,  1.15it/s, loss=0.232]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  93%|█████████▎| 232/250 [03:22<00:15,  1.15it/s, loss=0.232]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  93%|█████████▎| 232/250 [03:22<00:15,  1.15it/s, loss=0.42] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  93%|█████████▎| 233/250 [03:23<00:14,  1.15it/s, loss=0.42]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  93%|█████████▎| 233/250 [03:23<00:14,  1.15it/s, loss=0.308]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  94%|█████████▎| 234/250 [03:23<00:13,  1.15it/s, loss=0.308]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  94%|█████████▎| 234/250 [03:23<00:13,  1.15it/s, loss=0.26] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  94%|█████████▍| 235/250 [03:24<00:13,  1.15it/s, loss=0.26]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  94%|█████████▍| 235/250 [03:24<00:13,  1.15it/s, loss=1.06]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  94%|█████████▍| 236/250 [03:25<00:12,  1.15it/s, loss=1.06]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  94%|█████████▍| 236/250 [03:25<00:12,  1.15it/s, loss=0.562]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  95%|█████████▍| 237/250 [03:26<00:11,  1.15it/s, loss=0.562]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  95%|█████████▍| 237/250 [03:26<00:11,  1.15it/s, loss=0.3]  \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  95%|█████████▌| 238/250 [03:27<00:10,  1.15it/s, loss=0.3]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  95%|█████████▌| 238/250 [03:27<00:10,  1.15it/s, loss=0.58]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  96%|█████████▌| 239/250 [03:28<00:09,  1.15it/s, loss=0.58]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  96%|█████████▌| 239/250 [03:28<00:09,  1.15it/s, loss=0.492]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  96%|█████████▌| 240/250 [03:29<00:08,  1.15it/s, loss=0.492]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  96%|█████████▌| 240/250 [03:29<00:08,  1.15it/s, loss=0.57] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  96%|█████████▋| 241/250 [03:30<00:07,  1.15it/s, loss=0.57]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  96%|█████████▋| 241/250 [03:30<00:07,  1.15it/s, loss=0.361]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  97%|█████████▋| 242/250 [03:30<00:06,  1.15it/s, loss=0.361]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  97%|█████████▋| 242/250 [03:30<00:06,  1.15it/s, loss=0.27] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  97%|█████████▋| 243/250 [03:31<00:06,  1.15it/s, loss=0.27]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  97%|█████████▋| 243/250 [03:31<00:06,  1.15it/s, loss=0.371]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  98%|█████████▊| 244/250 [03:32<00:05,  1.15it/s, loss=0.371]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  98%|█████████▊| 244/250 [03:32<00:05,  1.15it/s, loss=0.769]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  98%|█████████▊| 245/250 [03:33<00:04,  1.15it/s, loss=0.769]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  98%|█████████▊| 245/250 [03:33<00:04,  1.15it/s, loss=0.234]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  98%|█████████▊| 246/250 [03:34<00:03,  1.15it/s, loss=0.234]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  98%|█████████▊| 246/250 [03:34<00:03,  1.15it/s, loss=0.598]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  99%|█████████▉| 247/250 [03:35<00:02,  1.15it/s, loss=0.598]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  99%|█████████▉| 247/250 [03:35<00:02,  1.15it/s, loss=0.108]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  99%|█████████▉| 248/250 [03:36<00:01,  1.15it/s, loss=0.108]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1:  99%|█████████▉| 248/250 [03:36<00:01,  1.15it/s, loss=1.03] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1: 100%|█████████▉| 249/250 [03:36<00:00,  1.15it/s, loss=1.03]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1: 100%|█████████▉| 249/250 [03:37<00:00,  1.15it/s, loss=0.844]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1: 100%|██████████| 250/250 [03:37<00:00,  1.15it/s, loss=0.844]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1: 100%|██████████| 250/250 [03:37<00:00,  1.15it/s, loss=0.196]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Train epoch:  67%|██████▋   | 2/3 [07:44<03:52, 232.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 1: 100%|██████████| 250/250 [03:52<00:00,  1.08it/s, loss=0.927, dist_mean=0.785]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Train step of epoch 2:   0%|          | 0/250 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   0%|          | 1/250 [00:00<03:30,  1.18it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   0%|          | 1/250 [00:00<03:30,  1.18it/s, loss=0.084]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   1%|          | 2/250 [00:01<03:34,  1.16it/s, loss=0.084]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   1%|          | 2/250 [00:01<03:34,  1.16it/s, loss=0.183]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   1%|          | 3/250 [00:02<03:34,  1.15it/s, loss=0.183]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   1%|          | 3/250 [00:02<03:34,  1.15it/s, loss=0.17] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   2%|▏         | 4/250 [00:03<03:33,  1.15it/s, loss=0.17]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   2%|▏         | 4/250 [00:03<03:33,  1.15it/s, loss=0.252]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   2%|▏         | 5/250 [00:04<03:33,  1.15it/s, loss=0.252]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   2%|▏         | 5/250 [00:04<03:33,  1.15it/s, loss=0.17] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   2%|▏         | 6/250 [00:05<03:32,  1.15it/s, loss=0.17]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   2%|▏         | 6/250 [00:05<03:32,  1.15it/s, loss=0.0365]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   3%|▎         | 7/250 [00:06<03:31,  1.15it/s, loss=0.0365]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   3%|▎         | 7/250 [00:06<03:31,  1.15it/s, loss=0.11]  \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   3%|▎         | 8/250 [00:06<03:30,  1.15it/s, loss=0.11]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   3%|▎         | 8/250 [00:06<03:30,  1.15it/s, loss=0.126]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   4%|▎         | 9/250 [00:07<03:30,  1.15it/s, loss=0.126]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   4%|▎         | 9/250 [00:07<03:30,  1.15it/s, loss=0.129]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   4%|▍         | 10/250 [00:08<03:29,  1.15it/s, loss=0.129]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   4%|▍         | 10/250 [00:08<03:29,  1.15it/s, loss=0.323]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   4%|▍         | 11/250 [00:09<03:28,  1.15it/s, loss=0.323]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   4%|▍         | 11/250 [00:09<03:28,  1.15it/s, loss=0.271]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   5%|▍         | 12/250 [00:10<03:27,  1.15it/s, loss=0.271]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   5%|▍         | 12/250 [00:10<03:27,  1.15it/s, loss=0.252]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   5%|▌         | 13/250 [00:11<03:26,  1.15it/s, loss=0.252]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   5%|▌         | 13/250 [00:11<03:26,  1.15it/s, loss=0.018]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   6%|▌         | 14/250 [00:12<03:25,  1.15it/s, loss=0.018]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   6%|▌         | 14/250 [00:12<03:25,  1.15it/s, loss=0.0799]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   6%|▌         | 15/250 [00:13<03:24,  1.15it/s, loss=0.0799]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   6%|▌         | 15/250 [00:13<03:24,  1.15it/s, loss=0.0649]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   6%|▋         | 16/250 [00:13<03:23,  1.15it/s, loss=0.0649]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   6%|▋         | 16/250 [00:13<03:23,  1.15it/s, loss=0.339] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   7%|▋         | 17/250 [00:14<03:23,  1.15it/s, loss=0.339]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   7%|▋         | 17/250 [00:14<03:23,  1.15it/s, loss=0.188]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   7%|▋         | 18/250 [00:15<03:22,  1.15it/s, loss=0.188]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   7%|▋         | 18/250 [00:15<03:22,  1.15it/s, loss=0.0793]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   8%|▊         | 19/250 [00:16<03:21,  1.15it/s, loss=0.0793]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   8%|▊         | 19/250 [00:16<03:21,  1.15it/s, loss=0.144] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   8%|▊         | 20/250 [00:17<03:20,  1.15it/s, loss=0.144]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   8%|▊         | 20/250 [00:17<03:20,  1.15it/s, loss=0.00685]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   8%|▊         | 21/250 [00:18<03:19,  1.15it/s, loss=0.00685]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   8%|▊         | 21/250 [00:18<03:19,  1.15it/s, loss=0.31]   \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   9%|▉         | 22/250 [00:19<03:18,  1.15it/s, loss=0.31]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   9%|▉         | 22/250 [00:19<03:18,  1.15it/s, loss=0.0689]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   9%|▉         | 23/250 [00:20<03:17,  1.15it/s, loss=0.0689]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:   9%|▉         | 23/250 [00:20<03:17,  1.15it/s, loss=0.0413]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  10%|▉         | 24/250 [00:20<03:16,  1.15it/s, loss=0.0413]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  10%|▉         | 24/250 [00:20<03:16,  1.15it/s, loss=0.0646]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  10%|█         | 25/250 [00:21<03:15,  1.15it/s, loss=0.0646]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  10%|█         | 25/250 [00:21<03:15,  1.15it/s, loss=0.00144]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  10%|█         | 26/250 [00:22<03:14,  1.15it/s, loss=0.00144]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  10%|█         | 26/250 [00:22<03:14,  1.15it/s, loss=0.0395] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  11%|█         | 27/250 [00:23<03:13,  1.15it/s, loss=0.0395]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  11%|█         | 27/250 [00:23<03:13,  1.15it/s, loss=0.256] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  11%|█         | 28/250 [00:24<03:13,  1.15it/s, loss=0.256]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  11%|█         | 28/250 [00:24<03:13,  1.15it/s, loss=0.00994]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  12%|█▏        | 29/250 [00:25<03:12,  1.15it/s, loss=0.00994]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  12%|█▏        | 29/250 [00:25<03:12,  1.15it/s, loss=0.000159]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  12%|█▏        | 30/250 [00:26<03:11,  1.15it/s, loss=0.000159]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  12%|█▏        | 30/250 [00:26<03:11,  1.15it/s, loss=0.0401]  \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  12%|█▏        | 31/250 [00:26<03:10,  1.15it/s, loss=0.0401]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  12%|█▏        | 31/250 [00:27<03:10,  1.15it/s, loss=0.000689]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  13%|█▎        | 32/250 [00:27<03:09,  1.15it/s, loss=0.000689]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  13%|█▎        | 32/250 [00:27<03:09,  1.15it/s, loss=1.65]    \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  13%|█▎        | 33/250 [00:28<03:08,  1.15it/s, loss=1.65]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  13%|█▎        | 33/250 [00:28<03:08,  1.15it/s, loss=0.322]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  14%|█▎        | 34/250 [00:29<03:08,  1.15it/s, loss=0.322]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  14%|█▎        | 34/250 [00:29<03:08,  1.15it/s, loss=0.104]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  14%|█▍        | 35/250 [00:30<03:07,  1.15it/s, loss=0.104]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  14%|█▍        | 35/250 [00:30<03:07,  1.15it/s, loss=0.0408]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  14%|█▍        | 36/250 [00:31<03:06,  1.15it/s, loss=0.0408]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  14%|█▍        | 36/250 [00:31<03:06,  1.15it/s, loss=0.233] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  15%|█▍        | 37/250 [00:32<03:05,  1.15it/s, loss=0.233]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  15%|█▍        | 37/250 [00:32<03:05,  1.15it/s, loss=0.113]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  15%|█▌        | 38/250 [00:33<03:04,  1.15it/s, loss=0.113]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  15%|█▌        | 38/250 [00:33<03:04,  1.15it/s, loss=0.00962]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  16%|█▌        | 39/250 [00:33<03:03,  1.15it/s, loss=0.00962]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  16%|█▌        | 39/250 [00:33<03:03,  1.15it/s, loss=0.0341] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  16%|█▌        | 40/250 [00:34<03:02,  1.15it/s, loss=0.0341]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  16%|█▌        | 40/250 [00:34<03:02,  1.15it/s, loss=0.0358]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  16%|█▋        | 41/250 [00:35<03:01,  1.15it/s, loss=0.0358]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  16%|█▋        | 41/250 [00:35<03:01,  1.15it/s, loss=0.0221]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  17%|█▋        | 42/250 [00:36<03:01,  1.15it/s, loss=0.0221]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  17%|█▋        | 42/250 [00:36<03:01,  1.15it/s, loss=0.0308]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  17%|█▋        | 43/250 [00:37<03:00,  1.15it/s, loss=0.0308]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  17%|█▋        | 43/250 [00:37<03:00,  1.15it/s, loss=0.0829]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  18%|█▊        | 44/250 [00:38<02:59,  1.15it/s, loss=0.0829]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  18%|█▊        | 44/250 [00:38<02:59,  1.15it/s, loss=0.0503]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  18%|█▊        | 45/250 [00:39<02:58,  1.15it/s, loss=0.0503]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  18%|█▊        | 45/250 [00:39<02:58,  1.15it/s, loss=0.0728]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  18%|█▊        | 46/250 [00:40<02:57,  1.15it/s, loss=0.0728]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  18%|█▊        | 46/250 [00:40<02:57,  1.15it/s, loss=0.316] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  19%|█▉        | 47/250 [00:40<02:56,  1.15it/s, loss=0.316]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  19%|█▉        | 47/250 [00:40<02:56,  1.15it/s, loss=0.324]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  19%|█▉        | 48/250 [00:41<02:55,  1.15it/s, loss=0.324]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  19%|█▉        | 48/250 [00:41<02:55,  1.15it/s, loss=0.532]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  20%|█▉        | 49/250 [00:42<02:54,  1.15it/s, loss=0.532]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  20%|█▉        | 49/250 [00:42<02:54,  1.15it/s, loss=0.0117]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  20%|██        | 50/250 [00:43<02:54,  1.15it/s, loss=0.0117]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  20%|██        | 50/250 [00:43<02:54,  1.15it/s, loss=0.87]  \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  20%|██        | 51/250 [00:44<02:53,  1.15it/s, loss=0.87]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  20%|██        | 51/250 [00:44<02:53,  1.15it/s, loss=0.103]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  21%|██        | 52/250 [00:45<02:52,  1.15it/s, loss=0.103]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  21%|██        | 52/250 [00:45<02:52,  1.15it/s, loss=0.0313]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  21%|██        | 53/250 [00:46<02:51,  1.15it/s, loss=0.0313]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  21%|██        | 53/250 [00:46<02:51,  1.15it/s, loss=0.0955]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  22%|██▏       | 54/250 [00:47<02:50,  1.15it/s, loss=0.0955]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  22%|██▏       | 54/250 [00:47<02:50,  1.15it/s, loss=0.419] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  22%|██▏       | 55/250 [00:47<02:49,  1.15it/s, loss=0.419]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  22%|██▏       | 55/250 [00:47<02:49,  1.15it/s, loss=0.0188]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  22%|██▏       | 56/250 [00:48<02:48,  1.15it/s, loss=0.0188]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  22%|██▏       | 56/250 [00:48<02:48,  1.15it/s, loss=0.0417]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  23%|██▎       | 57/250 [00:49<02:47,  1.15it/s, loss=0.0417]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  23%|██▎       | 57/250 [00:49<02:47,  1.15it/s, loss=0.0565]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  23%|██▎       | 58/250 [00:50<02:47,  1.15it/s, loss=0.0565]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  23%|██▎       | 58/250 [00:50<02:47,  1.15it/s, loss=0.00755]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  24%|██▎       | 59/250 [00:51<02:46,  1.15it/s, loss=0.00755]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  24%|██▎       | 59/250 [00:51<02:46,  1.15it/s, loss=0.133]  \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  24%|██▍       | 60/250 [00:52<02:45,  1.15it/s, loss=0.133]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  24%|██▍       | 60/250 [00:52<02:45,  1.15it/s, loss=0.0323]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  24%|██▍       | 61/250 [00:53<02:44,  1.15it/s, loss=0.0323]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  24%|██▍       | 61/250 [00:53<02:44,  1.15it/s, loss=0.00312]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  25%|██▍       | 62/250 [00:53<02:43,  1.15it/s, loss=0.00312]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  25%|██▍       | 62/250 [00:53<02:43,  1.15it/s, loss=0.275]  \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  25%|██▌       | 63/250 [00:54<02:42,  1.15it/s, loss=0.275]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  25%|██▌       | 63/250 [00:54<02:42,  1.15it/s, loss=0.273]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  26%|██▌       | 64/250 [00:55<02:41,  1.15it/s, loss=0.273]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  26%|██▌       | 64/250 [00:55<02:41,  1.15it/s, loss=0.00143]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  26%|██▌       | 65/250 [00:56<02:41,  1.15it/s, loss=0.00143]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  26%|██▌       | 65/250 [00:56<02:41,  1.15it/s, loss=0.212]  \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  26%|██▋       | 66/250 [00:57<02:40,  1.15it/s, loss=0.212]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  26%|██▋       | 66/250 [00:57<02:40,  1.15it/s, loss=0.0164]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  27%|██▋       | 67/250 [00:58<02:39,  1.15it/s, loss=0.0164]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  27%|██▋       | 67/250 [00:58<02:39,  1.15it/s, loss=0.0221]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  27%|██▋       | 68/250 [00:59<02:38,  1.15it/s, loss=0.0221]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  27%|██▋       | 68/250 [00:59<02:38,  1.15it/s, loss=0.0556]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  28%|██▊       | 69/250 [01:00<02:37,  1.15it/s, loss=0.0556]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  28%|██▊       | 69/250 [01:00<02:37,  1.15it/s, loss=0.172] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  28%|██▊       | 70/250 [01:00<02:36,  1.15it/s, loss=0.172]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  28%|██▊       | 70/250 [01:00<02:36,  1.15it/s, loss=0.268]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  28%|██▊       | 71/250 [01:01<02:35,  1.15it/s, loss=0.268]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  28%|██▊       | 71/250 [01:01<02:35,  1.15it/s, loss=0.0818]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  29%|██▉       | 72/250 [01:02<02:35,  1.15it/s, loss=0.0818]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  29%|██▉       | 72/250 [01:02<02:35,  1.15it/s, loss=0.0177]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  29%|██▉       | 73/250 [01:03<02:34,  1.15it/s, loss=0.0177]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  29%|██▉       | 73/250 [01:03<02:34,  1.15it/s, loss=0.215] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  30%|██▉       | 74/250 [01:04<02:33,  1.15it/s, loss=0.215]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  30%|██▉       | 74/250 [01:04<02:33,  1.15it/s, loss=0.00615]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  30%|███       | 75/250 [01:05<02:31,  1.15it/s, loss=0.00615]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  30%|███       | 75/250 [01:05<02:31,  1.15it/s, loss=1.49]   \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  30%|███       | 76/250 [01:06<02:31,  1.15it/s, loss=1.49]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  30%|███       | 76/250 [01:06<02:31,  1.15it/s, loss=0.0289]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  31%|███       | 77/250 [01:07<02:30,  1.15it/s, loss=0.0289]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  31%|███       | 77/250 [01:07<02:30,  1.15it/s, loss=0.108] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  31%|███       | 78/250 [01:07<02:29,  1.15it/s, loss=0.108]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  31%|███       | 78/250 [01:07<02:29,  1.15it/s, loss=0.0276]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  32%|███▏      | 79/250 [01:08<02:28,  1.15it/s, loss=0.0276]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  32%|███▏      | 79/250 [01:08<02:28,  1.15it/s, loss=0.24]  \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  32%|███▏      | 80/250 [01:09<02:27,  1.15it/s, loss=0.24]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  32%|███▏      | 80/250 [01:09<02:27,  1.15it/s, loss=0.183]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  32%|███▏      | 81/250 [01:10<02:26,  1.15it/s, loss=0.183]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  32%|███▏      | 81/250 [01:10<02:26,  1.15it/s, loss=0.148]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  33%|███▎      | 82/250 [01:11<02:26,  1.15it/s, loss=0.148]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  33%|███▎      | 82/250 [01:11<02:26,  1.15it/s, loss=0.576]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  33%|███▎      | 83/250 [01:12<02:25,  1.15it/s, loss=0.576]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  33%|███▎      | 83/250 [01:12<02:25,  1.15it/s, loss=0.213]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  34%|███▎      | 84/250 [01:13<02:24,  1.15it/s, loss=0.213]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  34%|███▎      | 84/250 [01:13<02:24,  1.15it/s, loss=0.0704]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  34%|███▍      | 85/250 [01:13<02:23,  1.15it/s, loss=0.0704]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  34%|███▍      | 85/250 [01:14<02:23,  1.15it/s, loss=0.29]  \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  34%|███▍      | 86/250 [01:14<02:22,  1.15it/s, loss=0.29]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  34%|███▍      | 86/250 [01:14<02:22,  1.15it/s, loss=0.242]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  35%|███▍      | 87/250 [01:15<02:21,  1.15it/s, loss=0.242]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  35%|███▍      | 87/250 [01:15<02:21,  1.15it/s, loss=0.236]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  35%|███▌      | 88/250 [01:16<02:20,  1.15it/s, loss=0.236]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  35%|███▌      | 88/250 [01:16<02:20,  1.15it/s, loss=0.758]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  36%|███▌      | 89/250 [01:17<02:20,  1.15it/s, loss=0.758]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  36%|███▌      | 89/250 [01:17<02:20,  1.15it/s, loss=0.457]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  36%|███▌      | 90/250 [01:18<02:19,  1.15it/s, loss=0.457]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  36%|███▌      | 90/250 [01:18<02:19,  1.15it/s, loss=0.0969]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  36%|███▋      | 91/250 [01:19<02:18,  1.15it/s, loss=0.0969]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  36%|███▋      | 91/250 [01:19<02:18,  1.15it/s, loss=0.617] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  37%|███▋      | 92/250 [01:20<02:17,  1.15it/s, loss=0.617]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  37%|███▋      | 92/250 [01:20<02:17,  1.15it/s, loss=0.459]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  37%|███▋      | 93/250 [01:20<02:16,  1.15it/s, loss=0.459]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  37%|███▋      | 93/250 [01:20<02:16,  1.15it/s, loss=0.261]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  38%|███▊      | 94/250 [01:21<02:15,  1.15it/s, loss=0.261]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  38%|███▊      | 94/250 [01:21<02:15,  1.15it/s, loss=0.366]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  38%|███▊      | 95/250 [01:22<02:14,  1.15it/s, loss=0.366]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  38%|███▊      | 95/250 [01:22<02:14,  1.15it/s, loss=0.289]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  38%|███▊      | 96/250 [01:23<02:14,  1.15it/s, loss=0.289]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  38%|███▊      | 96/250 [01:23<02:14,  1.15it/s, loss=0.628]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  39%|███▉      | 97/250 [01:24<02:13,  1.15it/s, loss=0.628]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  39%|███▉      | 97/250 [01:24<02:13,  1.15it/s, loss=0.355]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  39%|███▉      | 98/250 [01:25<02:12,  1.15it/s, loss=0.355]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  39%|███▉      | 98/250 [01:25<02:12,  1.15it/s, loss=0.209]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  40%|███▉      | 99/250 [01:26<02:11,  1.15it/s, loss=0.209]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  40%|███▉      | 99/250 [01:26<02:11,  1.15it/s, loss=0.274]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  40%|████      | 100/250 [01:27<02:10,  1.15it/s, loss=0.274]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  40%|████      | 100/250 [01:27<02:10,  1.15it/s, loss=0.371]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  40%|████      | 101/250 [01:27<02:09,  1.15it/s, loss=0.371]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  40%|████      | 101/250 [01:27<02:09,  1.15it/s, loss=0.342]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  41%|████      | 102/250 [01:28<02:08,  1.15it/s, loss=0.342]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  41%|████      | 102/250 [01:28<02:08,  1.15it/s, loss=0.526]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  41%|████      | 103/250 [01:29<02:07,  1.15it/s, loss=0.526]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  41%|████      | 103/250 [01:29<02:07,  1.15it/s, loss=0.733]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  42%|████▏     | 104/250 [01:30<02:07,  1.15it/s, loss=0.733]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  42%|████▏     | 104/250 [01:30<02:07,  1.15it/s, loss=0.07] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  42%|████▏     | 105/250 [01:31<02:06,  1.15it/s, loss=0.07]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  42%|████▏     | 105/250 [01:31<02:06,  1.15it/s, loss=0.23]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  42%|████▏     | 106/250 [01:32<02:05,  1.15it/s, loss=0.23]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  42%|████▏     | 106/250 [01:32<02:05,  1.15it/s, loss=0.225]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  43%|████▎     | 107/250 [01:33<02:04,  1.15it/s, loss=0.225]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  43%|████▎     | 107/250 [01:33<02:04,  1.15it/s, loss=0.323]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  43%|████▎     | 108/250 [01:33<02:03,  1.15it/s, loss=0.323]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  43%|████▎     | 108/250 [01:34<02:03,  1.15it/s, loss=0.0281]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  44%|████▎     | 109/250 [01:34<02:02,  1.15it/s, loss=0.0281]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  44%|████▎     | 109/250 [01:34<02:02,  1.15it/s, loss=0.316] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  44%|████▍     | 110/250 [01:35<02:01,  1.15it/s, loss=0.316]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  44%|████▍     | 110/250 [01:35<02:01,  1.15it/s, loss=0.0684]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  44%|████▍     | 111/250 [01:36<02:00,  1.15it/s, loss=0.0684]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  44%|████▍     | 111/250 [01:36<02:00,  1.15it/s, loss=0.77]  \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  45%|████▍     | 112/250 [01:37<02:00,  1.15it/s, loss=0.77]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  45%|████▍     | 112/250 [01:37<02:00,  1.15it/s, loss=0.00302]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  45%|████▌     | 113/250 [01:38<01:59,  1.15it/s, loss=0.00302]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  45%|████▌     | 113/250 [01:38<01:59,  1.15it/s, loss=0.014]  \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  46%|████▌     | 114/250 [01:39<01:58,  1.15it/s, loss=0.014]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  46%|████▌     | 114/250 [01:39<01:58,  1.15it/s, loss=0.129]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  46%|████▌     | 115/250 [01:40<01:57,  1.15it/s, loss=0.129]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  46%|████▌     | 115/250 [01:40<01:57,  1.15it/s, loss=0.0233]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  46%|████▋     | 116/250 [01:40<01:56,  1.15it/s, loss=0.0233]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  46%|████▋     | 116/250 [01:40<01:56,  1.15it/s, loss=0.00594]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  47%|████▋     | 117/250 [01:41<01:55,  1.15it/s, loss=0.00594]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  47%|████▋     | 117/250 [01:41<01:55,  1.15it/s, loss=0.265]  \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  47%|████▋     | 118/250 [01:42<01:54,  1.15it/s, loss=0.265]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  47%|████▋     | 118/250 [01:42<01:54,  1.15it/s, loss=0.0114]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  48%|████▊     | 119/250 [01:43<01:53,  1.15it/s, loss=0.0114]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  48%|████▊     | 119/250 [01:43<01:53,  1.15it/s, loss=0.00513]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  48%|████▊     | 120/250 [01:44<01:53,  1.15it/s, loss=0.00513]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  48%|████▊     | 120/250 [01:44<01:53,  1.15it/s, loss=0.0651] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  48%|████▊     | 121/250 [01:45<01:52,  1.15it/s, loss=0.0651]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  48%|████▊     | 121/250 [01:45<01:52,  1.15it/s, loss=0.0597]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  49%|████▉     | 122/250 [01:46<01:51,  1.15it/s, loss=0.0597]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  49%|████▉     | 122/250 [01:46<01:51,  1.15it/s, loss=0.0211]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  49%|████▉     | 123/250 [01:47<01:50,  1.15it/s, loss=0.0211]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  49%|████▉     | 123/250 [01:47<01:50,  1.15it/s, loss=6.71e-5]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  50%|████▉     | 124/250 [01:47<01:49,  1.15it/s, loss=6.71e-5]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  50%|████▉     | 124/250 [01:47<01:49,  1.15it/s, loss=0.142]  \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  50%|█████     | 125/250 [01:48<01:48,  1.16it/s, loss=0.142]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  50%|█████     | 125/250 [01:48<01:48,  1.16it/s, loss=0.479]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  50%|█████     | 126/250 [01:49<01:47,  1.16it/s, loss=0.479]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  50%|█████     | 126/250 [01:49<01:47,  1.16it/s, loss=0.224]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  51%|█████     | 127/250 [01:50<01:46,  1.16it/s, loss=0.224]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  51%|█████     | 127/250 [01:50<01:46,  1.16it/s, loss=1.2]  \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  51%|█████     | 128/250 [01:51<01:45,  1.15it/s, loss=1.2]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  51%|█████     | 128/250 [01:51<01:45,  1.15it/s, loss=0.0962]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  52%|█████▏    | 129/250 [01:52<01:45,  1.15it/s, loss=0.0962]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  52%|█████▏    | 129/250 [01:52<01:45,  1.15it/s, loss=0.0185]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  52%|█████▏    | 130/250 [01:53<01:44,  1.15it/s, loss=0.0185]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  52%|█████▏    | 130/250 [01:53<01:44,  1.15it/s, loss=0.563] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  52%|█████▏    | 131/250 [01:53<01:43,  1.15it/s, loss=0.563]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  52%|█████▏    | 131/250 [01:54<01:43,  1.15it/s, loss=0.00531]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  53%|█████▎    | 132/250 [01:54<01:42,  1.15it/s, loss=0.00531]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  53%|█████▎    | 132/250 [01:54<01:42,  1.15it/s, loss=0.0967] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  53%|█████▎    | 133/250 [01:55<01:41,  1.15it/s, loss=0.0967]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  53%|█████▎    | 133/250 [01:55<01:41,  1.15it/s, loss=0.172] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  54%|█████▎    | 134/250 [01:56<01:40,  1.15it/s, loss=0.172]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  54%|█████▎    | 134/250 [01:56<01:40,  1.15it/s, loss=0.0767]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  54%|█████▍    | 135/250 [01:57<01:40,  1.15it/s, loss=0.0767]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  54%|█████▍    | 135/250 [01:57<01:40,  1.15it/s, loss=0.269] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  54%|█████▍    | 136/250 [01:58<01:39,  1.15it/s, loss=0.269]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  54%|█████▍    | 136/250 [01:58<01:39,  1.15it/s, loss=0.0116]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  55%|█████▍    | 137/250 [01:59<01:38,  1.15it/s, loss=0.0116]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  55%|█████▍    | 137/250 [01:59<01:38,  1.15it/s, loss=0.402] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  55%|█████▌    | 138/250 [02:00<01:37,  1.15it/s, loss=0.402]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  55%|█████▌    | 138/250 [02:00<01:37,  1.15it/s, loss=0.115]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  56%|█████▌    | 139/250 [02:00<01:36,  1.15it/s, loss=0.115]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  56%|█████▌    | 139/250 [02:00<01:36,  1.15it/s, loss=0.0277]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  56%|█████▌    | 140/250 [02:01<01:35,  1.15it/s, loss=0.0277]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  56%|█████▌    | 140/250 [02:01<01:35,  1.15it/s, loss=0.0918]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  56%|█████▋    | 141/250 [02:02<01:35,  1.15it/s, loss=0.0918]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  56%|█████▋    | 141/250 [02:02<01:35,  1.15it/s, loss=0.0799]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  57%|█████▋    | 142/250 [02:03<01:34,  1.15it/s, loss=0.0799]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  57%|█████▋    | 142/250 [02:03<01:34,  1.15it/s, loss=0.123] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  57%|█████▋    | 143/250 [02:04<01:33,  1.15it/s, loss=0.123]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  57%|█████▋    | 143/250 [02:04<01:33,  1.15it/s, loss=1.48] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  58%|█████▊    | 144/250 [02:05<01:32,  1.15it/s, loss=1.48]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  58%|█████▊    | 144/250 [02:05<01:32,  1.15it/s, loss=0.0318]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  58%|█████▊    | 145/250 [02:06<01:31,  1.15it/s, loss=0.0318]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  58%|█████▊    | 145/250 [02:06<01:31,  1.15it/s, loss=0.0428]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  58%|█████▊    | 146/250 [02:07<01:30,  1.15it/s, loss=0.0428]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  58%|█████▊    | 146/250 [02:07<01:30,  1.15it/s, loss=1.05]  \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  59%|█████▉    | 147/250 [02:07<01:29,  1.15it/s, loss=1.05]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  59%|█████▉    | 147/250 [02:07<01:29,  1.15it/s, loss=0.0249]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  59%|█████▉    | 148/250 [02:08<01:28,  1.15it/s, loss=0.0249]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  59%|█████▉    | 148/250 [02:08<01:28,  1.15it/s, loss=0.0128]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  60%|█████▉    | 149/250 [02:09<01:27,  1.15it/s, loss=0.0128]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  60%|█████▉    | 149/250 [02:09<01:27,  1.15it/s, loss=0.0476]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  60%|██████    | 150/250 [02:10<01:27,  1.15it/s, loss=0.0476]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  60%|██████    | 150/250 [02:10<01:27,  1.15it/s, loss=0.161] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  60%|██████    | 151/250 [02:11<01:26,  1.15it/s, loss=0.161]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  60%|██████    | 151/250 [02:11<01:26,  1.15it/s, loss=0.043]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  61%|██████    | 152/250 [02:12<01:25,  1.15it/s, loss=0.043]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  61%|██████    | 152/250 [02:12<01:25,  1.15it/s, loss=0.25] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  61%|██████    | 153/250 [02:13<01:24,  1.15it/s, loss=0.25]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  61%|██████    | 153/250 [02:13<01:24,  1.15it/s, loss=0.054]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  62%|██████▏   | 154/250 [02:14<01:23,  1.15it/s, loss=0.054]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  62%|██████▏   | 154/250 [02:14<01:23,  1.15it/s, loss=0.174]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  62%|██████▏   | 155/250 [02:14<01:22,  1.15it/s, loss=0.174]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  62%|██████▏   | 155/250 [02:14<01:22,  1.15it/s, loss=0.348]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  62%|██████▏   | 156/250 [02:15<01:21,  1.15it/s, loss=0.348]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  62%|██████▏   | 156/250 [02:15<01:21,  1.15it/s, loss=0.0747]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  63%|██████▎   | 157/250 [02:16<01:20,  1.15it/s, loss=0.0747]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  63%|██████▎   | 157/250 [02:16<01:20,  1.15it/s, loss=0.0188]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  63%|██████▎   | 158/250 [02:17<01:20,  1.15it/s, loss=0.0188]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  63%|██████▎   | 158/250 [02:17<01:20,  1.15it/s, loss=0.864] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  64%|██████▎   | 159/250 [02:18<01:19,  1.15it/s, loss=0.864]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  64%|██████▎   | 159/250 [02:18<01:19,  1.15it/s, loss=0.238]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  64%|██████▍   | 160/250 [02:19<01:18,  1.15it/s, loss=0.238]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  64%|██████▍   | 160/250 [02:19<01:18,  1.15it/s, loss=0.0611]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  64%|██████▍   | 161/250 [02:20<01:17,  1.15it/s, loss=0.0611]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  64%|██████▍   | 161/250 [02:20<01:17,  1.15it/s, loss=0.0453]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  65%|██████▍   | 162/250 [02:20<01:16,  1.15it/s, loss=0.0453]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  65%|██████▍   | 162/250 [02:20<01:16,  1.15it/s, loss=0.261] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  65%|██████▌   | 163/250 [02:21<01:15,  1.15it/s, loss=0.261]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  65%|██████▌   | 163/250 [02:21<01:15,  1.15it/s, loss=0.00584]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  66%|██████▌   | 164/250 [02:22<01:14,  1.15it/s, loss=0.00584]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  66%|██████▌   | 164/250 [02:22<01:14,  1.15it/s, loss=0.019]  \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  66%|██████▌   | 165/250 [02:23<01:13,  1.15it/s, loss=0.019]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  66%|██████▌   | 165/250 [02:23<01:13,  1.15it/s, loss=0.562]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  66%|██████▋   | 166/250 [02:24<01:13,  1.15it/s, loss=0.562]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  66%|██████▋   | 166/250 [02:24<01:13,  1.15it/s, loss=0.221]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  67%|██████▋   | 167/250 [02:25<01:12,  1.15it/s, loss=0.221]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  67%|██████▋   | 167/250 [02:25<01:12,  1.15it/s, loss=0.0223]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  67%|██████▋   | 168/250 [02:26<01:11,  1.15it/s, loss=0.0223]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  67%|██████▋   | 168/250 [02:26<01:11,  1.15it/s, loss=0.212] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  68%|██████▊   | 169/250 [02:27<01:10,  1.15it/s, loss=0.212]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  68%|██████▊   | 169/250 [02:27<01:10,  1.15it/s, loss=0.0742]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  68%|██████▊   | 170/250 [02:27<01:09,  1.15it/s, loss=0.0742]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  68%|██████▊   | 170/250 [02:27<01:09,  1.15it/s, loss=0.385] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  68%|██████▊   | 171/250 [02:28<01:08,  1.15it/s, loss=0.385]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  68%|██████▊   | 171/250 [02:28<01:08,  1.15it/s, loss=0.0843]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  69%|██████▉   | 172/250 [02:29<01:07,  1.15it/s, loss=0.0843]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  69%|██████▉   | 172/250 [02:29<01:07,  1.15it/s, loss=0.156] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  69%|██████▉   | 173/250 [02:30<01:06,  1.15it/s, loss=0.156]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  69%|██████▉   | 173/250 [02:30<01:06,  1.15it/s, loss=0.0546]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  70%|██████▉   | 174/250 [02:31<01:06,  1.15it/s, loss=0.0546]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  70%|██████▉   | 174/250 [02:31<01:06,  1.15it/s, loss=0.0117]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  70%|███████   | 175/250 [02:32<01:05,  1.15it/s, loss=0.0117]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  70%|███████   | 175/250 [02:32<01:05,  1.15it/s, loss=0.218] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  70%|███████   | 176/250 [02:33<01:04,  1.15it/s, loss=0.218]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  70%|███████   | 176/250 [02:33<01:04,  1.15it/s, loss=0.00278]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  71%|███████   | 177/250 [02:34<01:03,  1.15it/s, loss=0.00278]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  71%|███████   | 177/250 [02:34<01:03,  1.15it/s, loss=0.0498] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  71%|███████   | 178/250 [02:34<01:02,  1.15it/s, loss=0.0498]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  71%|███████   | 178/250 [02:34<01:02,  1.15it/s, loss=0.0471]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  72%|███████▏  | 179/250 [02:35<01:01,  1.15it/s, loss=0.0471]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  72%|███████▏  | 179/250 [02:35<01:01,  1.15it/s, loss=0.0133]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  72%|███████▏  | 180/250 [02:36<01:00,  1.15it/s, loss=0.0133]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  72%|███████▏  | 180/250 [02:36<01:00,  1.15it/s, loss=0.0203]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  72%|███████▏  | 181/250 [02:37<01:00,  1.15it/s, loss=0.0203]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  72%|███████▏  | 181/250 [02:37<01:00,  1.15it/s, loss=0.625] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  73%|███████▎  | 182/250 [02:38<00:59,  1.15it/s, loss=0.625]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  73%|███████▎  | 182/250 [02:38<00:59,  1.15it/s, loss=0.205]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  73%|███████▎  | 183/250 [02:39<00:58,  1.15it/s, loss=0.205]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  73%|███████▎  | 183/250 [02:39<00:58,  1.15it/s, loss=0.00966]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  74%|███████▎  | 184/250 [02:40<00:57,  1.15it/s, loss=0.00966]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  74%|███████▎  | 184/250 [02:40<00:57,  1.15it/s, loss=0.666]  \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  74%|███████▍  | 185/250 [02:40<00:56,  1.15it/s, loss=0.666]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  74%|███████▍  | 185/250 [02:41<00:56,  1.15it/s, loss=0.303]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  74%|███████▍  | 186/250 [02:41<00:55,  1.15it/s, loss=0.303]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  74%|███████▍  | 186/250 [02:41<00:55,  1.15it/s, loss=0.0339]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  75%|███████▍  | 187/250 [02:42<00:54,  1.15it/s, loss=0.0339]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  75%|███████▍  | 187/250 [02:42<00:54,  1.15it/s, loss=0.0542]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  75%|███████▌  | 188/250 [02:43<00:54,  1.15it/s, loss=0.0542]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  75%|███████▌  | 188/250 [02:43<00:54,  1.15it/s, loss=0.0106]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  76%|███████▌  | 189/250 [02:44<00:53,  1.15it/s, loss=0.0106]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  76%|███████▌  | 189/250 [02:44<00:53,  1.15it/s, loss=0.487] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  76%|███████▌  | 190/250 [02:45<00:52,  1.15it/s, loss=0.487]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  76%|███████▌  | 190/250 [02:45<00:52,  1.15it/s, loss=0.00276]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  76%|███████▋  | 191/250 [02:46<00:51,  1.15it/s, loss=0.00276]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  76%|███████▋  | 191/250 [02:46<00:51,  1.15it/s, loss=0.0589] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  77%|███████▋  | 192/250 [02:47<00:50,  1.15it/s, loss=0.0589]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  77%|███████▋  | 192/250 [02:47<00:50,  1.15it/s, loss=0.0677]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  77%|███████▋  | 193/250 [02:47<00:49,  1.15it/s, loss=0.0677]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  77%|███████▋  | 193/250 [02:47<00:49,  1.15it/s, loss=2.55]  \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  78%|███████▊  | 194/250 [02:48<00:48,  1.15it/s, loss=2.55]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  78%|███████▊  | 194/250 [02:48<00:48,  1.15it/s, loss=0.0339]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  78%|███████▊  | 195/250 [02:49<00:47,  1.15it/s, loss=0.0339]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  78%|███████▊  | 195/250 [02:49<00:47,  1.15it/s, loss=0.0323]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  78%|███████▊  | 196/250 [02:50<00:46,  1.15it/s, loss=0.0323]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  78%|███████▊  | 196/250 [02:50<00:46,  1.15it/s, loss=0.314] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  79%|███████▉  | 197/250 [02:51<00:46,  1.15it/s, loss=0.314]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  79%|███████▉  | 197/250 [02:51<00:46,  1.15it/s, loss=0.924]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  79%|███████▉  | 198/250 [02:52<00:45,  1.15it/s, loss=0.924]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  79%|███████▉  | 198/250 [02:52<00:45,  1.15it/s, loss=0.337]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  80%|███████▉  | 199/250 [02:53<00:44,  1.15it/s, loss=0.337]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  80%|███████▉  | 199/250 [02:53<00:44,  1.15it/s, loss=0.166]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  80%|████████  | 200/250 [02:54<00:43,  1.15it/s, loss=0.166]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  80%|████████  | 200/250 [02:54<00:43,  1.15it/s, loss=0.155]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  80%|████████  | 201/250 [02:54<00:42,  1.15it/s, loss=0.155]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  80%|████████  | 201/250 [02:54<00:42,  1.15it/s, loss=0.118]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  81%|████████  | 202/250 [02:55<00:41,  1.15it/s, loss=0.118]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  81%|████████  | 202/250 [02:55<00:41,  1.15it/s, loss=0.451]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  81%|████████  | 203/250 [02:56<00:40,  1.15it/s, loss=0.451]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  81%|████████  | 203/250 [02:56<00:40,  1.15it/s, loss=0.282]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  82%|████████▏ | 204/250 [02:57<00:40,  1.15it/s, loss=0.282]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  82%|████████▏ | 204/250 [02:57<00:40,  1.15it/s, loss=0.561]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  82%|████████▏ | 205/250 [02:58<00:39,  1.15it/s, loss=0.561]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  82%|████████▏ | 205/250 [02:58<00:39,  1.15it/s, loss=0.324]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  82%|████████▏ | 206/250 [02:59<00:38,  1.15it/s, loss=0.324]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  82%|████████▏ | 206/250 [02:59<00:38,  1.15it/s, loss=0.544]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  83%|████████▎ | 207/250 [03:00<00:37,  1.15it/s, loss=0.544]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  83%|████████▎ | 207/250 [03:00<00:37,  1.15it/s, loss=0.196]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  83%|████████▎ | 208/250 [03:01<00:36,  1.15it/s, loss=0.196]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  83%|████████▎ | 208/250 [03:01<00:36,  1.15it/s, loss=0.405]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  84%|████████▎ | 209/250 [03:01<00:35,  1.15it/s, loss=0.405]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  84%|████████▎ | 209/250 [03:01<00:35,  1.15it/s, loss=0.317]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  84%|████████▍ | 210/250 [03:02<00:34,  1.15it/s, loss=0.317]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  84%|████████▍ | 210/250 [03:02<00:34,  1.15it/s, loss=0.528]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  84%|████████▍ | 211/250 [03:03<00:33,  1.15it/s, loss=0.528]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  84%|████████▍ | 211/250 [03:03<00:33,  1.15it/s, loss=0.253]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  85%|████████▍ | 212/250 [03:04<00:33,  1.15it/s, loss=0.253]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  85%|████████▍ | 212/250 [03:04<00:33,  1.15it/s, loss=0.612]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  85%|████████▌ | 213/250 [03:05<00:32,  1.15it/s, loss=0.612]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  85%|████████▌ | 213/250 [03:05<00:32,  1.15it/s, loss=0.344]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  86%|████████▌ | 214/250 [03:06<00:31,  1.15it/s, loss=0.344]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  86%|████████▌ | 214/250 [03:06<00:31,  1.15it/s, loss=0.451]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  86%|████████▌ | 215/250 [03:07<00:30,  1.15it/s, loss=0.451]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  86%|████████▌ | 215/250 [03:07<00:30,  1.15it/s, loss=0.0576]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  86%|████████▋ | 216/250 [03:07<00:29,  1.15it/s, loss=0.0576]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  86%|████████▋ | 216/250 [03:07<00:29,  1.15it/s, loss=0.703] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  87%|████████▋ | 217/250 [03:08<00:28,  1.15it/s, loss=0.703]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  87%|████████▋ | 217/250 [03:08<00:28,  1.15it/s, loss=0.325]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  87%|████████▋ | 218/250 [03:09<00:27,  1.15it/s, loss=0.325]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  87%|████████▋ | 218/250 [03:09<00:27,  1.15it/s, loss=0.373]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  88%|████████▊ | 219/250 [03:10<00:27,  1.15it/s, loss=0.373]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  88%|████████▊ | 219/250 [03:10<00:27,  1.15it/s, loss=0.282]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  88%|████████▊ | 220/250 [03:11<00:26,  1.15it/s, loss=0.282]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  88%|████████▊ | 220/250 [03:11<00:26,  1.15it/s, loss=0.123]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  88%|████████▊ | 221/250 [03:12<00:25,  1.15it/s, loss=0.123]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  88%|████████▊ | 221/250 [03:12<00:25,  1.15it/s, loss=0.219]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  89%|████████▉ | 222/250 [03:13<00:24,  1.15it/s, loss=0.219]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  89%|████████▉ | 222/250 [03:13<00:24,  1.15it/s, loss=0.0279]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  89%|████████▉ | 223/250 [03:14<00:23,  1.15it/s, loss=0.0279]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  89%|████████▉ | 223/250 [03:14<00:23,  1.15it/s, loss=1.18]  \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  90%|████████▉ | 224/250 [03:14<00:22,  1.15it/s, loss=1.18]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  90%|████████▉ | 224/250 [03:14<00:22,  1.15it/s, loss=0.391]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  90%|█████████ | 225/250 [03:15<00:21,  1.15it/s, loss=0.391]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  90%|█████████ | 225/250 [03:15<00:21,  1.15it/s, loss=0.133]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  90%|█████████ | 226/250 [03:16<00:20,  1.15it/s, loss=0.133]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  90%|█████████ | 226/250 [03:16<00:20,  1.15it/s, loss=0.884]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  91%|█████████ | 227/250 [03:17<00:20,  1.15it/s, loss=0.884]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  91%|█████████ | 227/250 [03:17<00:20,  1.15it/s, loss=0.425]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  91%|█████████ | 228/250 [03:18<00:19,  1.15it/s, loss=0.425]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  91%|█████████ | 228/250 [03:18<00:19,  1.15it/s, loss=0.0825]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  92%|█████████▏| 229/250 [03:19<00:18,  1.15it/s, loss=0.0825]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  92%|█████████▏| 229/250 [03:19<00:18,  1.15it/s, loss=0.0842]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  92%|█████████▏| 230/250 [03:20<00:17,  1.15it/s, loss=0.0842]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  92%|█████████▏| 230/250 [03:20<00:17,  1.15it/s, loss=0.0741]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  92%|█████████▏| 231/250 [03:21<00:16,  1.15it/s, loss=0.0741]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  92%|█████████▏| 231/250 [03:21<00:16,  1.15it/s, loss=0.072] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  93%|█████████▎| 232/250 [03:21<00:15,  1.15it/s, loss=0.072]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  93%|█████████▎| 232/250 [03:21<00:15,  1.15it/s, loss=0.316]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  93%|█████████▎| 233/250 [03:22<00:14,  1.15it/s, loss=0.316]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  93%|█████████▎| 233/250 [03:22<00:14,  1.15it/s, loss=0.0571]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  94%|█████████▎| 234/250 [03:23<00:13,  1.15it/s, loss=0.0571]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  94%|█████████▎| 234/250 [03:23<00:13,  1.15it/s, loss=0.171] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  94%|█████████▍| 235/250 [03:24<00:13,  1.15it/s, loss=0.171]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  94%|█████████▍| 235/250 [03:24<00:13,  1.15it/s, loss=0.111]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  94%|█████████▍| 236/250 [03:25<00:12,  1.15it/s, loss=0.111]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  94%|█████████▍| 236/250 [03:25<00:12,  1.15it/s, loss=0.0474]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  95%|█████████▍| 237/250 [03:26<00:11,  1.15it/s, loss=0.0474]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  95%|█████████▍| 237/250 [03:26<00:11,  1.15it/s, loss=0.567] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  95%|█████████▌| 238/250 [03:27<00:10,  1.15it/s, loss=0.567]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  95%|█████████▌| 238/250 [03:27<00:10,  1.15it/s, loss=0.376]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  96%|█████████▌| 239/250 [03:27<00:09,  1.15it/s, loss=0.376]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  96%|█████████▌| 239/250 [03:28<00:09,  1.15it/s, loss=0.124]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  96%|█████████▌| 240/250 [03:28<00:08,  1.15it/s, loss=0.124]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  96%|█████████▌| 240/250 [03:28<00:08,  1.15it/s, loss=0.113]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  96%|█████████▋| 241/250 [03:29<00:07,  1.15it/s, loss=0.113]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  96%|█████████▋| 241/250 [03:29<00:07,  1.15it/s, loss=0.0857]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  97%|█████████▋| 242/250 [03:30<00:06,  1.15it/s, loss=0.0857]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  97%|█████████▋| 242/250 [03:30<00:06,  1.15it/s, loss=0.0266]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  97%|█████████▋| 243/250 [03:31<00:06,  1.15it/s, loss=0.0266]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  97%|█████████▋| 243/250 [03:31<00:06,  1.15it/s, loss=0.173] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  98%|█████████▊| 244/250 [03:32<00:05,  1.15it/s, loss=0.173]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  98%|█████████▊| 244/250 [03:32<00:05,  1.15it/s, loss=0.448]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  98%|█████████▊| 245/250 [03:33<00:04,  1.15it/s, loss=0.448]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  98%|█████████▊| 245/250 [03:33<00:04,  1.15it/s, loss=0.0119]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  98%|█████████▊| 246/250 [03:34<00:03,  1.15it/s, loss=0.0119]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  98%|█████████▊| 246/250 [03:34<00:03,  1.15it/s, loss=0.0363]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  99%|█████████▉| 247/250 [03:34<00:02,  1.15it/s, loss=0.0363]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  99%|█████████▉| 247/250 [03:34<00:02,  1.15it/s, loss=0.00613]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  99%|█████████▉| 248/250 [03:35<00:01,  1.15it/s, loss=0.00613]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2:  99%|█████████▉| 248/250 [03:35<00:01,  1.15it/s, loss=0.223]  \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2: 100%|█████████▉| 249/250 [03:36<00:00,  1.15it/s, loss=0.223]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2: 100%|█████████▉| 249/250 [03:36<00:00,  1.15it/s, loss=0.191]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2: 100%|██████████| 250/250 [03:37<00:00,  1.15it/s, loss=0.191]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2: 100%|██████████| 250/250 [03:37<00:00,  1.15it/s, loss=0.0278]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Train epoch: 100%|██████████| 3/3 [11:36<00:00, 232.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 2: 100%|██████████| 250/250 [03:51<00:00,  1.08it/s, loss=1.54, dist_mean=1.4]\u001b[A\u001b[A\u001b[A\n",
      "Train epoch: 100%|██████████| 3/3 [11:36<00:00, 232.07s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(use_lora=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "017be388",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('aiffel/KoChatGPT/output_2_RM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c462e181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 인공지능은 똥멍청이 입니다\n",
      "reward score: 5.5\n"
     ]
    }
   ],
   "source": [
    "def inference_RM(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
    "        torch.cuda.current_device())\n",
    "    output = model(input_ids)\n",
    "    output_reward = output.cpu().detach().numpy()[0]\n",
    "\n",
    "    print('input: %s\\nreward score: %.1f'%(input_text, output_reward))\n",
    "\n",
    "    return output_reward\n",
    "\n",
    "input_text = '인공지능은 똥멍청이 입니다'\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e11167bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 인공지능(AI)은 컴퓨터에서 음성 및 작성된 언어를 보고 이해하고 번역하고 데이터를 분석하고 추천하는 기능을 포함하여 다양한 고급 기능을 수행할 수 있는 일련의 기술입니다.\n",
      "reward score: 5.6\n"
     ]
    }
   ],
   "source": [
    "input_text = '인공지능(AI)은 컴퓨터에서 음성 및 작성된 언어를 보고 이해하고 번역하고 데이터를 분석하고 추천하는 기능을 포함하여 다양한 고급 기능을 수행할 수 있는 일련의 기술입니다.'\n",
    "\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f01b4659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 인공지능(AI)은 컴퓨터에서 음성 및 작성된 언어를 보고 이해하고 번역하고 데이터를 분석하고 추천하는 기능을 포함하여 다양한 고급 기능을 수행할 수 있는 일련의 기술입니다. AI는 현대적인 컴퓨팅 혁신에서 중추적인 역할을 하며 개인과 비즈니스의 가치를 창출합니다. 예를 들어 광학 문자 인식(OCR)은 AI를 사용해 이미지 및 문서에서 텍스트 및 데이터를 추출하고, 구조화되지 않은 콘텐츠를 비즈니스에 바로 사용할 수 있게 만들고, 유용한 정보를 창출합니다.\n",
      "reward score: 5.4\n"
     ]
    }
   ],
   "source": [
    "input_text = \"인공지능(AI)은 컴퓨터에서 음성 및 작성된 언어를 보고 이해하고 번역하고 데이터를 분석하고 추천하는 기능을 포함하여 다양한 고급 기능을 수행할 수 있는 일련의 기술입니다. AI는 현대적인 컴퓨팅 혁신에서 중추적인 역할을 하며 개인과 비즈니스의 가치를 창출합니다. 예를 들어 광학 문자 인식(OCR)은 AI를 사용해 이미지 및 문서에서 텍스트 및 데이터를 추출하고, 구조화되지 않은 콘텐츠를 비즈니스에 바로 사용할 수 있게 만들고, 유용한 정보를 창출합니다.\"\n",
    "\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "54595e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 인공지능은 일반적으로 인간의 지능이 필요하거나 인간이 분석할 수 있는 것보다 규모가 큰 데이터를 포함하는 방식으로 추론, 학습 및 행동할 수 있는 컴퓨터 및 기계를 구축하는 것과 관련된 과학 분야입니다. AI는 컴퓨터 공학, 데이터 분석 및 통계, 하드웨어 및 소프트웨어 엔지니어링, 언어학, 신경 과학은 물론 철학과 심리학을 포함하여 여러 학문을 포괄하는 광범위한 분야입니다. 비즈니스의 운영 수준에서 AI는 주로 머신러닝과 딥 러닝을 기반으로 하는 기술 모음으로, 데이터 분석, 예상 및 예측, 객체 분류, 자연어 처리, 추천, 지능형 데이터 가져오기 등을 수행할 수 있습니다.\n",
      "reward score: 5.1\n"
     ]
    }
   ],
   "source": [
    "input_text = \"인공지능은 일반적으로 인간의 지능이 필요하거나 인간이 분석할 수 있는 것보다 규모가 큰 데이터를 포함하는 방식으로 추론, 학습 및 행동할 수 있는 컴퓨터 및 기계를 구축하는 것과 관련된 과학 분야입니다. AI는 컴퓨터 공학, 데이터 분석 및 통계, 하드웨어 및 소프트웨어 엔지니어링, 언어학, 신경 과학은 물론 철학과 심리학을 포함하여 여러 학문을 포괄하는 광범위한 분야입니다. 비즈니스의 운영 수준에서 AI는 주로 머신러닝과 딥 러닝을 기반으로 하는 기술 모음으로, 데이터 분석, 예상 및 예측, 객체 분류, 자연어 처리, 추천, 지능형 데이터 가져오기 등을 수행할 수 있습니다.\"\n",
    "\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b237bdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90fd686",
   "metadata": {},
   "source": [
    "## Proximal Policy Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "67cb884d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from chatgpt.models.base import RewardModel\n",
    "from chatgpt.models.gpt import GPTActor, GPTCritic\n",
    "from chatgpt.trainer import PPOTrainer\n",
    "from chatgpt.trainer.strategies import NaiveStrategy\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5c0d8cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with NaiveStrategy().model_init_context():\n",
    "    actor = GPTActor(pretrained='/aiffel/KoChatGPT/output_1_SFT', lora_rank=0).to(torch.cuda.current_device())\n",
    "    critic = GPTCritic(pretrained='aiffel/KoChatGPT/output_2_RM', lora_rank=0).to(torch.cuda.current_device())\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        'skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "        padding_side=\"right\", \n",
    "        model_max_length=512\n",
    "    )\n",
    "\n",
    "    initial_model = deepcopy(actor)\n",
    "    reward_model = RewardModel(deepcopy(critic.model), deepcopy(critic.value_head)).to(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f36ff6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델학습에 사용할 옵티마이저와 모델을 준비합니다.\n",
    "actor_optim = Adam(actor.parameters(), lr=5e-6)\n",
    "critic_optim = Adam(critic.parameters(), lr=5e-6)\n",
    "(actor, actor_optim), (critic, critic_optim), reward_model, initial_model = NaiveStrategy().prepare(\n",
    "    (actor, actor_optim), (critic, critic_optim), reward_model, initial_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "34970491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PPO 학습에 쓸 데이터를 불러와 토크나이징 해줍니다.\n",
    "with open('/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_3_PPO.jsonl', \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "    list_prompt = [tmp['prompt'] for tmp in list_data_dict]\n",
    "\n",
    "def tokenize_fn(texts):\n",
    "    batch = tokenizer(texts, return_tensors='pt', max_length=96, padding=True, truncation=True)\n",
    "    return {k: v.cuda() for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eb44b8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[47311, 10448, 19008,  9792, 11780, 11308, 30190, 10929, 11849, 21663,\n",
      "         44389,  9574, 13799,   458, 14308, 12778, 22469, 20938, 44696,   458,\n",
      "         13799,   458, 14308, 12778, 11756, 18944,   389]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "print(tokenize_fn('It takes something more than intelligence to act intelligently.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "824e39aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a5bcfa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PPO는 별도의 PPOTrainer 클래스를 설계하여 학습\n",
    "trainer = PPOTrainer(NaiveStrategy(),\n",
    "                     actor,\n",
    "                     critic,\n",
    "                     reward_model,\n",
    "                     initial_model,\n",
    "                     actor_optim,\n",
    "                     critic_optim,\n",
    "                     max_epochs=3,  \n",
    "                     train_batch_size=8, \n",
    "                     tokenizer=tokenize_fn,\n",
    "                     max_length=128,\n",
    "                     do_sample=True,\n",
    "                     temperature=1.0,\n",
    "                     top_k=50,\n",
    "                     pad_token_id=tokenizer.pad_token_id,\n",
    "                     eos_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0a60bcd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Episode [1/10]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Episode [1/10]:  33%|███▎      | 1/3 [00:06<00:12,  6.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "Episode [1/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0, critic_loss=0.0022]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.87it/s, actor_loss=0, critic_loss=0.0022]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.87it/s, actor_loss=0, critic_loss=0.0867]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.91it/s, actor_loss=0, critic_loss=0.0867]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.91it/s, actor_loss=0, critic_loss=0.00161]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]: 100%|██████████| 3/3 [00:01<00:00,  1.91it/s, actor_loss=0, critic_loss=0.00161]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0, critic_loss=0.0263]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.93it/s, actor_loss=0, critic_loss=0.0263]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.93it/s, actor_loss=0, critic_loss=0.0683]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.93it/s, actor_loss=0, critic_loss=0.0683]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.93it/s, actor_loss=0, critic_loss=0.0278]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]: 100%|██████████| 3/3 [00:01<00:00,  1.93it/s, actor_loss=0, critic_loss=0.0278]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0, critic_loss=0.00145]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.93it/s, actor_loss=0, critic_loss=0.00145]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.93it/s, actor_loss=0, critic_loss=0.00544]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.92it/s, actor_loss=0, critic_loss=0.00544]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.92it/s, actor_loss=0, critic_loss=0.0319] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]: 100%|██████████| 3/3 [00:01<00:00,  1.92it/s, actor_loss=0, critic_loss=0.0319]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Episode [1/10]: 100%|██████████| 3/3 [00:22<00:00,  7.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Episode [2/10]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Episode [2/10]:  33%|███▎      | 1/3 [00:05<00:11,  5.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "Episode [2/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.138, critic_loss=0.0348]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.87it/s, actor_loss=-.138, critic_loss=0.0348]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.87it/s, actor_loss=-.131, critic_loss=0.0139]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=-.131, critic_loss=0.0139]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=-.156, critic_loss=0.00373]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]: 100%|██████████| 3/3 [00:01<00:00,  1.86it/s, actor_loss=-.156, critic_loss=0.00373]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.163, critic_loss=0.00647]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.88it/s, actor_loss=-.163, critic_loss=0.00647]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.88it/s, actor_loss=-.147, critic_loss=0.0134] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=-.147, critic_loss=0.0134]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=-.152, critic_loss=0.0271]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]: 100%|██████████| 3/3 [00:01<00:00,  1.87it/s, actor_loss=-.152, critic_loss=0.0271]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.161, critic_loss=0.0162]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.89it/s, actor_loss=-.161, critic_loss=0.0162]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.89it/s, actor_loss=-.163, critic_loss=0.00358]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=-.163, critic_loss=0.00358]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=-.151, critic_loss=0.0025] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]: 100%|██████████| 3/3 [00:01<00:00,  1.87it/s, actor_loss=-.151, critic_loss=0.0025]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Episode [2/10]: 100%|██████████| 3/3 [00:22<00:00,  7.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Episode [3/10]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Episode [3/10]:  33%|███▎      | 1/3 [00:05<00:11,  5.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "Episode [3/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.84s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.07, critic_loss=0.00813]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.89it/s, actor_loss=-.07, critic_loss=0.00813]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.89it/s, actor_loss=-.0682, critic_loss=0.0116]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.90it/s, actor_loss=-.0682, critic_loss=0.0116]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.90it/s, actor_loss=-.0609, critic_loss=0.0232]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]: 100%|██████████| 3/3 [00:01<00:00,  1.89it/s, actor_loss=-.0609, critic_loss=0.0232]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0642, critic_loss=0.00405]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.90it/s, actor_loss=-.0642, critic_loss=0.00405]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.90it/s, actor_loss=-.0727, critic_loss=0.00286]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.89it/s, actor_loss=-.0727, critic_loss=0.00286]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.89it/s, actor_loss=-.063, critic_loss=0.00424] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]: 100%|██████████| 3/3 [00:01<00:00,  1.89it/s, actor_loss=-.063, critic_loss=0.00424]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.074, critic_loss=0.00771]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.89it/s, actor_loss=-.074, critic_loss=0.00771]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.89it/s, actor_loss=-.0581, critic_loss=0.0103]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.89it/s, actor_loss=-.0581, critic_loss=0.0103]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.89it/s, actor_loss=-.0748, critic_loss=0.00685]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]: 100%|██████████| 3/3 [00:01<00:00,  1.90it/s, actor_loss=-.0748, critic_loss=0.00685]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Episode [3/10]: 100%|██████████| 3/3 [00:22<00:00,  7.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Episode [4/10]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Episode [4/10]:  33%|███▎      | 1/3 [00:05<00:11,  5.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "Episode [4/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.307, critic_loss=0.499]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.90it/s, actor_loss=0.307, critic_loss=0.499]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.90it/s, actor_loss=0.524, critic_loss=0.457]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.90it/s, actor_loss=0.524, critic_loss=0.457]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.90it/s, actor_loss=0.18, critic_loss=0.11]  \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]: 100%|██████████| 3/3 [00:01<00:00,  1.89it/s, actor_loss=0.18, critic_loss=0.11]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.2, critic_loss=0.137]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.92it/s, actor_loss=0.2, critic_loss=0.137]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.92it/s, actor_loss=0.163, critic_loss=0.189]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.91it/s, actor_loss=0.163, critic_loss=0.189]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.91it/s, actor_loss=0.523, critic_loss=0.597]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]: 100%|██████████| 3/3 [00:01<00:00,  1.91it/s, actor_loss=0.523, critic_loss=0.597]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.479, critic_loss=0.536]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.92it/s, actor_loss=0.479, critic_loss=0.536]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.92it/s, actor_loss=0.118, critic_loss=0.0663]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.90it/s, actor_loss=0.118, critic_loss=0.0663]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.90it/s, actor_loss=0.203, critic_loss=0.189] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]: 100%|██████████| 3/3 [00:01<00:00,  1.90it/s, actor_loss=0.203, critic_loss=0.189]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Episode [4/10]: 100%|██████████| 3/3 [00:21<00:00,  7.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Episode [5/10]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Episode [5/10]:  33%|███▎      | 1/3 [00:05<00:11,  5.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "Episode [5/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.73s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0411, critic_loss=0.00324]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.88it/s, actor_loss=-.0411, critic_loss=0.00324]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.88it/s, actor_loss=-.0373, critic_loss=0.00182]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=-.0373, critic_loss=0.00182]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=0.0696, critic_loss=0.0974] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]: 100%|██████████| 3/3 [00:01<00:00,  1.88it/s, actor_loss=0.0696, critic_loss=0.0974]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0393, critic_loss=0.0224]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.88it/s, actor_loss=-.0393, critic_loss=0.0224]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.88it/s, actor_loss=0.0746, critic_loss=0.114] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=0.0746, critic_loss=0.114]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=-.0298, critic_loss=0.00593]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]: 100%|██████████| 3/3 [00:01<00:00,  1.87it/s, actor_loss=-.0298, critic_loss=0.00593]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0253, critic_loss=0.00227]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.87it/s, actor_loss=-.0253, critic_loss=0.00227]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.87it/s, actor_loss=-.0585, critic_loss=0.016]  \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=-.0585, critic_loss=0.016]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=0.0434, critic_loss=0.0566]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]: 100%|██████████| 3/3 [00:01<00:00,  1.87it/s, actor_loss=0.0434, critic_loss=0.0566]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Episode [5/10]: 100%|██████████| 3/3 [00:22<00:00,  7.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Episode [6/10]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Episode [6/10]:  33%|███▎      | 1/3 [00:05<00:11,  5.81s/it]\u001b[A\u001b[A\n",
      "\n",
      "Episode [6/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0852, critic_loss=0.00498]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.87it/s, actor_loss=-.0852, critic_loss=0.00498]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.87it/s, actor_loss=-.0802, critic_loss=0.013]  \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=-.0802, critic_loss=0.013]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=-.071, critic_loss=0.0114]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]: 100%|██████████| 3/3 [00:01<00:00,  1.87it/s, actor_loss=-.071, critic_loss=0.0114]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0815, critic_loss=0.00334]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.87it/s, actor_loss=-.0815, critic_loss=0.00334]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.87it/s, actor_loss=-.0753, critic_loss=0.00294]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=-.0753, critic_loss=0.00294]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=-.0824, critic_loss=0.00378]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]: 100%|██████████| 3/3 [00:01<00:00,  1.86it/s, actor_loss=-.0824, critic_loss=0.00378]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0668, critic_loss=0.00611]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.85it/s, actor_loss=-.0668, critic_loss=0.00611]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.85it/s, actor_loss=-.075, critic_loss=0.00455] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.85it/s, actor_loss=-.075, critic_loss=0.00455]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.85it/s, actor_loss=-.0965, critic_loss=0.00852]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]: 100%|██████████| 3/3 [00:01<00:00,  1.86it/s, actor_loss=-.0965, critic_loss=0.00852]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Episode [6/10]: 100%|██████████| 3/3 [00:22<00:00,  7.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Episode [7/10]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Episode [7/10]:  33%|███▎      | 1/3 [00:05<00:11,  5.86s/it]\u001b[A\u001b[A\n",
      "\n",
      "Episode [7/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.179, critic_loss=0.132]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.88it/s, actor_loss=0.179, critic_loss=0.132]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.88it/s, actor_loss=0.0381, critic_loss=0.00215]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=0.0381, critic_loss=0.00215]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=0.0215, critic_loss=0.0112] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]: 100%|██████████| 3/3 [00:01<00:00,  1.88it/s, actor_loss=0.0215, critic_loss=0.0112]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.143, critic_loss=0.134]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.89it/s, actor_loss=0.143, critic_loss=0.134]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.89it/s, actor_loss=0.0216, critic_loss=0.0114]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=0.0216, critic_loss=0.0114]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=0.0408, critic_loss=0.00935]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]: 100%|██████████| 3/3 [00:01<00:00,  1.88it/s, actor_loss=0.0408, critic_loss=0.00935]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.02, critic_loss=0.0128]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.88it/s, actor_loss=0.02, critic_loss=0.0128]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.88it/s, actor_loss=0.142, critic_loss=0.115]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.89it/s, actor_loss=0.142, critic_loss=0.115]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.89it/s, actor_loss=0.0336, critic_loss=0.00414]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]: 100%|██████████| 3/3 [00:01<00:00,  1.88it/s, actor_loss=0.0336, critic_loss=0.00414]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Episode [7/10]: 100%|██████████| 3/3 [00:22<00:00,  7.37s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Episode [8/10]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Episode [8/10]:  33%|███▎      | 1/3 [00:05<00:11,  5.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "Episode [8/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.042, critic_loss=0.0118]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.87it/s, actor_loss=-.042, critic_loss=0.0118]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.87it/s, actor_loss=0.0561, critic_loss=0.0204]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=0.0561, critic_loss=0.0204]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=-.00209, critic_loss=0.00125]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]: 100%|██████████| 3/3 [00:01<00:00,  1.86it/s, actor_loss=-.00209, critic_loss=0.00125]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.00558, critic_loss=0.0206]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.90it/s, actor_loss=-.00558, critic_loss=0.0206]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.90it/s, actor_loss=-.0225, critic_loss=0.0123] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=-.0225, critic_loss=0.0123]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=0.0216, critic_loss=0.00201]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]: 100%|██████████| 3/3 [00:01<00:00,  1.88it/s, actor_loss=0.0216, critic_loss=0.00201]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.0408, critic_loss=0.0111]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.88it/s, actor_loss=0.0408, critic_loss=0.0111]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.88it/s, actor_loss=-.0528, critic_loss=0.0232]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=-.0528, critic_loss=0.0232]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=-.00255, critic_loss=0.00259]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]: 100%|██████████| 3/3 [00:01<00:00,  1.88it/s, actor_loss=-.00255, critic_loss=0.00259]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Episode [8/10]: 100%|██████████| 3/3 [00:22<00:00,  7.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Episode [9/10]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Episode [9/10]:  33%|███▎      | 1/3 [00:05<00:11,  5.88s/it]\u001b[A\u001b[A\n",
      "\n",
      "Episode [9/10]:  67%|██████▋   | 2/3 [00:10<00:05,  5.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0675, critic_loss=0.00991]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.89it/s, actor_loss=-.0675, critic_loss=0.00991]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.89it/s, actor_loss=-.0751, critic_loss=0.0138] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=-.0751, critic_loss=0.0138]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=-.00192, critic_loss=0.00939]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]: 100%|██████████| 3/3 [00:01<00:00,  1.87it/s, actor_loss=-.00192, critic_loss=0.00939]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0753, critic_loss=0.00829]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.91it/s, actor_loss=-.0753, critic_loss=0.00829]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.91it/s, actor_loss=-.0181, critic_loss=0.00976]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=-.0181, critic_loss=0.00976]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=-.0518, critic_loss=0.0076] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]: 100%|██████████| 3/3 [00:01<00:00,  1.87it/s, actor_loss=-.0518, critic_loss=0.0076]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0595, critic_loss=0.00444]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.88it/s, actor_loss=-.0595, critic_loss=0.00444]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.88it/s, actor_loss=-.0192, critic_loss=0.000597]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=-.0192, critic_loss=0.000597]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=-.0683, critic_loss=0.0108]  \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]: 100%|██████████| 3/3 [00:01<00:00,  1.87it/s, actor_loss=-.0683, critic_loss=0.0108]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Episode [9/10]: 100%|██████████| 3/3 [00:20<00:00,  6.99s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Episode [10/10]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Episode [10/10]:  33%|███▎      | 1/3 [00:05<00:11,  5.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "Episode [10/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0578, critic_loss=0.00592]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.88it/s, actor_loss=-.0578, critic_loss=0.00592]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.88it/s, actor_loss=-.0519, critic_loss=0.0141] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=-.0519, critic_loss=0.0141]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=-.0442, critic_loss=0.0126]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/3]: 100%|██████████| 3/3 [00:01<00:00,  1.87it/s, actor_loss=-.0442, critic_loss=0.0126]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0466, critic_loss=0.00408]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.90it/s, actor_loss=-.0466, critic_loss=0.00408]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.90it/s, actor_loss=-.0385, critic_loss=0.0145] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=-.0385, critic_loss=0.0145]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=-.0593, critic_loss=0.00516]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [2/3]: 100%|██████████| 3/3 [00:01<00:00,  1.89it/s, actor_loss=-.0593, critic_loss=0.00516]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0221, critic_loss=0.0054]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:00<00:01,  1.88it/s, actor_loss=-.0221, critic_loss=0.0054]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:  33%|███▎      | 1/3 [00:01<00:01,  1.88it/s, actor_loss=-.0355, critic_loss=0.00137]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=-.0355, critic_loss=0.00137]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=-.0982, critic_loss=0.00729]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [3/3]: 100%|██████████| 3/3 [00:01<00:00,  1.88it/s, actor_loss=-.0982, critic_loss=0.00729]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Episode [10/10]: 100%|██████████| 3/3 [00:20<00:00,  6.87s/it]\u001b[A\u001b[A\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(list_prompt, \n",
    "            num_episodes=10,  \n",
    "            max_timesteps=3,\n",
    "            update_timesteps=3)\n",
    "\n",
    "model.save_pretrained('aiffel/KoChatGPT/output_3_PPO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "59ab1a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Instruction(명령어):\n",
      "불고기용 고기 한우에요?\n",
      "\n",
      "### Response(응답):'불고기용 고기는 한국에서 판매하는 식당 중 하나입니다. 국내에는 대형마트나 슈퍼마켓에서 판매하며, 주로 한우 안심, 삼겹, 육등급우 안심 등을 판매합니다. 특히 일부 식당은 한우 부위에서 고기를 구매할 수 있는 경우도 많습니다. 이는 소비자들에게 매우 편리한 상품입니다!川 nye니다.川 no tonoung setai\\'s soes on.?\\n\\n다음은 \"불고기용 고기의 맛에 대한 가격\"입니다.川 no like apply price and more equie neutral which important served.\\n\\n\\n만약 지역에서 판매되는 고기 중 어느 하나가 한우 안심, 삼겹, 육등급우 등등 다른 고기의 고기 한 가지보다 비싸다고 할 수 있습니다. 예를 들어 고기 한 번으로 살만한 고기도 있고, 아니면 고기나 야채 등의 채소를 함께 구매하는 경우에는 가격 차이가 있을 수 있습니다. yo like your price any\n",
      "\n",
      "### Instruction(명령어):\n",
      "리처드 닉슨이 43대 부통령직을 수행한 년도는?\n",
      "\n",
      "### Response(응답):'리처드 닉슨이 38대 부통령직을 수행한 년도는 1951년이다. 그는 부통령 취임 후 1962년까지 부통령직을 수행하였다. 그는 후에 부통령직을 맡게 되었다.\\n\\n그러나 정확한 년도는 알려지지 않았다. 닉슨은 1967년 대통령 선거에서 공화당 후보자로 출마하였지만, 공화당 후보가 당선되지 않았다는 보도가 있었다.\\n\\n그래서 닉슨은 부통령직을 수행하지 않았을 가능성이 있다.\\n\\n그러나 다른 여러 이유로 인해 부통령직을 맡았던 기간은 짧았다. \\n\\n위와 같은 연구들에 따르면, 킹은 48대였음에도 부통령직을 수행했다는 점은 알려져 있지 않다. 承林\\n하지만 이는 역사상 가장 최근의 사실이다.震)는 1963년 대통령 선거에서 이긴 것으로 알려져 있다. 先定은 닉슨의 취임 시기에 대해 매우 깊은 연구를 한 것이며, 이를 이용하여 그의 경험과 업적을 증명하였을 것이다.寶는 그의 대통령 선거에서 승리하였다. 寶는 킹의 대선 득표수의 한 부분이다. 眞은 닉슨이 대통령 선거에서 패배한 것에 대한 자세한 사항은 알지 못하다. 은유는 그의 아버지인 킹이 39\n",
      "\n",
      "### Instruction(명령어):\n",
      "시카고 오헤어 국제공항은 어디에 있어\n",
      "\n",
      "### Response(응답):'시카고 오헤어 국제공항은 시카고 시카고 국제공항입니다.恩京 국제공항에 위치해 있으며, 항공편들이 대부분 시카고에 있어요.銀京 국제공항은 항공편들이 모두 가능하지만, 각 국제공항이 운영하는 항공편들은 대부분 시카고 국제공항에서 출발하며, 일부 구간에서는 다른 기점이 배정됩니다.日報)은 현재 위치나 위치에 대한 정보가 없어서 정확한 위치를 파악하기는 어렵습니다.恩京新聞(香京日報), 新聞共和(新聞日報) 등에서도 확인하실 수 있습니다.英日報(香京日報) 등에서 확인하실 수 있습니다.實日報)에서도 같은 구간을 이용하는 항공편이 많습니다.實日報)에 참고하시기 바랍니다.峰香銀京新聞(香港日報)에서도 시카고 국제공항에 대한 정보를 찾으실 수 있습니다.實報導身(香京日報) 역시 시카고 국제공항의 위치를 찾을 수 있습니다.恩日報(香港日報) 또한 시카고 국제공항의 위치, 위치, 위치를 살펴보기 위해서 검색해보시는 구간을 추천합니다.視)는 지역정보를 제공하여 해당 지역의 항공사진을 볼 수\n",
      "\n",
      "### Instruction(명령어):\n",
      "오늘 미세먼지 어때?\n",
      "\n",
      "### Response(응답):'제가 인공지능 로봇으로 프로그래밍되어 있어서 정확한 정보를 전달하지 못하지만, 미세먼지 예보를 위해서는 적절한 미세먼지 농도를 준수하는 것이 중요합니다. 미세먼지 경보제는 미세먼지 농도가 높은 날이면 라디오나 인터넷 등에서 미세먼지 정보를 전달하며 큰 도움을 줄 수 있습니다. 하지만 일반적으로 날씨가 더 건조하거나 매우 심한 미세먼지 문제를 유발할 수 있으므로 주의가 필요합니다.試)는 \"미세먼지 예보\"라는 뜻으로 불리며, 미세먼지 농도를 측정하는 인공지능 기반의 자연어 처리 기술을 개발하고 있습니다. 이러한 기술은 미세먼지 농도를 감지하는 시스템을 구축하는 데 매우 중요한 역할을 합니다.試報恩\\에 따르면, 미세먼지 농도가 높은 날에는 야외활동을 줄이고, 실외활동을 줄이며 미세먼지 농도를 측정해 드립니다.輩恩自適 적으로 관리하여 건강에 영향을 미치지 않는 것이 좋습니다.寶恩)는 \"미세먼지 예보\"라는 뜻으로 사용되며, 미세먼지 경보에서 사용되는 기술을 개발할 때 널리 사용되는 기술입니다.?는 미세먼지 농도를 이용하여 미세먼지 농도를\n"
     ]
    }
   ],
   "source": [
    "# RLHF가 적용된 koGPT-2의 생성능력을 확인\n",
    "\n",
    "def generation(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
    "        torch.cuda.current_device())\n",
    "    outputs = actor.generate(input_ids,\n",
    "                             max_length=250,\n",
    "                             do_sample=True,\n",
    "                             top_k=50,\n",
    "                             top_p=0.95,\n",
    "                             num_return_sequences=1)\n",
    "    output = tokenizer.batch_decode(outputs[0], skip_special_tokens=True)[0]\n",
    "    print()\n",
    "    print(output)\n",
    "    return output\n",
    "\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "    )\n",
    "}\n",
    "\n",
    "list_prompt = [\n",
    "    '불고기용 고기 한우에요?', \n",
    "    '리처드 닉슨이 43대 부통령직을 수행한 년도는?', \n",
    "    '시카고 오헤어 국제공항은 어디에 있어',\n",
    "    '오늘 미세먼지 어때?']\n",
    "\n",
    "list_prompt = [PROMPT_DICT['prompt_input'].format_map({'prompt': tmp}) for tmp in list_prompt]\n",
    "\n",
    "for input_text in list_prompt:\n",
    "    output = generation(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21c2a424",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3e80ed",
   "metadata": {},
   "source": [
    "# KoChatGPT Upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba4a2b1",
   "metadata": {},
   "source": [
    "- 기존 데이터셋 추가 정제\n",
    "- foundation model 교체 -> skt/ko-gpt-trinity-1.2B-v0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "719ebcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import json \n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_name = \"skt/ko-gpt-trinity-1.2B-v0.5\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ef6981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "def load_and_clean_data(data_path, encoding='utf-8-sig'):\n",
    "    # 파일 로드\n",
    "    with open(data_path, \"r\", encoding=encoding) as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    # 데이터 정제\n",
    "    cleaned_data = []\n",
    "    for item in data:\n",
    "        prompt = item['prompt'].strip()  # 불필요한 공백 제거\n",
    "        completion = item.get('completion', '').strip()  # completion이 없는 경우를 고려\n",
    "        # 필요한 경우 여기에 특수 문자 제거 등의 추가 정제 과정을 적용\n",
    "        cleaned_data.append({'prompt': prompt, 'completion': completion})\n",
    "    \n",
    "    return cleaned_data\n",
    "\n",
    "# 파일 경로\n",
    "data_path_1_SFT = '/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_1_SFT.jsonl'\n",
    "data_path_2_RM = '/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_2_RM.jsonl'\n",
    "data_path_3_PPO = '/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_3_PPO.jsonl'\n",
    "\n",
    "# 데이터 로드 및 정제\n",
    "cleaned_data_sft = load_and_clean_data(data_path_1_SFT)\n",
    "cleaned_data_rm = load_and_clean_data(data_path_2_RM)\n",
    "cleaned_data_ppo = load_and_clean_data(data_path_3_PPO)\n",
    "\n",
    "# 첫 번째 정제된 항목 출력\n",
    "print(cleaned_data_sft[0])\n",
    "print(cleaned_data_rm[0])\n",
    "print(cleaned_data_ppo[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07d2a8f",
   "metadata": {},
   "source": [
    "### Dataset EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b44937a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def analyze_length_distribution(data):\n",
    "    # 문장의 길이(토큰 개수)를 저장할 리스트\n",
    "    prompt_lengths = [len(item['prompt'].split()) for item in data]\n",
    "    completion_lengths = [len(item['completion'].split()) for item in data if item['completion'] != '']\n",
    "\n",
    "    # 길이 분포 시각화\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(prompt_lengths, bins=20, color='skyblue')\n",
    "    plt.title('Prompt Length Distribution')\n",
    "    plt.xlabel('Length')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(completion_lengths, bins=20, color='orange')\n",
    "    plt.title('Completion Length Distribution')\n",
    "    plt.xlabel('Length')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# 각 데이터셋에 대한 길이 분포 분석\n",
    "analyze_length_distribution(cleaned_data_sft)\n",
    "analyze_length_distribution(cleaned_data_rm)\n",
    "analyze_length_distribution(cleaned_data_ppo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448bfde5",
   "metadata": {},
   "source": [
    "## SFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7c5f5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim import Adam\n",
    "from datasets import load_dataset\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from copy import deepcopy\n",
    "import copy\n",
    "import logging\n",
    "import json\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c82eb1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2TokenizerFast(name_or_path='skt/ko-gpt-trinity-1.2B-v0.5', vocab_size=51200, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '</s>', 'eos_token': '</s>', 'unk_token': '</s>', 'pad_token': '</s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True)\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name, bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "    padding_side=\"right\",\n",
    "    model_max_length=512,\n",
    ")\n",
    "\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a93b02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Dict, Sequence\n",
    "\n",
    "class SFT_dataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_path_1_SFT: str, tokenizer: transformers.PreTrainedTokenizer, verbose=False):\n",
    "        super(SFT_dataset, self).__init__()\n",
    "        logging.warning(\"Loading data...\")\n",
    "\n",
    "        pattern_instruction = 'prompt'  # instruction\n",
    "        pattern_output = 'completion'  # response\n",
    "\n",
    "        with open(data_path_1_SFT, \"r\", encoding='utf-8-sig') as json_file:\n",
    "            list_data_dict = json.load(json_file)\n",
    "\n",
    "        PROMPT_DICT = {\n",
    "            \"prompt_input\": (\n",
    "                \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "            )\n",
    "        }\n",
    "\n",
    "        prompt_input = PROMPT_DICT[\"prompt_input\"]\n",
    "\n",
    "        sources = []\n",
    "        for example in list_data_dict:\n",
    "            tmp = prompt_input.format_map(example)\n",
    "            sources.append(tmp)\n",
    "\n",
    "        targets = []\n",
    "        for example in list_data_dict:\n",
    "            targets.append(f\"{example[pattern_output]}{tokenizer.eos_token}\")\n",
    "        examples = [s + t for s, t in zip(sources, targets)]\n",
    "\n",
    "        sources_tokenized = self._tokenize_fn(sources, tokenizer)  # source\n",
    "        examples_tokenized = self._tokenize_fn(examples, tokenizer)  # source + target\n",
    "\n",
    "        input_ids = examples_tokenized[\"input_ids\"]\n",
    "        labels = copy.deepcopy(input_ids)\n",
    "        for label, source_len in zip(labels, sources_tokenized[\"input_ids_lens\"]):\n",
    "            label[:source_len] = -100\n",
    "\n",
    "        data_dict = dict(input_ids=input_ids, labels=labels)\n",
    "\n",
    "        self.input_ids = data_dict[\"input_ids\"]\n",
    "        self.labels = data_dict[\"labels\"]\n",
    "        logging.warning(\"Loading data done!!: %d\"%(len(self.labels)))\n",
    "\n",
    "\n",
    "    def _tokenize_fn(self, strings: Sequence[str], tokenizer: transformers.PreTrainedTokenizer) -> Dict:\n",
    "        tokenized_list = [\n",
    "            tokenizer(\n",
    "                text,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=\"longest\",\n",
    "                max_length=tokenizer.model_max_length,\n",
    "                truncation=True,\n",
    "            )\n",
    "            for text in strings\n",
    "        ]\n",
    "        input_ids = labels = [tokenized.input_ids[0] for tokenized in tokenized_list]\n",
    "        input_ids_lens = labels_lens = [\n",
    "            tokenized.input_ids.ne(tokenizer.pad_token_id).sum().item() for tokenized in tokenized_list\n",
    "        ]\n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            input_ids_lens=input_ids_lens,\n",
    "            labels_lens=labels_lens,\n",
    "        )\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "\n",
    "    def __getitem__(self, i) -> Dict[str, torch.Tensor]:\n",
    "        return dict(input_ids=self.input_ids[i], labels=self.labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc03f4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorForSupervisedDataset(object): \n",
    "\n",
    "    tokenizer: transformers.PreTrainedTokenizer\n",
    "\n",
    "    def __call__(self, instances: Sequence[Dict]) -> Dict[str, torch.Tensor]:\n",
    "        input_ids, labels = tuple([instance[key] for instance in instances] for key in (\"input_ids\", \"labels\"))\n",
    "        input_ids = torch.nn.utils.rnn.pad_sequence(\n",
    "            input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id\n",
    "        )\n",
    "        labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value= -100)\n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            attention_mask=input_ids.ne(self.tokenizer.pad_token_id),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d1c8982",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Loading data...\n",
      "WARNING:root:Loading data done!!: 12000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input : tensor([30132, 42872, 33313, 30679, 40479, 39911,   384, 22509, 21921, 25372,\n",
      "          385, 31245, 23280, 34957, 25617, 36539, 29991, 25624, 25400, 31167,\n",
      "          376, 42872,   379, 46803,   456, 30303, 35353,   384, 25785, 20573,\n",
      "        37780,   383, 46900, 43226,   565, 27071, 23151, 31555, 41690, 35071,\n",
      "        25400, 31269, 32677, 30765, 31810, 36229, 30326, 33889, 30093, 34957,\n",
      "        25617, 30021, 30434, 29991, 39687, 34036, 19016, 31997, 49906, 19352,\n",
      "        30011, 30904, 36731, 43502, 30228, 31214, 30326, 29991, 31621, 33314,\n",
      "        34347, 30843, 50342, 33512, 31370, 34243, 29991, 35144, 32586, 32622,\n",
      "        44680, 30110, 21844, 39826, 34803, 31356, 39075, 30242, 36966, 29985,\n",
      "        34179, 36513, 30718, 35557, 32361, 31018, 29404, 35942, 19352, 41049,\n",
      "            1])\n",
      "output: tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,   383, 46900, 43226,   565, 27071, 23151, 31555, 41690, 35071,\n",
      "        25400, 31269, 32677, 30765, 31810, 36229, 30326, 33889, 30093, 34957,\n",
      "        25617, 30021, 30434, 29991, 39687, 34036, 19016, 31997, 49906, 19352,\n",
      "        30011, 30904, 36731, 43502, 30228, 31214, 30326, 29991, 31621, 33314,\n",
      "        34347, 30843, 50342, 33512, 31370, 34243, 29991, 35144, 32586, 32622,\n",
      "        44680, 30110, 21844, 39826, 34803, 31356, 39075, 30242, 36966, 29985,\n",
      "        34179, 36513, 30718, 35557, 32361, 31018, 29404, 35942, 19352, 41049,\n",
      "            1])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SFT_dataset(data_path_1_SFT='/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_1_SFT.jsonl', tokenizer=tokenizer)\n",
    "data_collator = DataCollatorForSupervisedDataset(tokenizer=tokenizer)\n",
    "\n",
    "print('input : %s'%train_dataset.input_ids[0])\n",
    "print('output: %s'%train_dataset.labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6771f638",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/aiffel/KoChatGPT/test\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    warmup_steps=5,\n",
    "    prediction_loss_only=True,\n",
    "    fp16 = True\n",
    "    )\n",
    "\n",
    "# 모델을 GPU로 옮기기 전 fp16 사용 설정\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "model.to(device)  # 모델을 GPU로 옮기기\n",
    "model.half()  # 모델을 16비트 정밀도로 설정\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1148e0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "model.save_pretrained('/aiffel/KoChatGPT/output_1_SFT_UG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be8fd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline('text-generation', model='/aiffel/KoChatGPT/output_1_SFT', tokenizer=tokenizer)\n",
    "\n",
    "generation_args = dict(   \n",
    "    num_beams=4,\n",
    "    repetition_penalty=2.0,\n",
    "    no_repeat_ngram_size=4,\n",
    "    eos_token_id=375, # \\n   \n",
    "    max_new_tokens=64,\n",
    "    do_sample=True,\n",
    "    top_k=50,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "    )\n",
    "}\n",
    "\n",
    "list_prompt = ['불고기용 고기 한우에요?',\n",
    "               '리처드 닉슨이 43대 부통령직을 수행한 년도는?',\n",
    "               '시카고 오헤어 국제공항은 어디에 있어?',\n",
    "               '오늘 미세먼지 어때?']\n",
    "\n",
    "list_prompt = [PROMPT_DICT['prompt_input'].format_map({'prompt' : tmp}) for tmp in list_prompt]\n",
    "\n",
    "list_result = generator(list_prompt, **generation_args)   \n",
    "for prompt, result in zip(list_prompt, list_result):\n",
    "    print()\n",
    "    print((result[0]['generated_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c26a398",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d137646",
   "metadata": {},
   "source": [
    "## RM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af6e6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/aiffel/KoChatGPT/colossalai_ChatGPT_230319')\n",
    "\n",
    "import os\n",
    "import json\n",
    "from typing import Optional\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from chatgpt.dataset import RewardDataset\n",
    "from chatgpt.models.base import RewardModel\n",
    "from chatgpt.trainer import RewardModelTrainer\n",
    "from chatgpt.trainer.strategies import NaiveStrategy\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModel, AutoConfig\n",
    "from transformers.models.gpt2.configuration_gpt2 import GPT2Config\n",
    "from transformers.models.gpt2.modeling_gpt2 import GPT2Model\n",
    "import loralib as lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56df20c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTRM_custom(RewardModel):\n",
    "\n",
    "    def __init__(self,\n",
    "                 pretrained: Optional[str] = None,\n",
    "                 config: Optional[GPT2Config] = None,\n",
    "                 checkpoint: bool = False,\n",
    "                 lora_rank: int = 0,\n",
    "                 lora_train_bias: str = 'none',\n",
    "                 tokenizer=None) -> None:\n",
    "        if pretrained is not None:\n",
    "            model = GPT2Model.from_pretrained(pretrained)\n",
    "            model.resize_token_embeddings(len(tokenizer))\n",
    "        elif config is not None:\n",
    "            model = GPT2Model(config)\n",
    "        else:\n",
    "            model = GPT2Model(GPT2Config())\n",
    "        if checkpoint:\n",
    "            model.gradient_checkpointing_enable()\n",
    "\n",
    "        value_head = nn.Linear(model.config.n_embd, 1)\n",
    "        super().__init__(model, value_head, lora_rank, lora_train_bias)\n",
    "\n",
    "        if pretrained is not None:\n",
    "            self.model = model\n",
    "            self.pretrained = pretrained\n",
    "\n",
    "\n",
    "    def save_pretrained(self, dir):\n",
    "        if self.pretrained is not None:\n",
    "            self.model.save_pretrained(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851754a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name, bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "    padding_side=\"right\",\n",
    "    model_max_length=512,\n",
    ")\n",
    "\n",
    "with NaiveStrategy().model_init_context():\n",
    "        model = GPTRM_custom(pretrained='skt/kogpt2-base-v2', lora_rank=0, tokenizer=tokenizer).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119290f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_2_RM.jsonl', \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "total_data_ranking2chosen = []\n",
    "for tmp in list_data_dict:\n",
    "    one_data_ranking2chosen = []\n",
    "\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][0] < tmp['ranking'][1]:\n",
    "        data['chosen'] = tmp['completion_0']\n",
    "        data['rejected'] = tmp['completion_1']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_1']\n",
    "        data['rejected'] = tmp['completion_0']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][0] < tmp['ranking'][2]:\n",
    "        data['chosen'] = tmp['completion_0']\n",
    "        data['rejected'] = tmp['completion_2']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_2']\n",
    "        data['rejected'] = tmp['completion_0']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][1] < tmp['ranking'][2]:\n",
    "        data['chosen'] = tmp['completion_1']\n",
    "        data['rejected'] = tmp['completion_2']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_2']\n",
    "        data['rejected'] = tmp['completion_1']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "\n",
    "\n",
    "    total_data_ranking2chosen.extend(one_data_ranking2chosen)\n",
    "\n",
    "print('before data num: %d'%(len(list_data_dict)))\n",
    "print('after  data num: %d'%(len(total_data_ranking2chosen)))\n",
    "print('data example: \\n%s'%total_data_ranking2chosen[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84220ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(230319)\n",
    "random.shuffle(total_data_ranking2chosen)\n",
    "print(total_data_ranking2chosen[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8ab9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 셔플 후 일부만 학습\n",
    "train_data = total_data_ranking2chosen[:1000] \n",
    "eval_data = total_data_ranking2chosen[1000:1200]\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(eval_data))\n",
    "\n",
    "train_dataset = RewardDataset(train_data, tokenizer, 512)\n",
    "eval_dataset = RewardDataset(eval_data, tokenizer, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f70f67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = RewardModelTrainer(model=model,\n",
    "                             strategy=NaiveStrategy(),\n",
    "                             optim=Adam(model.parameters(), lr=5e-5),\n",
    "                             train_dataset=train_dataset,\n",
    "                             eval_dataset=eval_dataset,\n",
    "                             batch_size=4,\n",
    "                             max_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af81a9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(use_lora=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04a82c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('aiffel/KoChatGPT/output_2_RM_UG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea316c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_RM(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
    "        torch.cuda.current_device())\n",
    "    output = model(input_ids)\n",
    "    output_reward = output.cpu().detach().numpy()[0]\n",
    "\n",
    "    print('input: %s\\nreward score: %.1f'%(input_text, output_reward))\n",
    "\n",
    "    return output_reward\n",
    "\n",
    "input_text = '인공지능은 똥멍청이 입니다'\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765db451",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = '인공지능(AI)은 컴퓨터에서 음성 및 작성된 언어를 보고 이해하고 번역하고 데이터를 분석하고 추천하는 기능을 포함하여 다양한 고급 기능을 수행할 수 있는 일련의 기술입니다.'\n",
    "\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7629a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"인공지능(AI)은 컴퓨터에서 음성 및 작성된 언어를 보고 이해하고 번역하고 데이터를 분석하고 추천하는 기능을 포함하여 다양한 고급 기능을 수행할 수 있는 일련의 기술입니다. AI는 현대적인 컴퓨팅 혁신에서 중추적인 역할을 하며 개인과 비즈니스의 가치를 창출합니다. 예를 들어 광학 문자 인식(OCR)은 AI를 사용해 이미지 및 문서에서 텍스트 및 데이터를 추출하고, 구조화되지 않은 콘텐츠를 비즈니스에 바로 사용할 수 있게 만들고, 유용한 정보를 창출합니다.\"\n",
    "\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696ce338",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"인공지능은 일반적으로 인간의 지능이 필요하거나 인간이 분석할 수 있는 것보다 규모가 큰 데이터를 포함하는 방식으로 추론, 학습 및 행동할 수 있는 컴퓨터 및 기계를 구축하는 것과 관련된 과학 분야입니다. AI는 컴퓨터 공학, 데이터 분석 및 통계, 하드웨어 및 소프트웨어 엔지니어링, 언어학, 신경 과학은 물론 철학과 심리학을 포함하여 여러 학문을 포괄하는 광범위한 분야입니다. 비즈니스의 운영 수준에서 AI는 주로 머신러닝과 딥 러닝을 기반으로 하는 기술 모음으로, 데이터 분석, 예상 및 예측, 객체 분류, 자연어 처리, 추천, 지능형 데이터 가져오기 등을 수행할 수 있습니다.\"\n",
    "\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a96630a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bcb1fd",
   "metadata": {},
   "source": [
    "## PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28db5be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from chatgpt.models.base import RewardModel\n",
    "from chatgpt.models.gpt import GPTActor, GPTCritic\n",
    "from chatgpt.trainer import PPOTrainer\n",
    "from chatgpt.trainer.strategies import NaiveStrategy\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7cc6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with NaiveStrategy().model_init_context():\n",
    "    actor = GPTActor(pretrained='/aiffel/KoChatGPT/output_1_SFT_UG', lora_rank=0).to(torch.cuda.current_device())\n",
    "    critic = GPTCritic(pretrained='aiffel/KoChatGPT/output_2_RM_UG', lora_rank=0).to(torch.cuda.current_device())\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_name, bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "        padding_side=\"right\", \n",
    "        model_max_length=512\n",
    "    )\n",
    "\n",
    "    initial_model = deepcopy(actor)\n",
    "    reward_model = RewardModel(deepcopy(critic.model), deepcopy(critic.value_head)).to(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9959347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델학습에 사용할 옵티마이저와 모델을 준비합니다.\n",
    "actor_optim = Adam(actor.parameters(), lr=5e-6)\n",
    "critic_optim = Adam(critic.parameters(), lr=5e-6)\n",
    "(actor, actor_optim), (critic, critic_optim), reward_model, initial_model = NaiveStrategy().prepare(\n",
    "    (actor, actor_optim), (critic, critic_optim), reward_model, initial_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6720ece5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PPO 학습에 쓸 데이터를 불러와 토크나이징 해줍니다.\n",
    "with open('/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_3_PPO.jsonl', \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "    list_prompt = [tmp['prompt'] for tmp in list_data_dict]\n",
    "\n",
    "def tokenize_fn(texts):\n",
    "    batch = tokenizer(texts, return_tensors='pt', max_length=96, padding=True, truncation=True)\n",
    "    return {k: v.cuda() for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f865c68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PPO는 별도의 PPOTrainer 클래스를 설계하여 학습\n",
    "trainer = PPOTrainer(NaiveStrategy(),\n",
    "                     actor,\n",
    "                     critic,\n",
    "                     reward_model,\n",
    "                     initial_model,\n",
    "                     actor_optim,\n",
    "                     critic_optim,\n",
    "                     max_epochs=3,  \n",
    "                     train_batch_size=8, \n",
    "                     tokenizer=tokenize_fn,\n",
    "                     max_length=128,\n",
    "                     do_sample=True,\n",
    "                     temperature=1.0,\n",
    "                     top_k=50,\n",
    "                     pad_token_id=tokenizer.pad_token_id,\n",
    "                     eos_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2262e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(list_prompt, \n",
    "            num_episodes=10,  \n",
    "            max_timesteps=3,\n",
    "            update_timesteps=3)\n",
    "\n",
    "model.save_pretrained('aiffel/KoChatGPT/output_3_PPO_UG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6819634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLHF가 적용된 koGPT-2의 생성능력을 확인\n",
    "\n",
    "def generation(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
    "        torch.cuda.current_device())\n",
    "    outputs = actor.generate(input_ids,\n",
    "                             max_length=250,\n",
    "                             do_sample=True,\n",
    "                             top_k=50,\n",
    "                             top_p=0.95,\n",
    "                             num_return_sequences=1)\n",
    "    output = tokenizer.batch_decode(outputs[0], skip_special_tokens=True)[0]\n",
    "    print()\n",
    "    print(output)\n",
    "    return output\n",
    "\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "    )\n",
    "}\n",
    "\n",
    "list_prompt = [\n",
    "    '불고기용 고기 한우에요?', \n",
    "    '리처드 닉슨이 43대 부통령직을 수행한 년도는?', \n",
    "    '시카고 오헤어 국제공항은 어디에 있어',\n",
    "    '오늘 미세먼지 어때?']\n",
    "\n",
    "list_prompt = [PROMPT_DICT['prompt_input'].format_map({'prompt': tmp}) for tmp in list_prompt]\n",
    "\n",
    "for input_text in list_prompt:\n",
    "    output = generation(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e42dea",
   "metadata": {},
   "source": [
    "# Retrospective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c59bc3",
   "metadata": {},
   "source": [
    "다양한 방법으로 리소스를 감소시키기 위해 노력하였으나 지속적인 OOM과 Kernel Dead로 인해 학습이 불가능하여 아쉽게 성능 테스트를 끝내지 못했다.\n",
    "LLM모델중에는 작은편에 속하지만 처음 Large Model을 다루다보니 자원 관리의 중요성을 직접적으로 체감할 수 있었다.\n",
    "\n",
    "RLHF가 적용된 koGPT-2는 첫줄까지는 잘 출력되는 것 같았지만 이후에는 3개국어를 사용하며 답변의 퀄리티가 나빠지는 것이 확인되었다.\n",
    "\n",
    "1 Epoch 학습을 진행했을 때보다 3 Epoch를 진행했을 때 성능이 안좋아졌는데\n",
    "SFT에서는 Loss가 감소하였으나 RM에서 Loss가 높아지며 reward score가 비정상적으로 작동한 것으로 보여져 RM쪽에서 문제가 있었던 것 같다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
