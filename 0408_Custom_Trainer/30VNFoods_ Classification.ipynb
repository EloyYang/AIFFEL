{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5a9f403",
   "metadata": {},
   "source": [
    "# 30VNFoods Classification with Custom Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e03aa93",
   "metadata": {},
   "source": [
    "30종류의 베트남 음식 중 10개의 카테고리를 선별해서 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbffc318",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14f4245a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09da1c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set과 test set의 모든 이미지 파일에 대해서,\n",
    "# jpg image header가 포함되지 않은 (jpg의 파일 구조에 어긋나는) 파일들을 삭제\n",
    "\n",
    "data_path = '/aiffel/aiffel/model-fit/data/30vnfoods/'\n",
    "train_path = data_path + 'Train/'\n",
    "test_path = data_path + 'Test/'\n",
    "\n",
    "for path in [train_path, test_path]:\n",
    "    classes = os.listdir(path)\n",
    "\n",
    "    for food in classes:\n",
    "        food_path = os.path.join(path, food)\n",
    "        images = os.listdir(food_path)\n",
    "        \n",
    "        for image in images:\n",
    "            with open(os.path.join(food_path, image), 'rb') as f:\n",
    "                bytes = f.read()\n",
    "            if bytes[:3] != b'\\xff\\xd8\\xff':\n",
    "                print(os.path.join(food_path, image))\n",
    "                os.remove(os.path.join(food_path, image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ecd3abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data의 개수: 9775\n"
     ]
    }
   ],
   "source": [
    "classes = os.listdir(train_path)\n",
    "train_length = 0\n",
    "\n",
    "for food in classes:\n",
    "    food_path = os.path.join(train_path, food)\n",
    "    images = os.listdir(food_path)\n",
    "    \n",
    "    train_length += len(images)\n",
    "\n",
    "print('training data의 개수: '+str(train_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef450c5",
   "metadata": {},
   "source": [
    "## Define Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9d72422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def process_path(file_path, class_names, img_shape=(224, 224)):\n",
    "    '''\n",
    "    file_path로부터 class label을 만들고, 이미지를 읽는 함수\n",
    "    '''\n",
    "    label = tf.strings.split(file_path, os.path.sep)\n",
    "    label = label[-2] == class_names\n",
    "\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.image.resize(img, img_shape)\n",
    "    return img, label\n",
    "\n",
    "def prepare_for_training(ds, batch_size=32, cache=True, shuffle_buffer_size=1000):\n",
    "    '''\n",
    "    TensorFlow Data API를 이용해 data batch를 만드는 함수\n",
    "    '''\n",
    "    if cache:\n",
    "        if isinstance(cache, str):\n",
    "            ds = ds.cache(cache)\n",
    "        else:\n",
    "            ds = ds.cache()\n",
    "\n",
    "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "    ds = ds.repeat()\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return ds\n",
    "\n",
    "    \n",
    "def load_data(data_path, batch_size=32):\n",
    "    '''\n",
    "    데이터를 만들기 위해 필요한 함수들을 호출하고 데이터를 리턴해주는 함수\n",
    "    '''\n",
    "    class_names = [cls for cls in os.listdir(data_path) if cls != '.DS_Store']\n",
    "    data_path = pathlib.Path(data_path)\n",
    "\n",
    "    list_ds = tf.data.Dataset.list_files(str(data_path/'*/*'))\n",
    "    labeled_ds = list_ds.map(lambda x: process_path(x, class_names, img_shape=(224, 224)))\n",
    "    ds = prepare_for_training(labeled_ds, batch_size=batch_size)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e17f34",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc3ef803",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(tf.keras.Model):\n",
    "    def __init__(self, num_classes=10, freeze=False):\n",
    "        super(Model, self).__init__()\n",
    "        self.backbone = EfficientNetB0(include_top=False, input_shape=(224, 224, 3), weights='imagenet' if not freeze else None)\n",
    "        if freeze:\n",
    "            for layer in self.backbone.layers:\n",
    "                layer.trainable = False\n",
    "        self.global_avg_pooling = GlobalAveragePooling2D()\n",
    "        self.classifier = Dense(num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        x = self.backbone(inputs, training=training)\n",
    "        x = self.global_avg_pooling(x)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14c6cde",
   "metadata": {},
   "source": [
    "## Define Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7482ced7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 2.3098\n",
      "Seen so far: 32 samples\n",
      "Training loss (for one batch) at step 200: 0.7458\n",
      "Seen so far: 6432 samples\n",
      "Training acc over epoch: 0.8051\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: 0.1986\n",
      "Seen so far: 32 samples\n",
      "Training loss (for one batch) at step 200: 0.5218\n",
      "Seen so far: 6432 samples\n",
      "Training acc over epoch: 0.9094\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: 0.0809\n",
      "Seen so far: 32 samples\n",
      "Training loss (for one batch) at step 200: 0.0720\n",
      "Seen so far: 6432 samples\n",
      "Training acc over epoch: 0.9370\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: 0.0713\n",
      "Seen so far: 32 samples\n",
      "Training loss (for one batch) at step 200: 0.1981\n",
      "Seen so far: 6432 samples\n",
      "Training acc over epoch: 0.9488\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at step 0: 0.0735\n",
      "Seen so far: 32 samples\n",
      "Training loss (for one batch) at step 200: 0.1916\n",
      "Seen so far: 6432 samples\n",
      "Training acc over epoch: 0.9572\n"
     ]
    }
   ],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, epochs, batch, loss_fn, optimizer, steps_per_epoch):\n",
    "        self.model = model\n",
    "        self.epochs = epochs\n",
    "        self.batch = batch\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "\n",
    "    def train(self, train_dataset, train_metric):\n",
    "        for epoch in range(self.epochs):\n",
    "            print(\"\\nStart of epoch %d\" % (epoch + 1,))\n",
    "            train_metric.reset_states()\n",
    "\n",
    "            for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "                if step >= self.steps_per_epoch:\n",
    "                    break\n",
    "                with tf.GradientTape() as tape:\n",
    "                    logits = self.model(x_batch_train, training=True)\n",
    "                    loss_value = self.loss_fn(y_batch_train, logits)\n",
    "                grads = tape.gradient(loss_value, self.model.trainable_weights)\n",
    "                self.optimizer.apply_gradients(zip(grads, self.model.trainable_weights))\n",
    "                train_metric.update_state(y_batch_train, logits)\n",
    "\n",
    "                if step % 200 == 0:\n",
    "                    print(\"Training loss (for one batch) at step %d: %.4f\" %\n",
    "                          (step, float(loss_value)))\n",
    "                    print(\"Seen so far: %s samples\" % ((step + 1) * self.batch))\n",
    "\n",
    "            train_acc = train_metric.result()\n",
    "            print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "\n",
    "# Determine steps per epoch based on your dataset size\n",
    "train_length = 10000  # replace with the actual size of your dataset\n",
    "steps_per_epoch = train_length // batch\n",
    "\n",
    "# Usage Example\n",
    "train_path = \"/aiffel/aiffel/model-fit/data/30vnfoods/Train\"\n",
    "epoch = 5\n",
    "batch = 32\n",
    "\n",
    "model = Model(num_classes=10)\n",
    "dataset = load_data(data_path=train_path, batch_size=batch)\n",
    "loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "train_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "trainer = Trainer(model=model, epochs=epoch, batch=batch, loss_fn=loss_function, optimizer=optimizer, steps_per_epoch=steps_per_epoch)\n",
    "\n",
    "trainer.train(train_dataset=dataset, train_metric=train_acc_metric)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ae6de5",
   "metadata": {},
   "source": [
    "## Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbc04eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/32\n",
      "27/32\n",
      "32/32\n",
      "28/32\n",
      "29/32\n",
      "28/32\n",
      "28/32\n",
      "29/32\n",
      "28/32\n",
      "28/32\n"
     ]
    }
   ],
   "source": [
    "# 모델 테스트 코드\n",
    "test_ds = load_data(data_path=test_path)\n",
    "\n",
    "for step_train, (x_batch_train, y_batch_train) in enumerate(test_ds.take(10)):\n",
    "    prediction = model(x_batch_train)\n",
    "    print(\"{}/{}\".format(np.array(tf.equal(tf.argmax(y_batch_train, axis=1), tf.argmax(prediction, axis=1))).sum(), tf.argmax(y_batch_train, axis=1).shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97266f59",
   "metadata": {},
   "source": [
    "## Retrospective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fc5f90",
   "metadata": {},
   "source": [
    "steps_per_epoch를 설정하지 않아 prepare_for_training에서 repeat()으로 인해 밤새 학습하였음에도 모델이 종료되지 않는 문제가 있었다.<br/>\n",
    "분명 들었던 내용이었음에도 실제 구축하다보니 빼먹는 부분이 많았고 GPT가 없었다면 Custom을 완성하지 못했을 것 같다.<br/>\n",
    "<br/>\n",
    "backbone model은 Imagenet에서 뛰어난 성능을 보여주는 EfficientNet의 가장 기초 모델을 사용했지만 테스트할 때마다 보여주는 성능은 놀랍다.<br/><br/>\n",
    "간편하게 모델을 불러오고 학습하는 과정을 한줄의 코드로 사용하는 것 보다 원리를 이해하려고 노력하다보니 낮설던 코드와 조금은 친해진 것 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0d3f44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
